"""
æ”¹è¿›çš„å¹¶å‘åˆ†æç®¡ç†å™¨
è§£å†³åŸæœ‰çº¿ç¨‹æ§åˆ¶ä¸ç¨³å®šã€çŠ¶æ€æ§åˆ¶ä¸ç¨³å®šç­‰é—®é¢˜
"""

import threading
import time
import logging
from typing import Dict, Any, List, Tuple, Optional
from concurrent.futures import ThreadPoolExecutor, Future, as_completed
from django.conf import settings
from django.core.cache import cache
from .task_cancellation import cancellation_manager, TaskCancelledException

logger = logging.getLogger(__name__)


class ConcurrencyManager:
    """å¹¶å‘åˆ†æç®¡ç†å™¨"""

    def __init__(self):
        # æ¯ä¸ªç”¨æˆ·çš„ç‹¬ç«‹çº¿ç¨‹æ± æ‰§è¡Œå™¨
        self.user_executors: Dict[int, ThreadPoolExecutor] = {}
        # è·Ÿè¸ªæ‰€æœ‰æ´»åŠ¨çš„Futureå¯¹è±¡
        self.active_futures: Dict[Future, Dict[str, Any]] = {}
        # ç”¨æˆ·ä¿¡å·é‡ç®¡ç†
        self.user_semaphores: Dict[int, threading.Semaphore] = {}
        # å…¨å±€æ§åˆ¶é”
        self._lock = threading.RLock()
        # ç³»ç»Ÿå…³é—­æ ‡å¿—
        self._shutdown_event = threading.Event()
        # å…¨å±€æ´»è·ƒçº¿ç¨‹è®¡æ•°å™¨
        self.global_active_threads = 0

        # ç³»ç»Ÿé™åˆ¶é…ç½®
        self.global_max_concurrent = getattr(settings, 'OLLAMA_GLOBAL_MAX_CONCURRENT', 20)  # å¢åŠ å…¨å±€å¹¶å‘é™åˆ¶
        self.default_concurrent = getattr(settings, 'OLLAMA_DEFAULT_CONCURRENT', 5)  # å¢åŠ é»˜è®¤å¹¶å‘é™åˆ¶
        self.cleanup_interval = 300  # 5åˆ†é’Ÿæ¸…ç†ä¸€æ¬¡
        self.executor_timeout = 3600  # 1å°æ—¶åæ¸…ç†ç©ºé—²æ‰§è¡Œå™¨

        # å¯åŠ¨åå°æ¸…ç†çº¿ç¨‹
        self._start_cleanup_thread()

    def _start_cleanup_thread(self):
        """å¯åŠ¨åå°æ¸…ç†çº¿ç¨‹"""
        def cleanup_worker():
            while not self._shutdown_event.wait(self.cleanup_interval):
                try:
                    self.cleanup_idle_resources()
                except Exception as e:
                    logger.error(f"æ¸…ç†èµ„æºæ—¶å‡ºé”™: {str(e)}")

        cleanup_thread = threading.Thread(target=cleanup_worker, daemon=True)
        cleanup_thread.start()
        logger.info("ğŸ§¹ åå°èµ„æºæ¸…ç†çº¿ç¨‹å·²å¯åŠ¨")

    def get_or_create_user_executor(self, user_id: int, max_workers: int) -> ThreadPoolExecutor:
        """è·å–æˆ–åˆ›å»ºç”¨æˆ·çº¿ç¨‹æ± æ‰§è¡Œå™¨"""
        with self._lock:
            # æ£€æŸ¥ç³»ç»Ÿæ˜¯å¦æ­£åœ¨å…³é—­
            if self._shutdown_event.is_set():
                raise Exception("ç³»ç»Ÿæ­£åœ¨å…³é—­ï¼Œä¸æ¥å—æ–°ä»»åŠ¡")

            # æ£€æŸ¥å…¨å±€å¹¶å‘é™åˆ¶
            current_global_threads = sum(
                executor._threads.__len__() if hasattr(executor, '_threads') else 0
                for executor in self.user_executors.values()
            )

            # ç§»é™¤å…¨å±€çº¿ç¨‹æ•°é™åˆ¶ï¼Œå…è®¸æ¯ä¸ªç”¨æˆ·ç‹¬ç«‹æ§åˆ¶å¹¶å‘æ•°
            # if current_global_threads >= self.global_max_concurrent:
            #     logger.warning(f"âš ï¸ å…¨å±€çº¿ç¨‹æ•°å·²è¾¾ä¸Šé™: {current_global_threads}/{self.global_max_concurrent}")
            #     # ä½¿ç”¨æœ€å°çº¿ç¨‹æ•°åˆ›å»ºæ‰§è¡Œå™¨ï¼Œç¡®ä¿æ–°ä»»åŠ¡èƒ½è¢«æ¥å—ä½†ä¼šæ’é˜Ÿç­‰å¾…
            #     max_workers = min(max_workers, max(1, self.global_max_concurrent - current_global_threads))

            # ä¸ºç”¨æˆ·åˆ›å»ºæˆ–è·å–æ‰§è¡Œå™¨
            if user_id not in self.user_executors:
                executor = ThreadPoolExecutor(
                    max_workers=max_workers,
                    thread_name_prefix=f"user_{user_id}_worker"
                )
                self.user_executors[user_id] = executor
                logger.info(f"ğŸ”§ ä¸ºç”¨æˆ· {user_id} åˆ›å»ºçº¿ç¨‹æ± æ‰§è¡Œå™¨ï¼Œæœ€å¤§å¹¶å‘: {max_workers}")
            else:
                # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°æ‰§è¡Œå™¨çš„æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°
                existing_executor = self.user_executors[user_id]
                if hasattr(existing_executor, '_max_workers') and existing_executor._max_workers < max_workers:
                    logger.info(f"ğŸ”§ ç”¨æˆ· {user_id} çš„çº¿ç¨‹æ± æ‰§è¡Œå™¨éœ€è¦æ›´æ–°å¹¶å‘é™åˆ¶ï¼Œä» {existing_executor._max_workers} å¢åŠ åˆ° {max_workers}")
                    # æ³¨æ„ï¼šThreadPoolExecutor ä¸æ”¯æŒåŠ¨æ€è°ƒæ•´ max_workers
                    # è¿™é‡Œåªæ˜¯è®°å½•æ—¥å¿—ï¼Œå®é™…ä½¿ç”¨ä¸­å¯èƒ½éœ€è¦é‡æ–°åˆ›å»ºæ‰§è¡Œå™¨
                    # ä½†ä¸ºäº†ç¨³å®šæ€§ï¼Œæˆ‘ä»¬ä¿æŒç°æœ‰æ‰§è¡Œå™¨ï¼Œåªæ›´æ–°ä¿¡å·é‡

            return self.user_executors[user_id]

    def get_user_semaphore(self, user_id: int, max_concurrent: int) -> threading.Semaphore:
        """è·å–ç”¨æˆ·å¹¶å‘æ§åˆ¶ä¿¡å·é‡"""
        with self._lock:
            if user_id not in self.user_semaphores:
                self.user_semaphores[user_id] = threading.Semaphore(max_concurrent)
                logger.info(f"ğŸ”§ ä¸ºç”¨æˆ· {user_id} åˆ›å»ºä¿¡å·é‡ï¼Œå¹¶å‘é™åˆ¶: {max_concurrent}")
            else:
                # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ä¿¡å·é‡é™åˆ¶
                current_semaphore = self.user_semaphores[user_id]
                current_value = current_semaphore._value
                max_value = max_concurrent
                
                # å¦‚æœæ–°çš„å¹¶å‘é™åˆ¶æ›´å¤§ï¼Œéœ€è¦é‡æ–°åˆ›å»ºä¿¡å·é‡
                if max_value > current_value:
                    self.user_semaphores[user_id] = threading.Semaphore(max_concurrent)
                    logger.info(f"ğŸ”§ æ›´æ–°ç”¨æˆ· {user_id} ä¿¡å·é‡ï¼Œä» {current_value} å¢åŠ åˆ° {max_concurrent}")
                    
            return self.user_semaphores[user_id]

    def submit_task(self, user_id: int, task_func, *args, max_concurrent: Optional[int] = None, **kwargs) -> Future:
        """æäº¤ä»»åŠ¡åˆ°ç”¨æˆ·çš„çº¿ç¨‹æ± """
        max_concurrent = max_concurrent or self.default_concurrent
        
        logger.debug(f"ğŸ“¤ æäº¤ä»»åŠ¡: ç”¨æˆ· {user_id}, å¹¶å‘é™åˆ¶: {max_concurrent}")

        # æ£€æŸ¥ç³»ç»Ÿæ˜¯å¦å…³é—­
        if self._shutdown_event.is_set():
            raise Exception("ç³»ç»Ÿæ­£åœ¨å…³é—­ï¼Œä¸æ¥å—æ–°ä»»åŠ¡")

        # è·å–ç”¨æˆ·æ‰§è¡Œå™¨
        executor = self.get_or_create_user_executor(user_id, max_concurrent)

        # è·å–ç”¨æˆ·ä¿¡å·é‡
        semaphore = self.get_user_semaphore(user_id, max_concurrent)

        def task_wrapper(*task_args, **task_kwargs):
            """ä»»åŠ¡åŒ…è£…å™¨ï¼Œç®¡ç†ä¿¡å·é‡å’ŒçŠ¶æ€"""
            # è·å–ä¿¡å·é‡
            semaphore.acquire()
            thread_id = threading.get_ident()

            try:
                with self._lock:
                    self.global_active_threads += 1

                logger.info(f"ğŸš€ ç”¨æˆ· {user_id} ä»»åŠ¡å¼€å§‹æ‰§è¡Œ (çº¿ç¨‹: {thread_id})")
                start_time = time.time()

                # æ‰§è¡Œå®é™…ä»»åŠ¡
                result = task_func(*task_args, **task_kwargs)

                processing_time = time.time() - start_time
                logger.info(f"âœ… ç”¨æˆ· {user_id} ä»»åŠ¡å®Œæˆï¼Œè€—æ—¶: {processing_time:.2f}s")

                return result

            except TaskCancelledException:
                logger.info(f"ğŸš« ç”¨æˆ· {user_id} ä»»åŠ¡è¢«å–æ¶ˆ (çº¿ç¨‹: {thread_id})")
                raise
            except Exception as e:
                logger.error(f"âŒ ç”¨æˆ· {user_id} ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}")
                raise
            finally:
                # é‡Šæ”¾ä¿¡å·é‡å’Œæ›´æ–°è®¡æ•°å™¨
                semaphore.release()
                with self._lock:
                    self.global_active_threads -= 1
                    # ä»æ´»åŠ¨ä»»åŠ¡åˆ—è¡¨ä¸­ç§»é™¤
                    for future in list(self.active_futures.keys()):
                        if future.done() or future.cancelled():
                            self.active_futures.pop(future, None)

        # æäº¤ä»»åŠ¡
        future = executor.submit(task_wrapper, *args, **kwargs)

        # è®°å½•æ´»åŠ¨ä»»åŠ¡
        with self._lock:
            self.active_futures[future] = {
                'user_id': user_id,
                'thread_name': threading.current_thread().name,
                'submitted_at': time.time()
            }

        return future

    def cancel_user_tasks(self, user_id: int) -> Dict[str, Any]:
        """å–æ¶ˆç”¨æˆ·çš„æ‰€æœ‰ä»»åŠ¡"""
        cancelled_count = 0
        cancelled_futures = []

        with self._lock:
            # æ‰¾åˆ°è¯¥ç”¨æˆ·çš„æ‰€æœ‰æ´»åŠ¨ä»»åŠ¡
            user_futures = [
                future for future, info in self.active_futures.items()
                if info['user_id'] == user_id
            ]

            # å°è¯•å–æ¶ˆæœªå¼€å§‹çš„ä»»åŠ¡
            for future in user_futures:
                if not future.running():
                    if future.cancel():
                        cancelled_count += 1
                        cancelled_futures.append(future)
                        logger.debug(f"ğŸš« å–æ¶ˆæœªå¼€å§‹çš„ä»»åŠ¡: {future}")

        # æ¸…ç†å·²å–æ¶ˆçš„ä»»åŠ¡
        for future in cancelled_futures:
            self.active_futures.pop(future, None)

        # é€šè¿‡ä»»åŠ¡ç®¡ç†å™¨å–æ¶ˆå¯å–æ¶ˆä»»åŠ¡
        task_cancelled_count = cancellation_manager.cancel_user_tasks(user_id)

        total_cancelled = cancelled_count + task_cancelled_count

        logger.info(f"ğŸš« ç”¨æˆ· {user_id} ä»»åŠ¡å–æ¶ˆå®Œæˆ: "
                   f"future_cancelled={cancelled_count}, "
                   f"task_cancelled={task_cancelled_count}, "
                   f"total={total_cancelled}")

        return {
            'cancelled_count': total_cancelled,
            'future_cancelled': cancelled_count,
            'task_cancelled': task_cancelled_count
        }

    def execute_tasks_concurrently(
        self,
        tasks: List[Tuple[str, str]],
        analysis,
        executor_callback
    ) -> Dict[str, Any]:
        """å¹¶å‘æ‰§è¡Œåˆ†æä»»åŠ¡ï¼ˆæ”¹è¿›ç‰ˆï¼‰"""
        user_id = analysis.media.user.id if hasattr(analysis.media, 'user') else None
        options = analysis.analysis_options

        # è·å–å¹¶å‘æ§åˆ¶å‚æ•°
        max_concurrent = options.get('max_concurrent', self.default_concurrent)
        # ç§»é™¤å…¨å±€å¹¶å‘é™åˆ¶ï¼Œå…è®¸ç”¨æˆ·è®¾ç½®æ›´é«˜çš„å¹¶å‘æ•°
        # max_concurrent = min(max_concurrent, self.global_max_concurrent)

        logger.info(f"ğŸ”„ å¼€å§‹æ”¹è¿›ç‰ˆå¹¶å‘æ‰§è¡Œ {len(tasks)} ä¸ªä»»åŠ¡ï¼Œç”¨æˆ·: {user_id}ï¼Œå¹¶å‘æ•°: {max_concurrent}")

        results = {}
        failed_tasks = []
        submitted_futures = []

        try:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            for task_name, task_prompt in tasks:
                try:
                    future = self.submit_task(
                        user_id=user_id,
                        task_func=self._execute_single_task,
                        task_name=task_name,
                        task_prompt=task_prompt,
                        analysis=analysis,
                        executor_callback=executor_callback,
                        max_concurrent=max_concurrent
                    )
                    submitted_futures.append((future, task_name))
                except Exception as e:
                    failed_tasks.append(f"{task_name}: æäº¤ä»»åŠ¡å¤±è´¥ - {str(e)}")
                    logger.error(f"âŒ ä»»åŠ¡ {task_name} æäº¤å¤±è´¥: {str(e)}")

            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            for future, task_name in submitted_futures:
                try:
                    # è®¾ç½®è¶…æ—¶é™åˆ¶
                    timeout = getattr(settings, 'OLLAMA_ANALYSIS_TIMEOUT', 300)
                    result = future.result(timeout=timeout)

                    if result['success']:
                        results[task_name] = result['result']
                        logger.debug(f"âœ… ä»»åŠ¡ {task_name} æ‰§è¡ŒæˆåŠŸ")
                    else:
                        failed_tasks.append(f"{task_name}: {result['error']}")
                        logger.error(f"âŒ ä»»åŠ¡ {task_name} æ‰§è¡Œå¤±è´¥: {result['error']}")

                except Exception as e:
                    failed_tasks.append(f"{task_name}: æ‰§è¡Œå¼‚å¸¸ - {str(e)}")
                    logger.error(f"âŒ ä»»åŠ¡ {task_name} æ‰§è¡Œå¼‚å¸¸: {str(e)}")

            logger.info(f"ğŸ“Š å¹¶å‘æ‰§è¡Œå®Œæˆ: æˆåŠŸ {len(results)} ä¸ªï¼Œå¤±è´¥ {len(failed_tasks)} ä¸ª")

            return {
                'results': results,
                'failed_tasks': failed_tasks,
                'total_tasks': len(tasks),
                'completed_tasks': len(results)
            }

        except Exception as e:
            logger.error(f"âŒ å¹¶å‘æ‰§è¡Œå‡ºç°ä¸¥é‡é”™è¯¯: {str(e)}")
            return {
                'results': results,
                'failed_tasks': failed_tasks + [f"ç³»ç»Ÿé”™è¯¯: {str(e)}"],
                'total_tasks': len(tasks),
                'completed_tasks': len(results)
            }

    def _execute_single_task(self, task_name: str, task_prompt: str, analysis, executor_callback) -> Dict[str, Any]:
        """æ‰§è¡Œå•ä¸ªä»»åŠ¡ï¼ˆæ”¯æŒå–æ¶ˆï¼‰"""
        # åˆ›å»ºå¯å–æ¶ˆä»»åŠ¡
        cancellable_task = cancellation_manager.create_task(
            f"{task_name}_{analysis.id}_{int(time.time())}",
            analysis.media.user.id
        )

        try:
            cancellable_task.start()

            # æ£€æŸ¥å–æ¶ˆçŠ¶æ€
            cancellable_task.check_cancelled()

            # æ‰§è¡Œå›è°ƒå‡†å¤‡æ•°æ®
            data = cancellable_task.execute_with_cancellation_check(
                executor_callback, analysis, task_prompt
            )

            # å†æ¬¡æ£€æŸ¥å–æ¶ˆçŠ¶æ€
            cancellable_task.check_cancelled()

            # è°ƒç”¨API
            api_result = cancellable_task.execute_with_cancellation_check(
                self._call_api_with_timeout,
                analysis.model.endpoint.url,
                analysis.model.name,
                data,
                cancellable_task
            )

            # æœ€ç»ˆæ£€æŸ¥å–æ¶ˆçŠ¶æ€
            cancellable_task.check_cancelled()

            if api_result['success']:
                # å¤„ç†ç»“æœ
                from .ollama_client import OllamaImageAnalyzer
                analyzer = OllamaImageAnalyzer()

                response_dict = api_result['response']
                if isinstance(response_dict, dict) and 'response' in response_dict:
                    response_text = response_dict['response']
                else:
                    response_text = str(response_dict)

                task_result = analyzer._process_single_result(response_text, task_name)

                cancellable_task.set_result(task_result)
                return {'success': True, 'result': task_result}
            else:
                error_msg = api_result['error']
                cancellable_task.set_error(Exception(error_msg))
                return {'success': False, 'error': error_msg}

        except TaskCancelledException:
            logger.info(f"ğŸš« ä»»åŠ¡ {task_name} è¢«å–æ¶ˆ")
            return {'success': False, 'error': 'ä»»åŠ¡å·²è¢«å–æ¶ˆ', 'cancelled': True}
        except Exception as e:
            error_msg = f"ä»»åŠ¡ {task_name} å¼‚å¸¸: {str(e)}"
            cancellable_task.set_error(e)
            logger.error(error_msg)
            return {'success': False, 'error': error_msg}
        finally:
            # æ¸…ç†ä»»åŠ¡
            cancellation_manager.remove_task(cancellable_task.task_id)

    def _call_api_with_timeout(self, endpoint_url: str, model_name: str, data: Dict, cancellable_task) -> Dict:
        """è°ƒç”¨APIï¼ˆå¸¦å–æ¶ˆæ£€æŸ¥ï¼‰"""
        import requests

        timeout = getattr(settings, 'OLLAMA_ANALYSIS_TIMEOUT', 300)
        api_url = f"{endpoint_url.rstrip('/')}/api/generate"

        request_data = {
            'model': model_name,
            'prompt': data['prompt'],
            'images': [data['image']],
            'stream': False,
            'options': data['options']
        }

        try:
            # ä½¿ç”¨å¯å–æ¶ˆä»»åŠ¡æ‰§è¡Œè¯·æ±‚
            response = cancellable_task.execute_with_cancellation_check(
                requests.post,
                api_url,
                json=request_data,
                timeout=timeout,
                headers={'Content-Type': 'application/json'}
            )

            if response.status_code == 200:
                return {
                    'success': True,
                    'response': response.json()
                }
            else:
                return {
                    'success': False,
                    'error': f"APIè¯·æ±‚å¤±è´¥: HTTP {response.status_code}"
                }

        except requests.exceptions.Timeout:
            return {'success': False, 'error': "APIè¯·æ±‚è¶…æ—¶"}
        except requests.exceptions.ConnectionError:
            return {'success': False, 'error': "æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡"}
        except Exception as e:
            if "å–æ¶ˆ" in str(e):
                raise e
            return {'success': False, 'error': f"APIè°ƒç”¨å¼‚å¸¸: {str(e)}"}

    def get_active_tasks_info(self) -> Dict[str, Any]:
        """è·å–å½“å‰æ´»è·ƒä»»åŠ¡ä¿¡æ¯"""
        with self._lock:
            user_task_counts = {}
            for info in self.active_futures.values():
                user_id = info['user_id']
                user_task_counts[user_id] = user_task_counts.get(user_id, 0) + 1

            return {
                'total_active_tasks': len(self.active_futures),
                'global_active_threads': self.global_active_threads,
                'user_executors_count': len(self.user_executors),
                'user_semaphores_count': len(self.user_semaphores),
                'user_task_counts': user_task_counts,
                'active_futures_details': [
                    {
                        'user_id': info['user_id'],
                        'submitted_at': info['submitted_at'],
                        'is_running': future.running(),
                        'is_done': future.done()
                    }
                    for future, info in self.active_futures.items()
                ]
            }

    def cleanup_user_resources(self, user_id: int):
        """æ¸…ç†ç”¨æˆ·èµ„æº"""
        with self._lock:
            cancelled_count = self.cancel_user_tasks(user_id)['cancelled_count']

            # å…³é—­ç”¨æˆ·æ‰§è¡Œå™¨
            if user_id in self.user_executors:
                executor = self.user_executors[user_id]
                executor.shutdown(wait=False)
                del self.user_executors[user_id]
                logger.info(f"ğŸ”§ å…³é—­ç”¨æˆ· {user_id} çš„çº¿ç¨‹æ± æ‰§è¡Œå™¨")

            # æ¸…ç†ç”¨æˆ·ä¿¡å·é‡
            if user_id in self.user_semaphores:
                del self.user_semaphores[user_id]
                logger.info(f"ğŸ”§ æ¸…ç†ç”¨æˆ· {user_id} çš„ä¿¡å·é‡")

        logger.info(f"ğŸ§¹ ç”¨æˆ· {user_id} èµ„æºæ¸…ç†å®Œæˆï¼Œå–æ¶ˆ {cancelled_count} ä¸ªä»»åŠ¡")

    def cleanup_idle_resources(self):
        """æ¸…ç†ç©ºé—²èµ„æº"""
        with self._lock:
            current_time = time.time()
            idle_threshold = self.executor_timeout

            # æ¸…ç†ç©ºé—²çš„æ‰§è¡Œå™¨
            users_to_remove = []
            for user_id, executor in self.user_executors.items():
                # æ£€æŸ¥æ˜¯å¦æœ‰æ´»åŠ¨ä»»åŠ¡
                user_has_active_tasks = any(
                    info['user_id'] == user_id for info in self.active_futures.values()
                )

                if not user_has_active_tasks:
                    users_to_remove.append(user_id)

            for user_id in users_to_remove:
                self.cleanup_user_resources(user_id)

            # æ¸…ç†å·²å®Œæˆçš„Future
            completed_futures = [
                future for future in self.active_futures.keys()
                if future.done() or future.cancelled()
            ]
            for future in completed_futures:
                self.active_futures.pop(future, None)

            # æ¸…ç†ä»»åŠ¡ç®¡ç†å™¨ä¸­çš„å·²å®Œæˆä»»åŠ¡
            cancellation_manager.cleanup_completed_tasks()

        if users_to_remove or completed_futures:
            logger.info(f"ğŸ§¹ æ¸…ç†å®Œæˆ: ç§»é™¤ {len(users_to_remove)} ä¸ªç”¨æˆ·æ‰§è¡Œå™¨, "
                       f"æ¸…ç† {len(completed_futures)} ä¸ªå·²å®Œæˆçš„ä»»åŠ¡")

    def shutdown(self):
        """å…³é—­ç®¡ç†å™¨"""
        logger.info("ğŸ›‘ æ­£åœ¨å…³é—­å¹¶å‘ç®¡ç†å™¨...")

        self._shutdown_event.set()

        with self._lock:
            # å–æ¶ˆæ‰€æœ‰æ´»åŠ¨ä»»åŠ¡
            for future in list(self.active_futures.keys()):
                future.cancel()

            # å…³é—­æ‰€æœ‰æ‰§è¡Œå™¨
            for executor in self.user_executors.values():
                executor.shutdown(wait=False)

            self.user_executors.clear()
            self.user_semaphores.clear()
            self.active_futures.clear()

        logger.info("âœ… å¹¶å‘ç®¡ç†å™¨å·²å…³é—­")

    def process_batch_images(
        self,
        user_id: int,
        media_ids: List[int],
        model_name: str,
        analysis_options: Dict[str, Any],
        executor_callback=None
    ) -> Dict[str, Any]:
        """
        æ‰¹é‡å¤„ç†å›¾ç‰‡ï¼ˆæ”¹è¿›ç‰ˆï¼‰
        ä½¿ç”¨ç¨³å®šçš„çº¿ç¨‹æ± ç®¡ç†å’ŒçœŸæ­£çš„å–æ¶ˆæœºåˆ¶

        é‡è¦è¯´æ˜ï¼š
        - å¤šå¼ å›¾ç‰‡ä¹‹é—´å¯ä»¥å¹¶å‘å¤„ç†ï¼ˆå—max_concurrentæ§åˆ¶ï¼‰
        - æ¯å¼ å›¾ç‰‡å†…éƒ¨çš„4ä¸ªåˆ†æé¡¹ç›®ï¼ˆæ ‡é¢˜ã€æè¿°ã€åˆ†ç±»ã€æ ‡ç­¾ï¼‰å¼ºåˆ¶ä¸²è¡Œæ‰§è¡Œï¼Œé¿å…APIå†²çª
        """
        from ..models import OllamaImageAnalysis
        from .ollama_client import OllamaImageAnalyzer
        from .prompt_templates import TaskConfig

        max_concurrent = analysis_options.get('max_concurrent', self.default_concurrent)
        logger.info(f"ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç† {len(media_ids)} ä¸ªå›¾ç‰‡ï¼Œç”¨æˆ· {user_id} å›¾ç‰‡çº§å¹¶å‘é™åˆ¶: {max_concurrent}")
        logger.info(f"ğŸ“ è¯´æ˜ï¼šæ¯å¼ å›¾ç‰‡å†…éƒ¨çš„4ä¸ªåˆ†æé¡¹ç›®å°†ä¸²è¡Œæ‰§è¡Œï¼ˆæ ‡é¢˜ã€æè¿°ã€åˆ†ç±»ã€æ ‡ç­¾ï¼‰")
        
        # è®°å½•å½“å‰æ´»è·ƒä»»åŠ¡ä¿¡æ¯
        active_info = self.get_active_tasks_info()
        logger.info(f"ğŸ“Š å½“å‰æ´»è·ƒä»»åŠ¡ä¿¡æ¯: {active_info}")

        # è·å–æ‰€æœ‰åˆ†æå¯¹è±¡ï¼ˆåªå¤„ç†å¾…å¤„ç†çš„ä»»åŠ¡ï¼‰
        analyses = OllamaImageAnalysis.objects.filter(
            media_id__in=media_ids,
            media__user_id=user_id,
            status__in=['pending', 'processing']  # åªå¤„ç†æœªå®Œæˆçš„ä»»åŠ¡
        ).select_related('media', 'model')

        results = {}
        failed_items = []

        # æäº¤æ‰€æœ‰å›¾ç‰‡å¤„ç†ä»»åŠ¡
        submitted_futures = []
        try:
            for analysis in analyses:
                try:
                    future = self.submit_task(
                        user_id=user_id,
                        task_func=self._process_single_image_with_cancellation,
                        analysis=analysis,
                        executor_callback=executor_callback,
                        max_concurrent=max_concurrent
                    )
                    submitted_futures.append((future, analysis.media.id))
                except Exception as e:
                    failed_items.append({
                        'media_id': analysis.media.id,
                        'error': f"æäº¤ä»»åŠ¡å¤±è´¥: {str(e)}"
                    })
                    logger.error(f"âŒ å›¾ç‰‡ {analysis.media.id} ä»»åŠ¡æäº¤å¤±è´¥: {str(e)}")

            logger.info(f"ğŸ“¤ å·²æäº¤ {len(submitted_futures)} ä¸ªå›¾ç‰‡å¤„ç†ä»»åŠ¡")

            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            timeout = getattr(settings, 'OLLAMA_ANALYSIS_TIMEOUT', 300)
            for future, media_id in submitted_futures:
                try:
                    result = future.result(timeout=timeout)

                    if result['success']:
                        # ä¿®å¤ï¼šä½¿ç”¨çŠ¶æ€ç®¡ç†å™¨æ›´æ–°çŠ¶æ€
                        from .state_manager import state_manager
                        analysis = next(a for a in analyses if a.media.id == media_id)
                        
                        # å‡†å¤‡ç»“æœæ•°æ®
                        result_data = result.get('result', {})
                        
                        # åŸå­æ€§æ›´æ–°åª’ä½“ä¿¡æ¯
                        media_update_success = state_manager.update_media_with_analysis_result(
                            analysis, result_data
                        )
                        
                        if not media_update_success:
                            logger.warning(f"åª’ä½“ä¿¡æ¯æ›´æ–°å¤±è´¥ï¼Œä½†ç»§ç»­å®Œæˆä»»åŠ¡: media_id={media_id}")
                        
                        # è®¡ç®—å¤„ç†æ—¶é—´
                        processing_time_ms = result.get('processing_time_ms')
                        
                        # ç¡®ä¿å¤„ç†æ—¶é—´ä¸ä¸ºNone
                        if processing_time_ms is None:
                            processing_time_ms = 0
                            
                        # ä½¿ç”¨çŠ¶æ€ç®¡ç†å™¨æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå®Œæˆ
                        task_update_success = state_manager.update_analysis_status(
                            analysis_id=analysis.id,
                            from_status='processing',
                            to_status='completed',
                            analysis_results=result_data,
                            processing_time=processing_time_ms
                        )
                        
                        if not task_update_success:
                            # é‡æ–°è·å–åˆ†æå¯¹è±¡ä»¥è·å–æœ€æ–°çŠ¶æ€
                            from ..models import OllamaImageAnalysis
                            updated_analysis = OllamaImageAnalysis.objects.get(id=analysis.id)
                            
                            if updated_analysis.status == 'cancelled':
                                logger.warning(f"ä»»åŠ¡å·²è¢«å–æ¶ˆï¼Œæ— æ³•æ ‡è®°ä¸ºå®Œæˆ: media_id={media_id}")
                                results[media_id] = {
                                    'success': False,
                                    'status': 'cancelled',
                                    'error': 'ä»»åŠ¡å·²è¢«å–æ¶ˆ',
                                    'processing_time_s': round(processing_time_ms / 1000, 2) if processing_time_ms else None
                                }
                                continue
                            else:
                                logger.warning(f"ä»»åŠ¡çŠ¶æ€æ›´æ–°å¤±è´¥ï¼Œå½“å‰çŠ¶æ€: {updated_analysis.status}, media_id={media_id}")
                                results[media_id] = {
                                    'success': False,
                                    'status': updated_analysis.status,
                                    'error': f'çŠ¶æ€æ›´æ–°å¤±è´¥ï¼Œå½“å‰çŠ¶æ€: {updated_analysis.status}',
                                    'processing_time_s': round(processing_time_ms / 1000, 2) if processing_time_ms else None
                                }
                                continue

                        results[media_id] = {
                            'success': True,
                            'status': 'completed',
                            'processing_time_s': round(processing_time_ms / 1000, 2) if processing_time_ms else None
                        }
                    else:
                        failed_items.append({
                            'media_id': media_id,
                            'error': result.get('error', 'æœªçŸ¥é”™è¯¯')
                        })
                        # ä¿®å¤ï¼šä½¿ç”¨çŠ¶æ€ç®¡ç†å™¨æ ‡è®°å¤±è´¥
                        from .state_manager import state_manager
                        analysis = next(a for a in analyses if a.media.id == media_id)
                        
                        # ä½¿ç”¨çŠ¶æ€ç®¡ç†å™¨æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
                        task_update_success = state_manager.update_analysis_status(
                            analysis_id=analysis.id,
                            from_status=None,  # å…è®¸ä»ä»»ä½•çŠ¶æ€è½¬æ¢ä¸ºå¤±è´¥
                            to_status='failed',
                            error_message=result.get('error', 'æœªçŸ¥é”™è¯¯')
                        )
                        
                        if not task_update_success:
                            # é‡æ–°è·å–åˆ†æå¯¹è±¡ä»¥è·å–æœ€æ–°çŠ¶æ€
                            from ..models import OllamaImageAnalysis
                            updated_analysis = OllamaImageAnalysis.objects.get(id=analysis.id)
                            
                            if updated_analysis.status == 'cancelled':
                                logger.warning(f"ä»»åŠ¡å·²è¢«å–æ¶ˆï¼Œæ— æ³•æ ‡è®°ä¸ºå¤±è´¥: media_id={media_id}")
                                failed_items[-1]['error'] = "ä»»åŠ¡å·²è¢«å–æ¶ˆ"
                            else:
                                logger.warning(f"ä»»åŠ¡çŠ¶æ€æ›´æ–°å¤±è´¥ï¼Œå½“å‰çŠ¶æ€: {updated_analysis.status}, media_id={media_id}")
                                failed_items[-1]['error'] = f"çŠ¶æ€æ›´æ–°å¤±è´¥ï¼Œå½“å‰çŠ¶æ€: {updated_analysis.status}"

                except Exception as e:
                    failed_items.append({
                        'media_id': media_id,
                        'error': f"å›¾ç‰‡å¤„ç†å¼‚å¸¸: {str(e)}"
                    })
                    # ä¿®å¤ï¼šä½¿ç”¨çŠ¶æ€ç®¡ç†å™¨æ ‡è®°å¤±è´¥
                    try:
                        from .state_manager import state_manager
                        analysis = next(a for a in analyses if a.media.id == media_id)
                        
                        # ä½¿ç”¨çŠ¶æ€ç®¡ç†å™¨æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
                        state_manager.update_analysis_status(
                            analysis_id=analysis.id,
                            from_status=None,  # å…è®¸ä»ä»»ä½•çŠ¶æ€è½¬æ¢ä¸ºå¤±è´¥
                            to_status='failed',
                            error_message=str(e)
                        )
                    except:
                        pass

            logger.info(f"ğŸ“Š æ‰¹é‡å¤„ç†å®Œæˆ: æˆåŠŸ {len(results)} ä¸ªï¼Œå¤±è´¥ {len(failed_items)} ä¸ª")

        except Exception as e:
            logger.error(f"âŒ æ‰¹é‡å¤„ç†å‡ºç°ç³»ç»Ÿé”™è¯¯: {str(e)}")
            # å°è¯•å–æ¶ˆå·²æäº¤çš„ä»»åŠ¡
            for future, _ in submitted_futures:
                if not future.done():
                    future.cancel()

        return {
            'success_count': len(results),
            'error_count': len(failed_items),
            'results': results,
            'failed_items': failed_items,
            'total_processing_time_ms': 0  # è¿™é‡Œå¯ä»¥è®¡ç®—æ€»å¤„ç†æ—¶é—´
        }

    def _process_single_image_with_cancellation(self, analysis, executor_callback=None) -> Dict[str, Any]:
        """
        å¤„ç†å•å¼ å›¾ç‰‡çš„æ‰€æœ‰åˆ†æä»»åŠ¡ï¼ˆæ”¯æŒå–æ¶ˆï¼‰
        ä½¿ç”¨å¯å–æ¶ˆä»»åŠ¡æ¡†æ¶
        """
        from .prompt_templates import TaskConfig
        from .ollama_client import OllamaImageAnalyzer
        from .task_cancellation import TaskCancelledException

        start_time = time.time()

        # åˆ›å»ºå¯å–æ¶ˆä»»åŠ¡
        cancellable_task = cancellation_manager.create_task(
            f"batch_image_{analysis.media.id}_{int(time.time())}",
            analysis.media.user.id
        )

        try:
            cancellable_task.start()

            # å…³é”®ä¿®å¤ï¼šåœ¨å¼€å§‹å¤„ç†å‰æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å·²è¢«å–æ¶ˆ
            if analysis.status == 'cancelled':
                logger.info(f"ğŸš« ä»»åŠ¡å·²è¢«å–æ¶ˆï¼Œè·³è¿‡å¤„ç†: analysis_id={analysis.id}")
                return {
                    'success': False,
                    'result': {},
                    'failed_tasks': ["ä»»åŠ¡å·²è¢«å–æ¶ˆ"],
                    'total_tasks': 0,
                    'completed_tasks': 0,
                    'processing_time_ms': int((time.time() - start_time) * 1000),
                    'cancelled': True
                }

            # å…³é”®ä¿®å¤ï¼šä½¿ç”¨çŠ¶æ€ç®¡ç†å™¨å®‰å…¨åœ°æ ‡è®°ä»»åŠ¡ä¸ºå¤„ç†ä¸­çŠ¶æ€
            from .state_manager import state_manager
            status_update_success = state_manager.update_analysis_status(
                analysis_id=analysis.id,
                from_status='pending',
                to_status='processing'
            )
            
            if not status_update_success:
                # å¦‚æœçŠ¶æ€æ›´æ–°å¤±è´¥ï¼Œè¯´æ˜ä»»åŠ¡å¯èƒ½å·²è¢«å–æ¶ˆæˆ–çŠ¶æ€ä¸åŒ¹é…
                # é‡æ–°è·å–æœ€æ–°çŠ¶æ€
                from ..models import OllamaImageAnalysis
                updated_analysis = OllamaImageAnalysis.objects.get(id=analysis.id)
                
                if updated_analysis.status == 'cancelled':
                    logger.info(f"ğŸš« ä»»åŠ¡å·²è¢«å–æ¶ˆï¼Œåœæ­¢å¤„ç†: analysis_id={analysis.id}")
                    return {
                        'success': False,
                        'result': {},
                        'failed_tasks': ["ä»»åŠ¡å·²è¢«å–æ¶ˆ"],
                        'total_tasks': 0,
                        'completed_tasks': 0,
                        'processing_time_ms': int((time.time() - start_time) * 1000),
                        'cancelled': True
                    }
                else:
                    logger.warning(f"âš ï¸ ä»»åŠ¡çŠ¶æ€æ›´æ–°å¤±è´¥ï¼Œå½“å‰çŠ¶æ€: {updated_analysis.status}, analysis_id={analysis.id}")
                    return {
                        'success': False,
                        'result': {},
                        'failed_tasks': [f"ä»»åŠ¡çŠ¶æ€æ›´æ–°å¤±è´¥ï¼Œå½“å‰çŠ¶æ€: {updated_analysis.status}"],
                        'total_tasks': 0,
                        'completed_tasks': 0,
                        'processing_time_ms': int((time.time() - start_time) * 1000)
                    }
            
            logger.info(f"ğŸš€ å¼€å§‹å¤„ç†å›¾ç‰‡ {analysis.media.id}ï¼ŒçŠ¶æ€æˆåŠŸæ›´æ–°ä¸º processing")

            # æ£€æŸ¥å–æ¶ˆçŠ¶æ€
            cancellable_task.check_cancelled()

            # ä¿®å¤ï¼šä½¿ç”¨çœŸæ­£çš„Ollamaåˆ†æå™¨è€Œä¸æ˜¯æ‰‹åŠ¨æ‰§è¡Œä»»åŠ¡
            analyzer = OllamaImageAnalyzer()
            
            # æ‰§è¡ŒçœŸæ­£çš„å›¾ç‰‡åˆ†æï¼ˆæ”¯æŒå–æ¶ˆï¼‰
            result = analyzer.analyze_with_cancellation(analysis, cancellable_task)
            
            # æ£€æŸ¥å–æ¶ˆçŠ¶æ€
            cancellable_task.check_cancelled()

            if not result['success']:
                error_msg = result.get('error', 'åˆ†æå¤±è´¥')
                logger.error(f"âŒ Ollamaåˆ†æå¤±è´¥: {error_msg}")
                # ä¿®å¤ï¼šä½¿ç”¨çŠ¶æ€ç®¡ç†å™¨æ ‡è®°å¤±è´¥
                from .state_manager import state_manager
                state_manager.update_analysis_status(
                    analysis_id=analysis.id,
                    from_status='processing',
                    to_status='failed',
                    error_message=error_msg
                )
                return {
                    'success': False,
                    'result': {},
                    'failed_tasks': [error_msg],
                    'total_tasks': 0,
                    'completed_tasks': 0,
                    'processing_time_ms': int((time.time() - start_time) * 1000)
                }

            # è·å–åˆ†æç»“æœ
            results = result.get('result', {})
            failed_tasks = result.get('failed_tasks', [])
            
            # ä¿®å¤ï¼šç¡®ä¿failed_tasksä¸ä¸ºNone
            if failed_tasks is None:
                failed_tasks = []

            # æœ€ç»ˆæ£€æŸ¥å–æ¶ˆçŠ¶æ€
            cancellable_task.check_cancelled()

            processing_time = time.time() - start_time
            logger.debug(f"å›¾ç‰‡ {analysis.media.id} å¤„ç†å®Œæˆï¼Œæ€»è€—æ—¶: {processing_time:.2f}s")

            # è®¾ç½®ä»»åŠ¡ç»“æœ
            cancellable_task.set_result(results)

            return {
                'success': len(results) > 0,
                'result': results,
                'failed_tasks': failed_tasks,
                'total_tasks': len(results) + len(failed_tasks),
                'completed_tasks': len(results),
                'processing_time_ms': int(processing_time * 1000)
            }

        except TaskCancelledException:
            logger.info(f"ğŸš« å›¾ç‰‡ {analysis.media.id} å¤„ç†è¢«å–æ¶ˆ")
            # ä¿®å¤ï¼šä½¿ç”¨çŠ¶æ€ç®¡ç†å™¨æ ‡è®°å–æ¶ˆ
            from .state_manager import state_manager
            state_manager.update_analysis_status(
                analysis_id=analysis.id,
                from_status=None,  # å…è®¸ä»ä»»ä½•çŠ¶æ€è½¬æ¢ä¸ºå–æ¶ˆ
                to_status='cancelled',
                error_message="ä»»åŠ¡å·²è¢«å–æ¶ˆ"
            )
            return {
                'success': False,
                'result': {},
                'failed_tasks': ["ä»»åŠ¡å·²è¢«å–æ¶ˆ"],
                'total_tasks': 0,
                'completed_tasks': 0,
                'processing_time_ms': int((time.time() - start_time) * 1000),
                'cancelled': True
            }
        except Exception as e:
            logger.error(f"âŒ å›¾ç‰‡ {analysis.media.id} å¤„ç†å¼‚å¸¸: {str(e)}")
            # ä¿®å¤ï¼šä½¿ç”¨çŠ¶æ€ç®¡ç†å™¨æ ‡è®°å¤±è´¥
            try:
                from .state_manager import state_manager
                state_manager.update_analysis_status(
                    analysis_id=analysis.id,
                    from_status=None,  # å…è®¸ä»ä»»ä½•çŠ¶æ€è½¬æ¢ä¸ºå¤±è´¥
                    to_status='failed',
                    error_message=str(e)
                )
            except:
                pass

            return {
                'success': False,
                'result': {},
                'failed_tasks': [f"å¤„ç†å¼‚å¸¸: {str(e)}"],
                'total_tasks': 0,
                'completed_tasks': 0,
                'processing_time_ms': int((time.time() - start_time) * 1000)
            }
        finally:
            # æ¸…ç†ä»»åŠ¡
            cancellation_manager.remove_task(cancellable_task.task_id)

    def __del__(self):
        """ææ„å‡½æ•°"""
        try:
            self.shutdown()
        except:
            pass


# å…¨å±€å¹¶å‘ç®¡ç†å™¨å®ä¾‹
concurrency_manager = ConcurrencyManager()