"""
æ”¹è¿›çš„å¹¶å‘åˆ†æç®¡ç†å™¨ - ç®€åŒ–ç‰ˆ
åªè´Ÿè´£å›¾ç‰‡çº§å¹¶å‘ï¼Œå›¾ç‰‡å†…å¹¶è¡Œç”±analyzerå¤„ç†
"""

import asyncio
import logging
import time
import threading
from typing import Dict, Any, List
from concurrent.futures import ThreadPoolExecutor
from django.conf import settings

logger = logging.getLogger(__name__)


class SimplifiedConcurrencyManager:
    """ç®€åŒ–ç‰ˆå¹¶å‘ç®¡ç†å™¨ - åªæ§åˆ¶å›¾ç‰‡çº§å¹¶å‘"""

    def __init__(self):
        # å…¨å±€çº¿ç¨‹æ± ï¼Œæ›¿ä»£å¤æ‚çš„ç”¨æˆ·çº§çº¿ç¨‹æ± 
        self.executor = ThreadPoolExecutor(
            max_workers=getattr(settings, 'OLLAMA_GLOBAL_MAX_CONCURRENT', 10),
            thread_name_prefix="ollama_worker"
        )

        # æ´»è·ƒä»»åŠ¡è·Ÿè¸ª
        self.active_tasks = {}
        self._lock = threading.RLock()

        logger.info("ğŸ”§ ç®€åŒ–ç‰ˆå¹¶å‘ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")

    def process_batch_images(self, user_id, media_ids, model_name, analysis_options, executor_callback=None):
        """
        æ‰¹é‡å¤„ç†å›¾ç‰‡ - ç®€åŒ–ç‰ˆ
        ä½¿ç”¨å…¨å±€çº¿ç¨‹æ± ï¼Œæ¯å¼ å›¾ç‰‡ç‹¬ç«‹å¤„ç†
        """
        from ..models import OllamaImageAnalysis

        logger.info(f"ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç†: {len(media_ids)} ä¸ªå›¾ç‰‡ï¼Œç”¨æˆ· {user_id}")

        # è·å–æ‰€æœ‰åˆ†æå¯¹è±¡
        analyses = OllamaImageAnalysis.objects.filter(
            media_id__in=media_ids,
            media__user_id=user_id,
            status__in=['pending', 'processing']
        ).select_related('media', 'model')

        results = {}
        failed_items = []
        futures = []

        # æäº¤æ‰€æœ‰ä»»åŠ¡åˆ°çº¿ç¨‹æ± 
        for analysis in analyses:
            try:
                future = self.executor.submit(
                    self._process_single_image_simplified,
                    analysis
                )
                futures.append((future, analysis.media.id))

                with self._lock:
                    self.active_tasks[future] = {
                        'user_id': user_id,
                        'media_id': analysis.media.id
                    }

            except Exception as e:
                failed_items.append({
                    'media_id': analysis.media.id,
                    'error': f"æäº¤ä»»åŠ¡å¤±è´¥: {str(e)}"
                })

        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        for future, media_id in futures:
            try:
                result = future.result(timeout=getattr(settings, 'OLLAMA_ANALYSIS_TIMEOUT', 300))

                if result['success']:
                    results[media_id] = {
                        'success': True,
                        'status': 'completed'
                    }
                else:
                    failed_items.append({
                        'media_id': media_id,
                        'error': result.get('error', 'æœªçŸ¥é”™è¯¯')
                    })

            except Exception as e:
                failed_items.append({
                    'media_id': media_id,
                    'error': f"ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {str(e)}"
                })

            finally:
                with self._lock:
                    self.active_tasks.pop(future, None)

        logger.info(f"ğŸ“Š æ‰¹é‡å¤„ç†å®Œæˆ: æˆåŠŸ {len(results)} ä¸ªï¼Œå¤±è´¥ {len(failed_items)} ä¸ª")

        return {
            'success_count': len(results),
            'error_count': len(failed_items),
            'results': results,
            'failed_items': failed_items
        }

    def _process_single_image_simplified(self, analysis):
        """
        å¤„ç†å•å¼ å›¾ç‰‡ - ç®€åŒ–ç‰ˆ
        ä½¿ç”¨å¢å¼ºç‰ˆåˆ†æå™¨çš„å¹¶è¡Œå¤„ç†
        """
        from .state_manager import state_manager
        from .ollama_client import OllamaImageAnalyzer

        try:
            # æ›´æ–°çŠ¶æ€ä¸ºå¤„ç†ä¸­
            state_manager.update_analysis_status(
                analysis_id=analysis.id,
                from_status='pending',
                to_status='processing'
            )

            # ä½¿ç”¨å¢å¼ºç‰ˆåˆ†æå™¨ï¼ˆå¹¶è¡Œå¤„ç†ï¼‰
            analyzer = OllamaImageAnalyzer()
            result = analyzer.analyze_parallel(analysis)

            if result['success']:
                # æ›´æ–°åª’ä½“ä¿¡æ¯
                state_manager.update_media_with_analysis_result(
                    analysis, result['result']
                )

                # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                state_manager.update_analysis_status(
                    analysis_id=analysis.id,
                    from_status='processing',
                    to_status='completed',
                    analysis_results=result['result'],
                    processing_time=result.get('processing_time_ms')
                )

                return {
                    'success': True,
                    'media_id': analysis.media.id,
                    'result': result['result']
                }
            else:
                # æ ‡è®°å¤±è´¥
                state_manager.update_analysis_status(
                    analysis_id=analysis.id,
                    from_status='processing',
                    to_status='failed',
                    error_message=result.get('error', 'åˆ†æå¤±è´¥')
                )

                return {
                    'success': False,
                    'media_id': analysis.media.id,
                    'error': result.get('error', 'åˆ†æå¤±è´¥')
                }

        except Exception as e:
            logger.error(f"âŒ å¤„ç†å›¾ç‰‡å¤±è´¥: media_id={analysis.media.id}, error={str(e)}")

            # ç¡®ä¿ä»»åŠ¡è¢«æ ‡è®°ä¸ºå¤±è´¥
            try:
                state_manager.update_analysis_status(
                    analysis_id=analysis.id,
                    from_status=None,
                    to_status='failed',
                    error_message=str(e)
                )
            except:
                pass

            return {
                'success': False,
                'media_id': analysis.media.id,
                'error': str(e)
            }

    def cancel_user_tasks(self, user_id: int) -> Dict[str, Any]:
        """å–æ¶ˆç”¨æˆ·çš„æ‰€æœ‰ä»»åŠ¡"""
        cancelled_count = 0

        with self._lock:
            # æ‰¾åˆ°è¯¥ç”¨æˆ·çš„æ‰€æœ‰æ´»åŠ¨ä»»åŠ¡
            user_futures = [
                future for future, info in self.active_tasks.items()
                if info['user_id'] == user_id
            ]

            # å°è¯•å–æ¶ˆæœªå¼€å§‹çš„ä»»åŠ¡
            for future in user_futures:
                if not future.running():
                    if future.cancel():
                        cancelled_count += 1

        # ç®€åŒ–ç‰ˆå–æ¶ˆé€»è¾‘ - åªéœ€è¦æ ‡è®°æ•°æ®åº“ä¸­çš„ä»»åŠ¡çŠ¶æ€
        pass

        logger.info(f"ğŸš« ç”¨æˆ· {user_id} ä»»åŠ¡å–æ¶ˆå®Œæˆ: {cancelled_count} ä¸ª")

        return {
            'cancelled_count': cancelled_count
        }

    def get_active_tasks_info(self) -> Dict[str, Any]:
        """è·å–å½“å‰æ´»è·ƒä»»åŠ¡ä¿¡æ¯"""
        with self._lock:
            user_task_counts = {}
            for info in self.active_tasks.values():
                user_id = info['user_id']
                user_task_counts[user_id] = user_task_counts.get(user_id, 0) + 1

            return {
                'total_active_tasks': len(self.active_tasks),
                'user_task_counts': user_task_counts,
                'max_workers': self.executor._max_workers
            }

    def shutdown(self):
        """å…³é—­ç®¡ç†å™¨"""
        logger.info("ğŸ›‘ å…³é—­ç®€åŒ–ç‰ˆå¹¶å‘ç®¡ç†å™¨...")
        self.executor.shutdown(wait=False)
        logger.info("âœ… ç®€åŒ–ç‰ˆå¹¶å‘ç®¡ç†å™¨å·²å…³é—­")


# æ›¿æ¢å…¨å±€å®ä¾‹
concurrency_manager = SimplifiedConcurrencyManager()