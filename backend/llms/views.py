import logging
from django.shortcuts import get_object_or_404
from django.db import transaction
from rest_framework import status, permissions, viewsets
from rest_framework.decorators import action
from rest_framework.parsers import MultiPartParser, FormParser

from .models import AIAnalysis, AIModel, OllamaEndpoint
from .services import OllamaClient, OllamaAPIError
from .serializers import (
    AIAnalysisSerializer, AIAnalysisListSerializer,
    AIModelSerializer, OllamaEndpointSerializer, OllamaEndpointCreateSerializer,
    SingleAnalysisRequestSerializer
)
from media.models import Media, Category, Tag
from utils.responses import (
    success_response,
    error_response,
    not_found_response,
    paginated_response
)

logger = logging.getLogger(__name__)


class OllamaEndpointViewSet(viewsets.ModelViewSet):
    """Ollamaç«¯ç‚¹ç®¡ç† ViewSet"""
    permission_classes = [permissions.IsAuthenticated]
    queryset = OllamaEndpoint.objects.all()

    def get_serializer_class(self):
        """æ ¹æ® action é€‰æ‹©åºåˆ—åŒ–å™¨"""
        if self.action == 'create':
            return OllamaEndpointCreateSerializer
        return OllamaEndpointSerializer

    def get_queryset(self):
        """è·å–ç«¯ç‚¹åˆ—è¡¨"""
        return OllamaEndpoint.objects.all()

    def list(self, request):
        """è·å–ç«¯ç‚¹åˆ—è¡¨"""
        queryset = self.get_queryset()
        serializer = self.get_serializer(queryset, many=True)
        return success_response(
            data={
                'endpoints': serializer.data,
                'total': len(queryset)
            },
            message='è·å–ç«¯ç‚¹åˆ—è¡¨æˆåŠŸ'
        )

    def create(self, request):
        """åˆ›å»ºæ–°ç«¯ç‚¹"""
        serializer = self.get_serializer(data=request.data)
        serializer.is_valid(raise_exception=True)

        try:
            endpoint = serializer.save(created_by=request.user)
            response_serializer = OllamaEndpointSerializer(endpoint)
            return success_response(
                data=response_serializer.data,
                message='ç«¯ç‚¹åˆ›å»ºæˆåŠŸ',
                status_code=status.HTTP_201_CREATED
            )
        except Exception as e:
            logger.error(f"åˆ›å»ºç«¯ç‚¹å¤±è´¥: {str(e)}")
            return error_response(
                message='åˆ›å»ºç«¯ç‚¹å¤±è´¥',
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR
            )

    def retrieve(self, request, pk=None):
        """è·å–ç«¯ç‚¹è¯¦æƒ…"""
        try:
            endpoint = self.get_queryset().get(pk=pk)
        except OllamaEndpoint.DoesNotExist:
            return not_found_response('ç«¯ç‚¹')

        serializer = self.get_serializer(endpoint)
        return success_response(
            data=serializer.data,
            message='è·å–ç«¯ç‚¹è¯¦æƒ…æˆåŠŸ'
        )

    def update(self, request, pk=None):
        """æ›´æ–°ç«¯ç‚¹"""
        try:
            endpoint = self.get_queryset().get(pk=pk)
        except OllamaEndpoint.DoesNotExist:
            return not_found_response('ç«¯ç‚¹')

        # åªå…è®¸åˆ›å»ºè€…æˆ–è¶…çº§ç”¨æˆ·ä¿®æ”¹
        if endpoint.created_by != request.user and not request.user.is_superuser:
            return error_response(
                message='åªæœ‰åˆ›å»ºè€…å¯ä»¥ä¿®æ”¹ç«¯ç‚¹é…ç½®',
                status_code=status.HTTP_403_FORBIDDEN
            )

        serializer = OllamaEndpointSerializer(endpoint, data=request.data, partial=True)
        serializer.is_valid(raise_exception=True)

        try:
            serializer.save()
            return success_response(
                data=serializer.data,
                message='ç«¯ç‚¹æ›´æ–°æˆåŠŸ'
            )
        except Exception as e:
            logger.error(f"æ›´æ–°ç«¯ç‚¹å¤±è´¥: {str(e)}")
            return error_response(
                message='æ›´æ–°ç«¯ç‚¹å¤±è´¥',
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR
            )

    def partial_update(self, request, pk=None):
        """éƒ¨åˆ†æ›´æ–°ç«¯ç‚¹"""
        return self.update(request, pk)  # å¤ç”¨updateæ–¹æ³•çš„é€»è¾‘

    def destroy(self, request, pk=None):
        """åˆ é™¤ç«¯ç‚¹"""
        try:
            endpoint = self.get_queryset().get(pk=pk)
        except OllamaEndpoint.DoesNotExist:
            return not_found_response('ç«¯ç‚¹')

        # åªå…è®¸åˆ›å»ºè€…æˆ–è¶…çº§ç”¨æˆ·åˆ é™¤
        if endpoint.created_by != request.user and not request.user.is_superuser:
            return error_response(
                message='åªæœ‰åˆ›å»ºè€…å¯ä»¥åˆ é™¤ç«¯ç‚¹',
                status_code=status.HTTP_403_FORBIDDEN
            )

        try:
            endpoint.delete()
            return success_response(
                message='ç«¯ç‚¹åˆ é™¤æˆåŠŸ'
            )
        except Exception as e:
            logger.error(f"åˆ é™¤ç«¯ç‚¹å¤±è´¥: {str(e)}")
            return error_response(
                message='åˆ é™¤ç«¯ç‚¹å¤±è´¥',
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR
            )

    @action(detail=True, methods=['get'])
    def test(self, request, pk=None):
        """æµ‹è¯•ç«¯ç‚¹è¿æ¥"""
        try:
            endpoint = self.get_queryset().get(pk=pk)
            result = endpoint.test_connection()

            if result['success']:
                return success_response(
                    data={
                        'status': 'success',
                        'message': 'è¿æ¥æˆåŠŸ',
                        'models_count': result['models_count'],
                        'models': result['models']
                    },
                    message='ç«¯ç‚¹è¿æ¥æµ‹è¯•æˆåŠŸ'
                )
            else:
                return error_response(
                    message=f'è¿æ¥å¤±è´¥: {result["error"]}',
                    status_code=status.HTTP_400_BAD_REQUEST
                )

        except OllamaEndpoint.DoesNotExist:
            return not_found_response('ç«¯ç‚¹')
        except Exception as e:
            logger.error(f"æµ‹è¯•ç«¯ç‚¹è¿æ¥å¤±è´¥: {str(e)}")
            return error_response(
                message=f'æµ‹è¯•è¿æ¥å¤±è´¥: {str(e)}',
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR
            )


class AIModelViewSet(viewsets.ReadOnlyModelViewSet):
    """AIæ¨¡å‹ç®¡ç† ViewSet"""
    permission_classes = [permissions.IsAuthenticated]
    queryset = AIModel.objects.all()
    serializer_class = AIModelSerializer

    def get_queryset(self):
        """è·å–æ´»è·ƒçš„è§†è§‰æ¨¡å‹"""
        return AIModel.get_active_vision_models()

    def list(self, request):
        """è·å–å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨"""
        # ä»ç”¨æˆ·é…ç½®çš„æ´»è·ƒç«¯ç‚¹åŠ¨æ€è·å–æ¨¡å‹
        from .services import OllamaClient

        models_data = []

        # æ”¯æŒæŒ‰ç«¯ç‚¹ç­›é€‰
        endpoint_id = request.query_params.get('endpoint_id')
        if endpoint_id:
            # åªè·å–æŒ‡å®šç«¯ç‚¹çš„æ¨¡å‹
            try:
                endpoints = OllamaEndpoint.objects.filter(id=endpoint_id, is_active=True)
                if not endpoints.exists():
                    return error_response(
                        message=f'ç«¯ç‚¹ ID {endpoint_id} ä¸å­˜åœ¨æˆ–æœªæ¿€æ´»',
                        status_code=status.HTTP_404_NOT_FOUND
                    )
            except ValueError:
                return error_response(
                    message='æ— æ•ˆçš„ç«¯ç‚¹IDæ ¼å¼',
                    status_code=status.HTTP_400_BAD_REQUEST
                )
        else:
            # è·å–æ‰€æœ‰æ´»è·ƒç«¯ç‚¹
            endpoints = OllamaEndpoint.objects.filter(is_active=True)

        for endpoint in endpoints:
            try:
                # ä¸ºæ¯ä¸ªç«¯ç‚¹åˆ›å»ºå®¢æˆ·ç«¯
                client = OllamaClient(base_url=endpoint.url, timeout=endpoint.timeout)

                # è·å–è¯¥ç«¯ç‚¹çš„æ¨¡å‹åˆ—è¡¨
                endpoint_models = client.list_models()

                for model_data in endpoint_models:
                    model_name = model_data.get('name', '')
                    details = model_data.get('details', {})
                    families = details.get('families', [])

                    # æ£€æŸ¥æ˜¯å¦ä¸ºè§†è§‰æ¨¡å‹
                    is_vision_capable = any(
                        family in ['qwen3vl', 'clip', 'llava', 'minicpm', 'vision']
                        for family in families
                    ) or ('vl' in model_name.lower() or 'vision' in model_name.lower() or
                          'qwen3-vl' in model_name.lower() or 'minicpm-v' in model_name.lower())

                    if is_vision_capable:
                        size_bytes = model_data.get('size', 0)
                        size_gb = round(size_bytes / (1024**3), 2) if size_bytes > 0 else None

                        models_data.append({
                            'name': model_name,
                            'display_name': model_name.replace('/', ' - ').title(),
                            'description': f"è§†è§‰æ¨¡å‹ - å‚æ•°è§„æ¨¡: {details.get('parameter_size', 'Unknown')}",
                            'endpoint': endpoint.id,
                            'endpoint_name': endpoint.name,
                            'endpoint_url': endpoint.url,
                            'is_active': True,
                            'is_vision_capable': True,
                            'is_default': False,  # è¿™é‡Œå¯ä»¥é€šè¿‡æ£€æŸ¥æ•°æ®åº“è·å–çœŸå®çš„é»˜è®¤çŠ¶æ€
                            'model_size': f"{size_gb}GB" if size_gb else None,
                            'parameter_size': details.get('parameter_size', 'Unknown'),
                            'families': families,
                            'digest': model_data.get('digest', ''),
                            'modified_at': model_data.get('modified_at', '')
                        })

            except Exception as e:
                logger.error(f"è·å–ç«¯ç‚¹ {endpoint.name} çš„æ¨¡å‹å¤±è´¥: {str(e)}")
                continue

        # è·å–é»˜è®¤æ¨¡å‹åç§°
        default_model = AIModel.get_default_model()
        default_model_name = default_model.name if default_model else None

        # å¦‚æœæœ‰é»˜è®¤æ¨¡å‹ï¼Œå°†å…¶æ ‡è®°ä¸ºé»˜è®¤
        if default_model_name:
            for model in models_data:
                if model['name'] == default_model_name and model['endpoint'] == default_model.endpoint.id:
                    model['is_default'] = True

        # æŒ‰æ¨¡å‹å¤§å°æ’åºï¼ˆé™åºï¼š4Bæ’åœ¨2Bå‰é¢ï¼‰ï¼Œç„¶åæŒ‰åç§°æ’åº
        def model_size_sort_key(model):
            # æå–æ¨¡å‹å¤§å°ä¸­çš„æ•°å­—ï¼ˆå¦‚ä» "4.7GB" ä¸­æå– 4.7ï¼‰
            import re
            size_str = model.get('model_size', '')
            if size_str:
                # æŸ¥æ‰¾æ•°å­—ï¼ˆå¯èƒ½åŒ…å«å°æ•°ç‚¹ï¼‰
                size_match = re.search(r'(\d+\.?\d*)', size_str)
                if size_match:
                    size_num = float(size_match.group(1))
                    # è¿”å›è´Ÿæ•°ä»¥å®ç°é™åºæ’åº
                    return -size_num

            # å¦‚æœæ²¡æœ‰å¤§å°ä¿¡æ¯ï¼Œä»æ¨¡å‹åç§°ä¸­æå–
            name = model.get('name', '').lower()
            if '4b' in name:
                return -4.0
            elif '2b' in name:
                return -2.0
            elif '8b' in name:
                return -8.0
            elif '1b' in name:
                return -1.0

            # é»˜è®¤æƒ…å†µï¼ŒæŒ‰åç§°æ’åº
            return -1000  # æ”¾åœ¨æœ€å

        # å¯¹æ¨¡å‹è¿›è¡Œæ’åº
        models_data.sort(key=model_size_sort_key)

        return success_response(
            data={
                'models': models_data,
                'total': len(models_data),
                'default_model': default_model_name,
                'endpoints_count': endpoints.count()
            },
            message='è·å–å¯ç”¨æ¨¡å‹æˆåŠŸ'
        )

    def list_default(self, request):
        """è·å–é»˜è®¤ç«¯ç‚¹çš„æ¨¡å‹åˆ—è¡¨"""
        from .services import OllamaClient

        models_data = []

        # è·å–é»˜è®¤ç«¯ç‚¹
        try:
            default_endpoint = OllamaEndpoint.objects.get(is_default=True, is_active=True)
        except OllamaEndpoint.DoesNotExist:
            return error_response(
                message='æ²¡æœ‰æ‰¾åˆ°é»˜è®¤çš„æ´»è·ƒç«¯ç‚¹',
                status_code=status.HTTP_404_NOT_FOUND
            )

        try:
            # ä¸ºé»˜è®¤ç«¯ç‚¹åˆ›å»ºå®¢æˆ·ç«¯
            client = OllamaClient(base_url=default_endpoint.url, timeout=default_endpoint.timeout)

            # è·å–é»˜è®¤ç«¯ç‚¹çš„æ¨¡å‹åˆ—è¡¨
            endpoint_models = client.list_models()

            for model_data in endpoint_models:
                model_name = model_data.get('name', '')
                details = model_data.get('details', {})
                families = details.get('families', [])

                # æ£€æŸ¥æ˜¯å¦ä¸ºè§†è§‰æ¨¡å‹
                is_vision_capable = any(
                    family in ['qwen3vl', 'clip', 'llava', 'minicpm', 'vision']
                    for family in families
                ) or ('vl' in model_name.lower() or 'vision' in model_name.lower() or
                      'qwen3-vl' in model_name.lower() or 'minicpm-v' in model_name.lower())

                if is_vision_capable:
                    size_bytes = model_data.get('size', 0)
                    size_gb = round(size_bytes / (1024**3), 2) if size_bytes > 0 else None

                    models_data.append({
                        'id': len(models_data) + 1,  # ç”Ÿæˆä¸´æ—¶ID
                        'name': model_name,
                        'display_name': model_name.replace('/', ' - ').title(),
                        'description': f"è§†è§‰æ¨¡å‹ - å‚æ•°è§„æ¨¡: {details.get('parameter_size', 'Unknown')}",
                        'endpoint_id': default_endpoint.id,
                        'endpoint_name': default_endpoint.name,
                        'endpoint_url': default_endpoint.url,
                        'is_active': True,
                        'is_vision_capable': True,
                        'is_default': False,  # è¿™é‡Œå¯ä»¥é€šè¿‡æ£€æŸ¥æ•°æ®åº“è·å–çœŸå®çš„é»˜è®¤çŠ¶æ€
                        'model_size': f"{size_gb}GB" if size_gb else None,
                        'parameter_size': details.get('parameter_size', 'Unknown'),
                        'families': families,
                        'digest': model_data.get('digest', ''),
                        'modified_at': model_data.get('modified_at', '')
                    })

        except Exception as e:
            logger.error(f"è·å–é»˜è®¤ç«¯ç‚¹ {default_endpoint.name} çš„æ¨¡å‹å¤±è´¥: {str(e)}")
            return error_response(
                message=f'è·å–é»˜è®¤ç«¯ç‚¹æ¨¡å‹å¤±è´¥: {str(e)}',
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR
            )

        # è·å–é»˜è®¤æ¨¡å‹åç§°
        default_model = AIModel.get_default_model()
        default_model_name = default_model.name if default_model else None

        # å¦‚æœæœ‰é»˜è®¤æ¨¡å‹ï¼Œå°†å…¶æ ‡è®°ä¸ºé»˜è®¤
        if default_model_name:
            for model in models_data:
                if model['name'] == default_model_name and model['endpoint_id'] == default_model.endpoint.id:
                    model['is_default'] = True

        # æŒ‰æ¨¡å‹å¤§å°æ’åº
        def model_size_sort_key(model):
            # æå–æ¨¡å‹å¤§å°ä¸­çš„æ•°å­—
            import re
            size_str = model.get('model_size', '')
            if size_str:
                size_match = re.search(r'(\d+\.?\d*)', size_str)
                if size_match:
                    size_num = float(size_match.group(1))
                    return -size_num

            # å¦‚æœæ²¡æœ‰å¤§å°ä¿¡æ¯ï¼Œä»æ¨¡å‹åç§°ä¸­æå–
            name = model.get('name', '').lower()
            if '4b' in name:
                return -4.0
            elif '2b' in name:
                return -2.0
            elif '8b' in name:
                return -8.0
            elif '1b' in name:
                return -1.0

            return -1000  # æ”¾åœ¨æœ€å

        # å¯¹æ¨¡å‹è¿›è¡Œæ’åº
        models_data.sort(key=model_size_sort_key)

        return success_response(
            data={
                'models': models_data,
                'total': len(models_data),
                'default_model': default_model_name,
                'default_endpoint': {
                    'id': default_endpoint.id,
                    'name': default_endpoint.name,
                    'url': default_endpoint.url
                }
            },
            message='è·å–é»˜è®¤ç«¯ç‚¹æ¨¡å‹æˆåŠŸ'
        )

    def retrieve(self, request, pk=None):
        """è·å–æ¨¡å‹è¯¦æƒ…"""
        # å°è¯•å…ˆä»æ•°æ®åº“ä¸­æŸ¥æ‰¾
        try:
            db_model = self.get_queryset().get(pk=pk)
            serializer = self.get_serializer(db_model)
            return success_response(
                data=serializer.data,
                message='è·å–æ¨¡å‹è¯¦æƒ…æˆåŠŸ'
            )
        except AIModel.DoesNotExist:
            # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰ï¼Œä»åŠ¨æ€è·å–çš„æ¨¡å‹åˆ—è¡¨ä¸­æŸ¥æ‰¾
            try:
                pk = int(pk)
                # è·å–åŠ¨æ€æ¨¡å‹åˆ—è¡¨
                from .services import OllamaClient

                models_data = []
                endpoints = OllamaEndpoint.objects.filter(is_active=True)

                for endpoint in endpoints:
                    try:
                        client = OllamaClient(base_url=endpoint.url, timeout=endpoint.timeout)
                        endpoint_models = client.list_models()

                        for model_data in endpoint_models:
                            model_name = model_data.get('name', '')
                            details = model_data.get('details', {})
                            families = details.get('families', [])

                            # æ£€æŸ¥æ˜¯å¦ä¸ºè§†è§‰æ¨¡å‹
                            is_vision_capable = any(
                                family in ['qwen3vl', 'clip', 'llava', 'minicpm', 'vision']
                                for family in families
                            ) or ('vl' in model_name.lower() or 'vision' in model_name.lower() or
                                  'qwen3-vl' in model_name.lower() or 'minicpm-v' in model_name.lower())

                            if is_vision_capable:
                                size_bytes = model_data.get('size', 0)
                                size_gb = round(size_bytes / (1024**3), 2) if size_bytes > 0 else None

                                models_data.append({
                                    'id': len(models_data) + 1,  # ç”Ÿæˆä¸´æ—¶ID
                                    'name': model_name,
                                    'display_name': model_name.replace('/', ' - ').title(),
                                    'description': f"è§†è§‰æ¨¡å‹ - å‚æ•°è§„æ¨¡: {details.get('parameter_size', 'Unknown')}",
                                    'endpoint': endpoint.id,
                                    'endpoint_name': endpoint.name,
                                    'endpoint_url': endpoint.url,
                                    'is_active': True,
                                    'is_vision_capable': True,
                                    'is_default': False,
                                    'model_size': f"{size_gb}GB" if size_gb else None,
                                    'parameter_size': details.get('parameter_size', 'Unknown'),
                                    'families': families,
                                    'digest': model_data.get('digest', ''),
                                    'modified_at': model_data.get('modified_at', '')
                                })
                    except Exception as e:
                        logger.error(f"è·å–ç«¯ç‚¹ {endpoint.name} çš„æ¨¡å‹å¤±è´¥: {str(e)}")
                        continue

                # æŸ¥æ‰¾æŒ‡å®šIDçš„æ¨¡å‹ï¼ˆè¿™é‡Œä½¿ç”¨åˆ—è¡¨ç´¢å¼•+1ä½œä¸ºIDï¼‰
                if 1 <= pk <= len(models_data):
                    model = models_data[pk - 1]

                    # è·å–é»˜è®¤æ¨¡å‹ä¿¡æ¯
                    default_model = AIModel.get_default_model()
                    default_model_name = default_model.name if default_model else None

                    if default_model_name:
                        model['is_default'] = (model['name'] == default_model_name and
                                               model['endpoint'] == default_model.endpoint.id)

                    return success_response(
                        data=model,
                        message='è·å–æ¨¡å‹è¯¦æƒ…æˆåŠŸ'
                    )
                else:
                    return not_found_response('AIæ¨¡å‹')

            except Exception as e:
                logger.error(f"åŠ¨æ€è·å–æ¨¡å‹è¯¦æƒ…å¤±è´¥: {str(e)}")
                return not_found_response('AIæ¨¡å‹')

    @action(detail=False, methods=['post'])
    def refresh(self, request):
        """åˆ·æ–°æ¨¡å‹åˆ—è¡¨"""
        try:
            endpoint_id = request.data.get('endpoint_id')

            if endpoint_id:
                # åˆ·æ–°ç‰¹å®šç«¯ç‚¹çš„æ¨¡å‹
                try:
                    endpoint = OllamaEndpoint.objects.get(id=endpoint_id)
                    client = OllamaClient(base_url=endpoint.url, timeout=endpoint.timeout)
                except OllamaEndpoint.DoesNotExist:
                    return error_response(
                        message=f'ç«¯ç‚¹ ID {endpoint_id} ä¸å­˜åœ¨',
                        status_code=status.HTTP_404_NOT_FOUND
                    )
            else:
                # åˆ·æ–°æ‰€æœ‰ç«¯ç‚¹çš„æ¨¡å‹
                endpoints = OllamaEndpoint.objects.filter(is_active=True)

                # å¦‚æœæ²¡æœ‰ç«¯ç‚¹ï¼Œåˆ›å»ºä¸€ä¸ªé»˜è®¤ç«¯ç‚¹
                if not endpoints.exists():
                    try:
                        endpoint, created = OllamaEndpoint.objects.get_or_create(
                            name='é»˜è®¤Ollamaç«¯ç‚¹',
                            defaults={
                                'url': 'http://115.190.140.100:31434',
                                'description': 'é»˜è®¤çš„OllamaæœåŠ¡ç«¯ç‚¹',
                                'is_active': True,
                                'is_default': True,
                                'timeout': 300,
                                'created_by': request.user
                            }
                        )
                        endpoints = OllamaEndpoint.objects.filter(is_active=True)
                        logger.info(f"åˆ›å»ºäº†é»˜è®¤ç«¯ç‚¹: {endpoint.name}")
                    except Exception as e:
                        logger.error(f"åˆ›å»ºé»˜è®¤ç«¯ç‚¹å¤±è´¥: {str(e)}")
                        return error_response(
                            message=f'æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„ç«¯ç‚¹ï¼Œä¸”åˆ›å»ºé»˜è®¤ç«¯ç‚¹å¤±è´¥: {str(e)}',
                            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR
                        )

                synced_count = 0

                for endpoint in endpoints:
                    try:
                        client = OllamaClient(base_url=endpoint.url, timeout=endpoint.timeout)
                        models_data = client.list_models()

                        for model_data in models_data:
                            model_name = model_data.get('name', '')
                            details = model_data.get('details', {})
                            families = details.get('families', [])

                            # æ£€æŸ¥æ˜¯å¦ä¸ºè§†è§‰æ¨¡å‹
                            is_vision_capable = any(
                                family in ['qwen3vl', 'clip', 'llava', 'minicpm', 'vision']
                                for family in families
                            ) or ('vl' in model_name.lower() or 'vision' in model_name.lower() or
                                  'qwen3-vl' in model_name.lower() or 'minicpm-v' in model_name.lower())

                            if is_vision_capable:
                                size_bytes = model_data.get('size', 0)
                                size_gb = round(size_bytes / (1024**3), 2) if size_bytes > 0 else None

                                AIModel.objects.update_or_create(
                                    name=model_name,
                                    endpoint=endpoint,
                                    defaults={
                                        'display_name': model_name.replace('/', ' - ').title(),
                                        'description': f"è§†è§‰æ¨¡å‹ - å‚æ•°è§„æ¨¡: {details.get('parameter_size', 'Unknown')}",
                                        'is_active': True,
                                        'is_vision_capable': True,
                                        'model_size': f"{size_gb}GB" if size_gb else None
                                    }
                                )
                                synced_count += 1

                    except Exception as e:
                        logger.error(f"åˆ·æ–°ç«¯ç‚¹ {endpoint.name} å¤±è´¥: {str(e)}")
                        continue

                return success_response(
                    data={
                        'message': 'æ¨¡å‹åˆ·æ–°å®Œæˆ',
                        'synced': synced_count
                    },
                    message='æ¨¡å‹åˆ·æ–°å®Œæˆ'
                )

            return success_response(
                message='æ¨¡å‹åˆ·æ–°æˆåŠŸ'
            )

        except Exception as e:
            logger.error(f"åˆ·æ–°æ¨¡å‹å¤±è´¥: {str(e)}")
            return error_response(
                message=f'åˆ·æ–°æ¨¡å‹å¤±è´¥: {str(e)}',
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR
            )

    @action(detail=True, methods=['get'])
    def test(self, request, pk=None):
        """æµ‹è¯•æŒ‡å®šæ¨¡å‹è¿æ¥"""
        # å°è¯•å…ˆä»æ•°æ®åº“ä¸­æŸ¥æ‰¾
        try:
            db_model = self.get_queryset().get(pk=pk)
            model_name = db_model.name
            endpoint = db_model.endpoint
        except AIModel.DoesNotExist:
            # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰ï¼Œä»åŠ¨æ€è·å–çš„æ¨¡å‹åˆ—è¡¨ä¸­æŸ¥æ‰¾
            try:
                pk = int(pk)
                from .services import OllamaClient

                models_data = []
                endpoints = OllamaEndpoint.objects.filter(is_active=True)

                for endpoint in endpoints:
                    try:
                        client = OllamaClient(base_url=endpoint.url, timeout=endpoint.timeout)
                        endpoint_models = client.list_models()

                        for model_data in endpoint_models:
                            model_name = model_data.get('name', '')
                            details = model_data.get('details', {})
                            families = details.get('families', [])

                            # æ£€æŸ¥æ˜¯å¦ä¸ºè§†è§‰æ¨¡å‹
                            is_vision_capable = any(
                                family in ['qwen3vl', 'clip', 'llava', 'minicpm', 'vision']
                                for family in families
                            ) or ('vl' in model_name.lower() or 'vision' in model_name.lower() or
                                  'qwen3-vl' in model_name.lower() or 'minicpm-v' in model_name.lower())

                            if is_vision_capable:
                                models_data.append({
                                    'name': model_name,
                                    'endpoint': endpoint
                                })
                    except Exception:
                        continue

                # æŸ¥æ‰¾æŒ‡å®šIDçš„æ¨¡å‹
                if 1 <= pk <= len(models_data):
                    model_info = models_data[pk - 1]
                    model_name = model_info['name']
                    endpoint = model_info['endpoint']
                else:
                    return not_found_response('AIæ¨¡å‹')
            except Exception as e:
                logger.error(f"åŠ¨æ€è·å–æ¨¡å‹å¤±è´¥: {str(e)}")
                return not_found_response('AIæ¨¡å‹')

        try:
            # ä½¿ç”¨æ¨¡å‹çš„ç«¯ç‚¹æµ‹è¯•è¿æ¥
            client = OllamaClient(base_url=endpoint.url, timeout=endpoint.timeout)

            # å°è¯•ç”Ÿæˆä¸€ä¸ªç®€å•çš„æµ‹è¯•è¯·æ±‚
            try:
                models = client.list_models()
                model_exists = any(m.get('name') == model_name for m in models)

                if model_exists:
                    return success_response(
                        data={
                            'status': 'success',
                            'message': 'æ¨¡å‹å¯ç”¨',
                            'endpoint': endpoint.url,
                            'endpoint_name': endpoint.name,
                            'model_name': model_name
                        },
                        message='æ¨¡å‹è¿æ¥æµ‹è¯•æˆåŠŸ'
                    )
                else:
                    return error_response(
                        message=f'æ¨¡å‹ {model_name} åœ¨ç«¯ç‚¹ä¸Šä¸å­˜åœ¨',
                        status_code=status.HTTP_400_BAD_REQUEST
                    )

            except Exception as e:
                return error_response(
                    message=f'æ¨¡å‹æµ‹è¯•å¤±è´¥: {str(e)}',
                    status_code=status.HTTP_400_BAD_REQUEST
                )

        except Exception as e:
            logger.error(f"æµ‹è¯•æ¨¡å‹è¿æ¥å¤±è´¥: {str(e)}")
            return error_response(
                message=f'æµ‹è¯•è¿æ¥å¤±è´¥: {str(e)}',
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR
            )

    @action(detail=True, methods=['post'])
    def default(self, request, pk=None):
        """è®¾ç½®é»˜è®¤æ¨¡å‹"""
        # å°è¯•å…ˆä»æ•°æ®åº“ä¸­æŸ¥æ‰¾
        try:
            model = self.get_queryset().get(pk=pk)
            # å¦‚æœæ‰¾åˆ°äº†ï¼Œç›´æ¥è®¾ç½®ä¸ºé»˜è®¤
            model.is_default = True
            model.save()

            serializer = self.get_serializer(model)
            return success_response(
                data=serializer.data,
                message='é»˜è®¤æ¨¡å‹è®¾ç½®æˆåŠŸ'
            )
        except AIModel.DoesNotExist:
            # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰ï¼Œä»åŠ¨æ€è·å–çš„æ¨¡å‹åˆ—è¡¨ä¸­æŸ¥æ‰¾
            try:
                pk = int(pk)
                from .services import OllamaClient

                models_data = []
                endpoints = OllamaEndpoint.objects.filter(is_active=True)

                for endpoint in endpoints:
                    try:
                        client = OllamaClient(base_url=endpoint.url, timeout=endpoint.timeout)
                        endpoint_models = client.list_models()

                        for model_data in endpoint_models:
                            model_name = model_data.get('name', '')
                            details = model_data.get('details', {})
                            families = details.get('families', [])

                            # æ£€æŸ¥æ˜¯å¦ä¸ºè§†è§‰æ¨¡å‹
                            is_vision_capable = any(
                                family in ['qwen3vl', 'clip', 'llava', 'minicpm', 'vision']
                                for family in families
                            ) or ('vl' in model_name.lower() or 'vision' in model_name.lower() or
                                  'qwen3-vl' in model_name.lower() or 'minicpm-v' in model_name.lower())

                            if is_vision_capable:
                                models_data.append({
                                    'name': model_name,
                                    'endpoint': endpoint
                                })
                    except Exception:
                        continue

                # æŸ¥æ‰¾æŒ‡å®šIDçš„æ¨¡å‹
                if 1 <= pk <= len(models_data):
                    model_info = models_data[pk - 1]
                    model_name = model_info['name']
                    endpoint = model_info['endpoint']

                    # è°ƒç”¨ set_default_by_name çš„é€»è¾‘
                    # é¦–å…ˆå–æ¶ˆæ‰€æœ‰å…¶ä»–æ¨¡å‹çš„é»˜è®¤çŠ¶æ€
                    AIModel.objects.filter(is_default=True).update(is_default=False)

                    # æŸ¥æ‰¾æˆ–åˆ›å»ºæ¨¡å‹
                    model, created = AIModel.objects.get_or_create(
                        name=model_name,
                        endpoint=endpoint,
                        defaults={
                            'display_name': model_name.replace('/', ' - ').title(),
                            'description': 'ç”¨æˆ·è®¾ç½®çš„é»˜è®¤æ¨¡å‹',
                            'is_active': True,
                            'is_vision_capable': True,
                            'is_default': True
                        }
                    )

                    if not created:
                        # å¦‚æœæ¨¡å‹å·²å­˜åœ¨ï¼Œå°†å…¶è®¾ä¸ºé»˜è®¤
                        model.is_default = True
                        model.save()

                    return success_response(
                        data={
                            'model_name': model.name,
                            'endpoint_name': model.endpoint.name,
                            'is_default': model.is_default
                        },
                        message='é»˜è®¤æ¨¡å‹è®¾ç½®æˆåŠŸ'
                    )
                else:
                    return not_found_response('AIæ¨¡å‹')
            except Exception as e:
                logger.error(f"åŠ¨æ€è®¾ç½®é»˜è®¤æ¨¡å‹å¤±è´¥: {str(e)}")
                return not_found_response('AIæ¨¡å‹')
        except Exception as e:
            logger.error(f"è®¾ç½®é»˜è®¤æ¨¡å‹å¤±è´¥: {str(e)}")
            return error_response(
                message='è®¾ç½®é»˜è®¤æ¨¡å‹å¤±è´¥',
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR
            )

    def set_default_by_name(self, request):
        """é€šè¿‡æ¨¡å‹åç§°å’Œç«¯ç‚¹IDè®¾ç½®é»˜è®¤æ¨¡å‹"""
        model_name = request.data.get('model_name')
        endpoint_id = request.data.get('endpoint_id')

        if not model_name or not endpoint_id:
            return error_response(
                message='è¯·æä¾›æ¨¡å‹åç§°å’Œç«¯ç‚¹ID',
                status_code=status.HTTP_400_BAD_REQUEST
            )

        try:
            # è·å–ç«¯ç‚¹
            endpoint = OllamaEndpoint.objects.get(id=endpoint_id, is_active=True)

            # æŸ¥æ‰¾æˆ–åˆ›å»ºæ¨¡å‹
            model, created = AIModel.objects.get_or_create(
                name=model_name,
                endpoint=endpoint,
                defaults={
                    'display_name': model_name.replace('/', ' - ').title(),
                    'description': 'ç”¨æˆ·è®¾ç½®çš„é»˜è®¤æ¨¡å‹',
                    'is_active': True,
                    'is_vision_capable': True,
                    'is_default': True
                }
            )

            if not created:
                # å¦‚æœæ¨¡å‹å·²å­˜åœ¨ï¼Œå°†å…¶è®¾ä¸ºé»˜è®¤
                # é¦–å…ˆå–æ¶ˆæ‰€æœ‰å…¶ä»–æ¨¡å‹çš„é»˜è®¤çŠ¶æ€
                AIModel.objects.filter(is_default=True).update(is_default=False)

                # è®¾ç½®å½“å‰æ¨¡å‹ä¸ºé»˜è®¤
                model.is_default = True
                model.save()

            return success_response(
                data={
                    'model_name': model.name,
                    'endpoint_name': model.endpoint.name,
                    'is_default': model.is_default
                },
                message='é»˜è®¤æ¨¡å‹è®¾ç½®æˆåŠŸ'
            )

        except OllamaEndpoint.DoesNotExist:
            return error_response(
                message='æŒ‡å®šçš„ç«¯ç‚¹ä¸å­˜åœ¨æˆ–æœªæ¿€æ´»',
                status_code=status.HTTP_404_NOT_FOUND
            )
        except Exception as e:
            logger.error(f"è®¾ç½®é»˜è®¤æ¨¡å‹å¤±è´¥: {str(e)}")
            return error_response(
                message='è®¾ç½®é»˜è®¤æ¨¡å‹å¤±è´¥',
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR
            )


class AIAnalysisViewSet(viewsets.GenericViewSet):
    """é‡æ„åçš„AIåˆ†æ ViewSet - ä½¿ç”¨Django-Qå¼‚æ­¥å¤„ç†"""
    permission_classes = [permissions.IsAuthenticated]
    queryset = AIAnalysis.objects.all()

    def get_serializer_class(self):
        """æ ¹æ® action é€‰æ‹©åºåˆ—åŒ–å™¨"""
        if self.action == 'list':
            return AIAnalysisListSerializer
        return AIAnalysisSerializer

    def get_queryset(self):
        """è·å–å½“å‰ç”¨æˆ·çš„AIåˆ†æè®°å½•"""
        return AIAnalysis.objects.filter(media__user=self.request.user)

    def list(self, request):
        """è·å–ç”¨æˆ·çš„AIåˆ†æè®°å½•åˆ—è¡¨"""
        queryset = self.get_queryset().order_by('-created_at')

        # æ”¯æŒæŒ‰çŠ¶æ€è¿‡æ»¤
        status_filter = request.query_params.get('status', None)
        if status_filter:
            queryset = queryset.filter(status=status_filter)

        # åˆ†é¡µ
        page = self.paginate_queryset(queryset)
        if page is not None:
            serializer = self.get_serializer(page, many=True)
            return self.get_paginated_response(serializer.data)

        serializer = self.get_serializer(queryset, many=True)
        return success_response(
            data={
                'analyses': serializer.data,
                'total': queryset.count()
            },
            message='è·å–åˆ†æè®°å½•åˆ—è¡¨æˆåŠŸ'
        )

    def retrieve(self, request):
        """è·å–å•ä¸ªåˆ†æè®°å½•è¯¦æƒ…"""
        analysis_id = request.data.get('analysis_id')
        if not analysis_id:
            return error_response(
                message='ç¼ºå°‘analysis_idå‚æ•°',
                status_code=status.HTTP_400_BAD_REQUEST
            )

        try:
            analysis = self.get_queryset().get(pk=analysis_id)
            serializer = self.get_serializer(analysis)
            return success_response(
                data=serializer.data,
                message='è·å–åˆ†æè®°å½•è¯¦æƒ…æˆåŠŸ'
            )
        except AIAnalysis.DoesNotExist:
            return not_found_response('åˆ†æè®°å½•ä¸å­˜åœ¨')

    @action(detail=False, methods=['post'], url_path='single')
    def single(self, request):
        """
        å•å›¾åˆ†ææ¥å£ - å¼‚æ­¥å¤„ç†
        åˆ›å»ºåˆ†æä»»åŠ¡å¹¶ç«‹å³è¿”å›ä»»åŠ¡ä¿¡æ¯
        """
        from .tasks import create_analysis_task

        try:
            media_id = request.data.get('media_id')
            if not media_id:
                return error_response(
                    message='ç¼ºå°‘media_idå‚æ•°',
                    status_code=status.HTTP_400_BAD_REQUEST
                )

            # è·å–åˆ†æé€‰é¡¹
            options = request.data.get('options', {})

            # åˆ›å»ºåˆ†æä»»åŠ¡
            model_name = request.data.get('model_name')
            logger.info(f"ğŸ” [API] æ”¶åˆ°åˆ†æè¯·æ±‚: media_id={media_id}, model_name={model_name}, options={options}")

            analysis = create_analysis_task(
                media_id=int(media_id),
                user_id=request.user.id,
                model_name=model_name,
                options=options
            )

            logger.info(f"ğŸ” [API] åˆ›å»ºä»»åŠ¡å: analysis_id={analysis.id}, model_used={analysis.model_used}")

            # è¿”å›ä»»åŠ¡ä¿¡æ¯
            response_data = {
                'analysis_id': analysis.id,
                'task_id': analysis.task_id,
                'status': analysis.status,
                'media_id': analysis.media.id,
                'media_title': analysis.media.title or analysis.media.file.name,
                'created_at': analysis.created_at,
                'message': 'åˆ†æä»»åŠ¡å·²åˆ›å»ºï¼Œæ­£åœ¨å¤„ç†ä¸­...'
            }

            return success_response(
                data=response_data,
                message='å›¾ç‰‡åˆ†æä»»åŠ¡åˆ›å»ºæˆåŠŸ',
                status_code=status.HTTP_202_ACCEPTED
            )

        except Exception as e:
            logger.error(f"åˆ›å»ºåˆ†æä»»åŠ¡å¤±è´¥: {str(e)}")
            return error_response(
                message=f'åˆ›å»ºåˆ†æä»»åŠ¡å¤±è´¥: {str(e)}',
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR
            )

    @action(detail=False, methods=['post'], url_path='status')
    def status(self, request):
        """è·å–åˆ†æä»»åŠ¡çŠ¶æ€"""
        analysis_id = request.data.get('analysis_id')
        task_id = request.data.get('task_id')

        # å¦‚æœæä¾›äº† task_idï¼Œç›´æ¥æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
        if task_id and not analysis_id:
            try:
                from .tasks import get_task_status
                task_info = get_task_status(task_id)

                return success_response(
                    data=task_info,
                    message='è·å–ä»»åŠ¡çŠ¶æ€æˆåŠŸ'
                )

            except Exception as e:
                logger.error(f"è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {str(e)}")
                return error_response(
                    message=f'è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {str(e)}',
                    status_code=status.HTTP_500_INTERNAL_SERVER_ERROR
                )

        # å¦‚æœæä¾›äº† analysis_idï¼ŒæŒ‰åŸæœ‰é€»è¾‘æŸ¥è¯¢
        if analysis_id:
            try:
                analysis = self.get_queryset().get(pk=analysis_id)

                # å¦‚æœæœ‰ä»»åŠ¡IDï¼Œä»Django-Qè·å–å®æ—¶çŠ¶æ€
                task_info = {}
                if analysis.task_id:
                    from .tasks import get_task_status
                    task_info = get_task_status(analysis.task_id)

                response_data = {
                    'analysis_id': analysis.id,
                    'status': analysis.status,
                    'progress': analysis.task_progress,
                    'is_task_running': analysis.is_task_running,
                    'task_id': analysis.task_id,
                    'model_used': analysis.model_used,
                    'created_at': analysis.created_at,
                    'analyzed_at': analysis.analyzed_at,
                    'error_message': analysis.error_message,
                    'applied_to_media': analysis.applied_to_media,
                    'task_info': task_info
                }

                return success_response(
                    data=response_data,
                    message='è·å–ä»»åŠ¡çŠ¶æ€æˆåŠŸ'
                )

            except AIAnalysis.DoesNotExist:
                return not_found_response('åˆ†æè®°å½•ä¸å­˜åœ¨')
            except Exception as e:
                logger.error(f"è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {str(e)}")
                return error_response(
                    message=f'è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {str(e)}',
                    status_code=status.HTTP_500_INTERNAL_SERVER_ERROR
                )

        # å¦‚æœä¸¤ä¸ªå‚æ•°éƒ½æ²¡æœ‰æä¾›
        return error_response(
            message='ç¼ºå°‘analysis_idæˆ–task_idå‚æ•°',
            status_code=status.HTTP_400_BAD_REQUEST
        )

    @action(detail=False, methods=['post'], url_path='task-status')
    def task_status(self, request):
        """é€šè¿‡task_idç›´æ¥æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€"""
        task_id = request.data.get('task_id')
        if not task_id:
            return error_response(
                message='ç¼ºå°‘task_idå‚æ•°',
                status_code=status.HTTP_400_BAD_REQUEST
            )

        try:
            from .tasks import get_task_status
            task_info = get_task_status(task_id)

            return success_response(
                data=task_info,
                message='è·å–ä»»åŠ¡çŠ¶æ€æˆåŠŸ'
            )

        except Exception as e:
            logger.error(f"è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {str(e)}")
            return error_response(
                message=f'è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {str(e)}',
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR
            )

    @action(detail=False, methods=['post'], url_path='apply')
    def apply(self, request):
        """æ‰‹åŠ¨åº”ç”¨åˆ†æç»“æœåˆ°åª’ä½“æ–‡ä»¶"""
        analysis_id = request.data.get('analysis_id')
        if not analysis_id:
            return error_response(
                message='ç¼ºå°‘analysis_idå‚æ•°',
                status_code=status.HTTP_400_BAD_REQUEST
            )

        try:
            analysis = self.get_queryset().get(pk=analysis_id)

            if analysis.status != 'completed':
                return error_response(
                    message='åªèƒ½åº”ç”¨å·²å®Œæˆçš„åˆ†æç»“æœ',
                    status_code=status.HTTP_400_BAD_REQUEST
                )

            if analysis.applied_to_media:
                return error_response(
                    message='åˆ†æç»“æœå·²ç»åº”ç”¨åˆ°åª’ä½“æ–‡ä»¶',
                    status_code=status.HTTP_400_BAD_REQUEST
                )

            # åº”ç”¨ç»“æœ
            success = analysis.apply_to_media()

            if success:
                return success_response(
                    data={
                        'analysis_id': analysis.id,
                        'applied_to_media': True,
                        'media_title': analysis.media.title
                    },
                    message='åˆ†æç»“æœå·²æˆåŠŸåº”ç”¨åˆ°åª’ä½“æ–‡ä»¶'
                )
            else:
                return error_response(
                    message='åº”ç”¨åˆ†æç»“æœå¤±è´¥',
                    status_code=status.HTTP_500_INTERNAL_SERVER_ERROR
                )

        except AIAnalysis.DoesNotExist:
            return not_found_response('åˆ†æè®°å½•ä¸å­˜åœ¨')
        except Exception as e:
            logger.error(f"åº”ç”¨åˆ†æç»“æœå¤±è´¥: {str(e)}")
            return error_response(
                message=f'åº”ç”¨åˆ†æç»“æœå¤±è´¥: {str(e)}',
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR
            )

    @action(detail=False, methods=['post'], url_path='retry')
    def retry(self, request):
        """é‡è¯•å¤±è´¥çš„åˆ†æä»»åŠ¡"""
        analysis_id = request.data.get('analysis_id')
        if not analysis_id:
            return error_response(
                message='ç¼ºå°‘analysis_idå‚æ•°',
                status_code=status.HTTP_400_BAD_REQUEST
            )

        try:
            analysis = self.get_queryset().get(pk=analysis_id)

            if analysis.status not in ['failed', 'completed']:
                return error_response(
                    message='åªèƒ½é‡è¯•å¤±è´¥æˆ–å·²å®Œæˆçš„åˆ†æ',
                    status_code=status.HTTP_400_BAD_REQUEST
                )

            # é‡ç½®åˆ†æçŠ¶æ€
            analysis.status = 'pending'
            analysis.error_message = None
            analysis.task_id = None
            analysis.save()

            # é‡æ–°åˆ›å»ºä»»åŠ¡
            from .tasks import create_analysis_task
            new_analysis = create_analysis_task(
                media_id=analysis.media.id,
                user_id=request.user.id,
                model_name=analysis.model_used
            )

            # åˆ é™¤æ—§çš„åˆ†æè®°å½•
            analysis.delete()

            return success_response(
                data={
                    'analysis_id': new_analysis.id,
                    'task_id': new_analysis.task_id,
                    'status': new_analysis.status,
                    'message': 'é‡æ–°åˆ›å»ºåˆ†æä»»åŠ¡æˆåŠŸ'
                },
                message='é‡è¯•åˆ†æä»»åŠ¡æˆåŠŸ'
            )

        except AIAnalysis.DoesNotExist:
            return not_found_response('åˆ†æè®°å½•ä¸å­˜åœ¨')
        except Exception as e:
            logger.error(f"é‡è¯•åˆ†æä»»åŠ¡å¤±è´¥: {str(e)}")
            return error_response(
                message=f'é‡è¯•åˆ†æä»»åŠ¡å¤±è´¥: {str(e)}',
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR
            )

    def destroy(self, request):
        """åˆ é™¤åˆ†æè®°å½•"""
        analysis_id = request.data.get('analysis_id')
        if not analysis_id:
            return error_response(
                message='ç¼ºå°‘analysis_idå‚æ•°',
                status_code=status.HTTP_400_BAD_REQUEST
            )

        try:
            analysis = self.get_queryset().get(pk=analysis_id)

            # å¦‚æœä»»åŠ¡æ­£åœ¨è¿è¡Œï¼Œå…ˆå–æ¶ˆä»»åŠ¡
            if analysis.is_task_running and analysis.task_id:
                try:
                    from django_async_manager.models import AsyncTask
                    task = AsyncTask.objects.get(id=analysis.task_id)
                    task.cancel()
                except:
                    pass  # å¿½ç•¥å–æ¶ˆä»»åŠ¡å¤±è´¥çš„æƒ…å†µ

            analysis.delete()
            return success_response(message='åˆ†æè®°å½•åˆ é™¤æˆåŠŸ')

        except AIAnalysis.DoesNotExist:
            return not_found_response('åˆ†æè®°å½•ä¸å­˜åœ¨')
        except Exception as e:
            logger.error(f"åˆ é™¤åˆ†æè®°å½•å¤±è´¥: {str(e)}")
            return error_response(
                message=f'åˆ é™¤åˆ†æè®°å½•å¤±è´¥: {str(e)}',
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR
            )
