"""
è¯·æ±‚é˜Ÿåˆ—ç®¡ç†å™¨
æ§åˆ¶å¹¶å‘è¯·æ±‚æ•°é‡ï¼Œé¿å…æ•°æ®åº“é”ç«äº‰
"""

import threading
import time
import logging
from typing import Callable, Any

logger = logging.getLogger(__name__)


class RequestQueueManager:
    """è¯·æ±‚é˜Ÿåˆ—ç®¡ç†å™¨"""

    def __init__(self, max_concurrent=5):
        self.max_concurrent = max_concurrent
        self._lock = threading.RLock()
        self._active_requests = 0
        self._waiting_requests = 0
        self._condition = threading.Condition(self._lock)

    def execute_with_throttle(self, func: Callable, *args, **kwargs) -> Any:
        """
        å¸¦é™æµçš„æ‰§è¡Œå‡½æ•°
        å¦‚æœå½“å‰æ´»è·ƒè¯·æ±‚è¶…è¿‡é™åˆ¶ï¼Œç­‰å¾…ç›´åˆ°æœ‰ç©ºé—²ä½ç½®
        """
        with self._lock:
            self._waiting_requests += 1
            logger.debug(f"ğŸ“¥ è¯·æ±‚è¿›å…¥é˜Ÿåˆ—: ç­‰å¾…ä¸­ {self._waiting_requests}, æ´»è·ƒä¸­ {self._active_requests}")

        try:
            # ç­‰å¾…ç›´åˆ°æœ‰ç©ºé—²ä½ç½®
            with self._condition:
                while self._active_requests >= self.max_concurrent:
                    logger.debug(f"â³ è¯·æ±‚ç­‰å¾…ä¸­: æ´»è·ƒ {self._active_requests}/{self.max_concurrent}")
                    self._condition.wait(timeout=0.1)

                # è·å–æ‰§è¡Œæƒé™
                with self._lock:
                    self._waiting_requests -= 1
                    self._active_requests += 1
                    logger.debug(f"ğŸš€ è¯·æ±‚å¼€å§‹æ‰§è¡Œ: æ´»è·ƒ {self._active_requests}/{self.max_concurrent}")

            # æ‰§è¡Œå‡½æ•°
            try:
                return func(*args, **kwargs)
            finally:
                # é‡Šæ”¾æ‰§è¡Œæƒé™
                with self._lock:
                    self._active_requests -= 1
                    logger.debug(f"âœ… è¯·æ±‚æ‰§è¡Œå®Œæˆ: æ´»è·ƒ {self._active_requests}/{self.max_concurrent}")

                # é€šçŸ¥ç­‰å¾…çš„è¯·æ±‚
                with self._condition:
                    self._condition.notify_all()

        except Exception as e:
            # ç¡®ä¿åœ¨å¼‚å¸¸æƒ…å†µä¸‹ä¹Ÿé‡Šæ”¾èµ„æº
            with self._lock:
                self._active_requests = max(0, self._active_requests - 1)
                logger.debug(f"âŒ è¯·æ±‚æ‰§è¡Œå¼‚å¸¸: æ´»è·ƒ {self._active_requests}/{self.max_concurrent}")

            with self._condition:
                self._condition.notify_all()
            raise

    def get_stats(self) -> dict:
        """è·å–é˜Ÿåˆ—ç»Ÿè®¡ä¿¡æ¯"""
        with self._lock:
            return {
                'max_concurrent': self.max_concurrent,
                'active_requests': self._active_requests,
                'waiting_requests': self._waiting_requests,
                'utilization': self._active_requests / self.max_concurrent if self.max_concurrent > 0 else 0
            }


# å…¨å±€è¯·æ±‚é˜Ÿåˆ—ç®¡ç†å™¨å®ä¾‹
# é’ˆå¯¹æ•°æ®åº“å†™æ“ä½œè¿›è¡Œé™æµ
db_write_queue = RequestQueueManager(max_concurrent=3)


def throttle_db_write(func: Callable):
    """æ•°æ®åº“å†™æ“ä½œé™æµè£…é¥°å™¨"""
    def wrapper(*args, **kwargs):
        return db_write_queue.execute_with_throttle(func, *args, **kwargs)
    return wrapper


# é’ˆå¯¹æ‰¹é‡æ“ä½œçš„ç‰¹æ®Šé˜Ÿåˆ—
batch_queue = RequestQueueManager(max_concurrent=2)


def throttle_batch_operation(func: Callable):
    """æ‰¹é‡æ“ä½œé™æµè£…é¥°å™¨"""
    def wrapper(*args, **kwargs):
        return batch_queue.execute_with_throttle(func, *args, **kwargs)
    return wrapper