=== /root/dev/epipremnum/backend/workflow/admin.py ===
from django.contrib import admin

# Register your models here.



=== /root/dev/epipremnum/backend/workflow/apps.py ===
from django.apps import AppConfig
import logging

logger = logging.getLogger(__name__)


class WorkflowConfig(AppConfig):
    default_auto_field = 'django.db.models.BigAutoField'
    name = 'workflow'

    def ready(self):
        """åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–"""
        # é¿å…åœ¨è¿ç§»æ—¶è¿è¡Œ
        import sys
        if 'migrate' in sys.argv or 'makemigrations' in sys.argv:
            return

        try:
            # åˆå§‹åŒ–å·¥ä½œæµç›¸å…³ç»„ä»¶
            logger.info("âœ… Workflowåº”ç”¨å¯åŠ¨æˆåŠŸ")
        except Exception as e:
            logger.warning(f"âš ï¸ Workflowåº”ç”¨å¯åŠ¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")



=== /root/dev/epipremnum/backend/workflow/batch_handler.py ===
"""
æ”¹è¿›çš„æ‰¹é‡å¤„ç†å™¨ - ç®€åŒ–ç‰ˆ
ç§»é™¤å¤æ‚çš„å¹¶å‘æ§åˆ¶ï¼Œåªè´Ÿè´£ä»»åŠ¡å‡†å¤‡å’Œç»“æœæ•´ç†
"""

import logging
from typing import Dict, Any, List
from django.db import transaction
from .state_manager import state_manager

logger = logging.getLogger(__name__)


class SimplifiedBatchHandler:
    """ç®€åŒ–ç‰ˆæ‰¹é‡å¤„ç†å™¨"""

    def __init__(self):
        self.max_batch_size = 50  # å¢åŠ æ‰¹é‡å¤§å°

    def prepare_tasks(self, user, media_ids, model_name=None, analysis_options=None, prompt=None):
        """å‡†å¤‡æ‰¹é‡ä»»åŠ¡ - ç®€åŒ–ç‰ˆ"""
        from media.models import Media
        from ollama.models import OllamaAIModel

        valid_tasks = []
        validation_errors = []

        # æ‰¹é‡æŸ¥è¯¢åª’ä½“æ–‡ä»¶
        media_items = Media.objects.filter(
            id__in=media_ids,
            user=user
        ).select_related('user')

        # æ£€æŸ¥ç¼ºå¤±çš„åª’ä½“
        found_ids = {m.id for m in media_items}
        for media_id in media_ids:
            if media_id not in found_ids:
                validation_errors.append({
                    'media_id': media_id,
                    'error': 'åª’ä½“æ–‡ä»¶ä¸å­˜åœ¨æˆ–æ— æƒè®¿é—®'
                })

        # è·å–æ¨¡å‹
        model = self._get_model(user, model_name)
        if not model:
            raise BatchValidationError("æ²¡æœ‰å¯ç”¨çš„åˆ†ææ¨¡å‹")

        # æ‰¹é‡åˆ›å»ºåˆ†æä»»åŠ¡
        for media in media_items:
            try:
                analysis, created = state_manager.create_analysis_safely(
                    media=media,
                    model=model,
                    analysis_options=analysis_options or {},
                    prompt=prompt
                )

                valid_tasks.append(analysis)
                logger.debug(f"åˆ›å»ºåˆ†æä»»åŠ¡: media_id={media.id}, analysis_id={analysis.id}")

            except Exception as e:
                validation_errors.append({
                    'media_id': media.id,
                    'error': f"åˆ›å»ºåˆ†æä»»åŠ¡å¤±è´¥: {str(e)}"
                })

        summary = {
            'total_requested': len(media_ids),
            'valid_tasks': len(valid_tasks),
            'validation_errors': len(validation_errors)
        }

        return valid_tasks, validation_errors, summary

    def _get_model(self, user, model_name=None):
        """è·å–æ¨¡å‹ - ç®€åŒ–ç‰ˆ"""
        from ollama.models import OllamaAIModel

        queryset = OllamaAIModel.objects.filter(
            endpoint__created_by=user,
            is_active=True,
            is_vision_capable=True
        )

        if model_name:
            queryset = queryset.filter(name=model_name)

        return queryset.filter(is_default=True).first() or queryset.first()

    def analyze_images_with_concurrency_task(self, user_id, media_ids, model_name, analysis_options=None, prompt=None):
        """
        å›¾ç‰‡å¹¶å‘æ‰¹é‡åˆ†æä»»åŠ¡ - ç®€åŒ–ç‰ˆ
        ç›´æ¥ä½¿ç”¨å¹¶å‘ç®¡ç†å™¨
        """
        logger.info(f"ğŸš€ å¼€å§‹æ‰¹é‡åˆ†æ: {len(media_ids)} å¼ å›¾ç‰‡ï¼Œç”¨æˆ·: {user_id}")

        try:
            from django.contrib.auth import get_user_model
            User = get_user_model()

            # è·å–ç”¨æˆ·
            user = User.objects.get(id=user_id)

            # éªŒè¯è¯·æ±‚
            validation_result = self.validate_request(media_ids, model_name, analysis_options)
            if not validation_result['valid']:
                return {
                    'success': False,
                    'error': f"æ‰¹é‡è¯·æ±‚éªŒè¯å¤±è´¥: {'; '.join(validation_result['errors'])}"
                }

            # å‡†å¤‡ä»»åŠ¡
            valid_tasks, validation_errors, summary = self.prepare_tasks(
                user=user,
                media_ids=media_ids,
                model_name=model_name,
                analysis_options=analysis_options,
                prompt=prompt
            )

            if not valid_tasks:
                return {
                    'success': False,
                    'error': 'æ²¡æœ‰å¯å¤„ç†çš„ä»»åŠ¡',
                    'validation_errors': validation_errors
                }

            # åˆ›å»ºæ‰¹é‡åˆ†æå¼‚æ­¥ä»»åŠ¡
            from .task_workers import analyze_batch_task

            analysis_ids = [task.id for task in valid_tasks]
            max_concurrent = analysis_options.get('max_concurrent', 10) if analysis_options else 10

            batch_task = analyze_batch_task.run_async(
                user_id=user_id,
                analysis_ids=analysis_ids,
                model_name=model_name,
                max_concurrent=max_concurrent
            )

            logger.info(f"âœ… æ‰¹é‡åˆ†æä»»åŠ¡å·²å¯åŠ¨: task_id={batch_task.id}")

            return {
                'success': True,
                'batch_started': True,
                'batch_task_id': str(batch_task.id),
                'summary': summary,
                'analysis_ids': analysis_ids,
                'max_concurrent': max_concurrent
            }

        except Exception as e:
            logger.error(f"âŒ æ‰¹é‡åˆ†æä»»åŠ¡å¼‚å¸¸: {str(e)}")
            return {
                'success': False,
                'error': f"æ‰¹é‡åˆ†æä»»åŠ¡å¼‚å¸¸: {str(e)}"
            }

    def validate_request(self, media_ids, model_name=None, analysis_options=None):
        """éªŒè¯æ‰¹é‡è¯·æ±‚å‚æ•°"""
        errors = []
        warnings = []

        # éªŒè¯åª’ä½“IDåˆ—è¡¨
        if not media_ids or not isinstance(media_ids, list):
            errors.append("media_ids å¿…é¡»æ˜¯éç©ºæ•°ç»„")
            return {'valid': False, 'errors': errors, 'warnings': warnings}

        if len(media_ids) > self.max_batch_size:
            errors.append(f"æ‰¹é‡å¤§å°è¶…è¿‡é™åˆ¶ï¼Œæœ€å¤šæ”¯æŒ {self.max_batch_size} ä¸ªæ–‡ä»¶")

        if len(media_ids) == 0:
            errors.append("åª’ä½“IDåˆ—è¡¨ä¸èƒ½ä¸ºç©º")

        # æ£€æŸ¥é‡å¤ID
        if len(media_ids) != len(set(media_ids)):
            warnings.append("åª’ä½“IDåˆ—è¡¨ä¸­åŒ…å«é‡å¤é¡¹")

        # éªŒè¯å¹¶å‘æ§åˆ¶å‚æ•°
        analysis_options = analysis_options or {}
        if 'max_concurrent' in analysis_options:
            max_concurrent = analysis_options['max_concurrent']
            if not isinstance(max_concurrent, int) or not 1 <= max_concurrent <= 10:
                errors.append('max_concurrentå¿…é¡»åœ¨1-10ä¹‹é—´')

        # éªŒè¯æ¨¡å‹åç§°
        if model_name and not isinstance(model_name, str):
            errors.append("æ¨¡å‹åç§°å¿…é¡»æ˜¯å­—ç¬¦ä¸²")

        return {
            'valid': len(errors) == 0,
            'errors': errors,
            'warnings': warnings,
            'media_count': len(media_ids)
        }

    def execute_processing(self, user, valid_tasks, analysis_options):
        """ç®€åŒ–çš„æ‰¹é‡æ‰§è¡Œå¤„ç†"""
        from .concurrency_manager import concurrency_manager

        media_ids = [task.media.id for task in valid_tasks]

        return concurrency_manager.process_batch_images(
            user_id=user.id,
            media_ids=media_ids,
            model_name=valid_tasks[0].model.name,
            analysis_options=analysis_options
        )


class BatchError(Exception):
    """æ‰¹é‡å¤„ç†é”™è¯¯åŸºç±»"""
    pass


class BatchValidationError(BatchError):
    """æ‰¹é‡å¤„ç†éªŒè¯é”™è¯¯"""
    pass


# æ›´æ–°å…¨å±€å®ä¾‹
batch_handler = SimplifiedBatchHandler()


=== /root/dev/epipremnum/backend/workflow/concurrency_manager.py ===
"""
æ”¹è¿›çš„å¹¶å‘åˆ†æç®¡ç†å™¨ - ç®€åŒ–ç‰ˆ
åªè´Ÿè´£å›¾ç‰‡çº§å¹¶å‘ï¼Œå›¾ç‰‡å†…å¹¶è¡Œç”±analyzerå¤„ç†
"""

import asyncio
import logging
import time
import threading
from typing import Dict, Any, List
from concurrent.futures import ThreadPoolExecutor
from django.conf import settings

logger = logging.getLogger(__name__)


class SimplifiedConcurrencyManager:
    """ç®€åŒ–ç‰ˆå¹¶å‘ç®¡ç†å™¨ - åªæ§åˆ¶å›¾ç‰‡çº§å¹¶å‘"""

    def __init__(self):
        # å…¨å±€çº¿ç¨‹æ± ï¼Œæ›¿ä»£å¤æ‚çš„ç”¨æˆ·çº§çº¿ç¨‹æ± 
        self.executor = ThreadPoolExecutor(
            max_workers=getattr(settings, 'OLLAMA_GLOBAL_MAX_CONCURRENT', 10),
            thread_name_prefix="ollama_worker"
        )

        # æ´»è·ƒä»»åŠ¡è·Ÿè¸ª
        self.active_tasks = {}
        self._lock = threading.RLock()

        logger.info("ğŸ”§ ç®€åŒ–ç‰ˆå¹¶å‘ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")

    def process_batch_images(self, user_id, media_ids, model_name, analysis_options, executor_callback=None):
        """
        æ‰¹é‡å¤„ç†å›¾ç‰‡ - ç®€åŒ–ç‰ˆ
        ä½¿ç”¨å…¨å±€çº¿ç¨‹æ± ï¼Œæ¯å¼ å›¾ç‰‡ç‹¬ç«‹å¤„ç†
        """
        from ollama.models import OllamaImageAnalysis

        logger.info(f"ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç†: {len(media_ids)} ä¸ªå›¾ç‰‡ï¼Œç”¨æˆ· {user_id}")

        # è·å–æ‰€æœ‰åˆ†æå¯¹è±¡
        analyses = OllamaImageAnalysis.objects.filter(
            media_id__in=media_ids,
            media__user_id=user_id,
            status__in=['pending', 'processing']
        ).select_related('media', 'model')

        results = {}
        failed_items = []
        futures = []

        # æäº¤æ‰€æœ‰ä»»åŠ¡åˆ°çº¿ç¨‹æ± 
        for analysis in analyses:
            try:
                future = self.executor.submit(
                    self._process_single_image_simplified,
                    analysis
                )
                futures.append((future, analysis.media.id))

                with self._lock:
                    self.active_tasks[future] = {
                        'user_id': user_id,
                        'media_id': analysis.media.id
                    }

            except Exception as e:
                failed_items.append({
                    'media_id': analysis.media.id,
                    'error': f"æäº¤ä»»åŠ¡å¤±è´¥: {str(e)}"
                })

        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        for future, media_id in futures:
            try:
                result = future.result(timeout=getattr(settings, 'OLLAMA_ANALYSIS_TIMEOUT', 300))

                if result['success']:
                    results[media_id] = {
                        'success': True,
                        'status': 'completed'
                    }
                else:
                    failed_items.append({
                        'media_id': media_id,
                        'error': result.get('error', 'æœªçŸ¥é”™è¯¯')
                    })

            except Exception as e:
                failed_items.append({
                    'media_id': media_id,
                    'error': f"ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {str(e)}"
                })

            finally:
                with self._lock:
                    self.active_tasks.pop(future, None)

        logger.info(f"ğŸ“Š æ‰¹é‡å¤„ç†å®Œæˆ: æˆåŠŸ {len(results)} ä¸ªï¼Œå¤±è´¥ {len(failed_items)} ä¸ª")

        return {
            'success_count': len(results),
            'error_count': len(failed_items),
            'results': results,
            'failed_items': failed_items
        }

    def _process_single_image_simplified(self, analysis):
        """
        å¤„ç†å•å¼ å›¾ç‰‡ - ç®€åŒ–ç‰ˆ
        ä½¿ç”¨å¢å¼ºç‰ˆåˆ†æå™¨çš„å¹¶è¡Œå¤„ç†
        """
        from .state_manager import state_manager
        from .ollama_client import OllamaImageAnalyzer

        try:
            # æ›´æ–°çŠ¶æ€ä¸ºå¤„ç†ä¸­
            state_manager.update_analysis_status(
                analysis_id=analysis.id,
                from_status='pending',
                to_status='processing'
            )

            # ä½¿ç”¨å¢å¼ºç‰ˆåˆ†æå™¨ï¼ˆå¹¶è¡Œå¤„ç†ï¼‰
            analyzer = OllamaImageAnalyzer()
            result = analyzer.analyze_parallel(analysis)

            if result['success']:
                # æ›´æ–°åª’ä½“ä¿¡æ¯
                state_manager.update_media_with_analysis_result(
                    analysis, result['result']
                )

                # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                state_manager.update_analysis_status(
                    analysis_id=analysis.id,
                    from_status='processing',
                    to_status='completed',
                    analysis_results=result['result'],
                    processing_time=result.get('processing_time_ms')
                )

                return {
                    'success': True,
                    'media_id': analysis.media.id,
                    'result': result['result']
                }
            else:
                # æ ‡è®°å¤±è´¥
                state_manager.update_analysis_status(
                    analysis_id=analysis.id,
                    from_status='processing',
                    to_status='failed',
                    error_message=result.get('error', 'åˆ†æå¤±è´¥')
                )

                return {
                    'success': False,
                    'media_id': analysis.media.id,
                    'error': result.get('error', 'åˆ†æå¤±è´¥')
                }

        except Exception as e:
            logger.error(f"âŒ å¤„ç†å›¾ç‰‡å¤±è´¥: media_id={analysis.media.id}, error={str(e)}")

            # ç¡®ä¿ä»»åŠ¡è¢«æ ‡è®°ä¸ºå¤±è´¥
            try:
                state_manager.update_analysis_status(
                    analysis_id=analysis.id,
                    from_status=None,
                    to_status='failed',
                    error_message=str(e)
                )
            except:
                pass

            return {
                'success': False,
                'media_id': analysis.media.id,
                'error': str(e)
            }

    def cancel_user_tasks(self, user_id: int) -> Dict[str, Any]:
        """å–æ¶ˆç”¨æˆ·çš„æ‰€æœ‰ä»»åŠ¡"""
        cancelled_count = 0

        with self._lock:
            # æ‰¾åˆ°è¯¥ç”¨æˆ·çš„æ‰€æœ‰æ´»åŠ¨ä»»åŠ¡
            user_futures = [
                future for future, info in self.active_tasks.items()
                if info['user_id'] == user_id
            ]

            # å°è¯•å–æ¶ˆæœªå¼€å§‹çš„ä»»åŠ¡
            for future in user_futures:
                if not future.running():
                    if future.cancel():
                        cancelled_count += 1

        # ç®€åŒ–ç‰ˆå–æ¶ˆé€»è¾‘ - åªéœ€è¦æ ‡è®°æ•°æ®åº“ä¸­çš„ä»»åŠ¡çŠ¶æ€
        pass

        logger.info(f"ğŸš« ç”¨æˆ· {user_id} ä»»åŠ¡å–æ¶ˆå®Œæˆ: {cancelled_count} ä¸ª")

        return {
            'cancelled_count': cancelled_count
        }

    def get_active_tasks_info(self) -> Dict[str, Any]:
        """è·å–å½“å‰æ´»è·ƒä»»åŠ¡ä¿¡æ¯"""
        with self._lock:
            user_task_counts = {}
            for info in self.active_tasks.values():
                user_id = info['user_id']
                user_task_counts[user_id] = user_task_counts.get(user_id, 0) + 1

            return {
                'total_active_tasks': len(self.active_tasks),
                'user_task_counts': user_task_counts,
                'max_workers': self.executor._max_workers
            }

    def shutdown(self):
        """å…³é—­ç®¡ç†å™¨"""
        logger.info("ğŸ›‘ å…³é—­ç®€åŒ–ç‰ˆå¹¶å‘ç®¡ç†å™¨...")
        self.executor.shutdown(wait=False)
        logger.info("âœ… ç®€åŒ–ç‰ˆå¹¶å‘ç®¡ç†å™¨å·²å…³é—­")


# æ›¿æ¢å…¨å±€å®ä¾‹
concurrency_manager = SimplifiedConcurrencyManager()


=== /root/dev/epipremnum/backend/workflow/models.py ===
from django.db import models

# Create your models here.



=== /root/dev/epipremnum/backend/workflow/ollama_client.py ===
"""
Ollamaå›¾ç‰‡åˆ†æå®¢æˆ·ç«¯ - ä½¿ç”¨LangChainé‡æ„
ç®€åŒ–å®ç°ï¼Œåˆ©ç”¨LangChainçš„å¼‚æ­¥æ”¯æŒå’Œå¹¶å‘ç®¡ç†
"""
import base64
import logging
import time
from typing import Dict, Any, List, Optional
from django.conf import settings
from django.core.cache import cache
from langchain_core.messages import HumanMessage
from langchain_core.runnables import RunnableParallel, RunnableLambda
from langchain_core.output_parsers import StrOutputParser
from langchain_core.language_models.chat_models import BaseChatModel
from .prompt_templates import PromptTemplates, TaskConfig

logger = logging.getLogger(__name__)


class LangChainImageAnalyzer:
    """åŸºäºLangChainçš„å›¾ç‰‡åˆ†æå™¨"""

    def __init__(self):
        self.timeout = getattr(settings, 'OLLAMA_ANALYSIS_TIMEOUT', 300)
        self.image_cache_ttl = 600  # å›¾ç‰‡ç¼“å­˜10åˆ†é’Ÿ

    def analyze_parallel(self, analysis) -> Dict[str, Any]:
        """
        å¹¶è¡Œæ‰§è¡Œå•å¼ å›¾ç‰‡çš„æ‰€æœ‰åˆ†æä»»åŠ¡
        ä½¿ç”¨LangChainçš„RunnableParallelè¿›è¡Œå¹¶å‘å¤„ç†
        """
        try:
            # éªŒè¯è¾“å…¥
            self._validate_input(analysis)

            # æå–åˆ†ææ•°æ®
            analysis_data = self._extract_analysis_data(analysis)

            # è·å–éœ€è¦æ‰§è¡Œçš„ä»»åŠ¡
            enabled_tasks = TaskConfig.get_enabled_tasks(analysis_data['options'])
            if not enabled_tasks:
                enabled_tasks = TaskConfig.get_default_tasks()

            # å‡†å¤‡å›¾ç‰‡æ•°æ®ï¼ˆå¸¦ç¼“å­˜ï¼‰
            image_base64 = self._get_cached_image_data(analysis)

            # è·å–LangChainå®¢æˆ·ç«¯
            client = self._get_langchain_client(analysis_data['endpoint_url'], analysis_data['model_name'])

            # è·å–ç”¨æˆ·è‡ªå®šä¹‰æç¤ºè¯ï¼ˆå¦‚æœæœ‰ï¼‰
            custom_prompt = getattr(analysis, 'prompt', None)

            # æ„å»ºå¹¶è¡Œä»»åŠ¡é“¾
            parallel_chain = self._build_parallel_chain(client, enabled_tasks, analysis_data['options'], custom_prompt)

            # æ‰§è¡Œå¹¶è¡Œåˆ†æ
            start_time = time.time()
            results = parallel_chain.invoke({
                "image_base64": image_base64,
                "image_path": analysis.media.file.path
            })

            # Debug: æ‰“å°å¹¶è¡Œæ‰§è¡Œç»“æœ
            logger.info(f"=== AIåŸå§‹å“åº”ç»“æœ ===")
            for task_type, result in results.items():
                logger.info(f"Task {task_type}: type={type(result)}, value={result}")
                # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œè®°å½•é•¿åº¦
                if isinstance(result, str):
                    logger.info(f"  - å­—ç¬¦ä¸²é•¿åº¦: {len(result)}")
                    logger.info(f"  - å‰100å­—ç¬¦: {result[:100]}")
            logger.info(f"=== å“åº”ç»“æœç»“æŸ ===")

            # å¤„ç†ç»“æœ
            return self._process_results(results, enabled_tasks, analysis, start_time)

        except Exception as e:
            logger.error(f"å¹¶è¡Œåˆ†æå¤±è´¥: {str(e)}")
            return {'success': False, 'error': f'åˆ†æå¤±è´¥: {str(e)}'}

    def _get_langchain_client(self, endpoint_url: str, model_name: str) -> BaseChatModel:
        """è·å–LangChainå®¢æˆ·ç«¯"""
        from ollama.clients.client_factory import ClientFactory
        from ollama.models import OllamaEndpoint

        # è·å–ç«¯ç‚¹ä¿¡æ¯
        endpoint = OllamaEndpoint.objects.get(url=endpoint_url)

        # åˆ›å»ºå®¢æˆ·ç«¯
        client = ClientFactory.create_client(endpoint)
        if not client:
            raise ValueError(f"æ— æ³•åˆ›å»º {endpoint.provider} å®¢æˆ·ç«¯")

        # è¿”å›LangChainæ¨¡å‹å®ä¾‹
        return client.get_langchain_model(model_name)

    def _build_parallel_chain(self, client: BaseChatModel, tasks: List[str], options: Dict[str, Any], custom_prompt: Optional[str] = None):
        """æ„å»ºå¹¶è¡Œåˆ†æé“¾"""
        chain_dict = {}

        for task_type in tasks:
            # åˆ›å»ºä»»åŠ¡ç‰¹å®šçš„æç¤ºè¯
            prompt = self._create_task_prompt(task_type, options, custom_prompt)

            # åˆ›å»ºåˆ†æé“¾
            chain = (
                {
                    "image_base64": lambda x: x["image_base64"],
                    "prompt": lambda x: prompt,
                    "image_path": lambda x: x["image_path"]
                }
                | RunnableLambda(lambda x: self._prepare_messages(x))
                | client
                | StrOutputParser()
                | RunnableLambda(lambda x: self._process_single_result(x, task_type))
            )

            chain_dict[task_type] = chain

        # åˆ›å»ºå¹¶è¡Œé“¾
        return RunnableParallel(**chain_dict)

    def _prepare_messages(self, inputs: Dict[str, Any]) -> List[HumanMessage]:
        """å‡†å¤‡LangChainæ¶ˆæ¯"""
        return [
            HumanMessage(
                content=[
                    {
                        "type": "text",
                        "text": inputs["prompt"]
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{inputs['image_base64']}"
                        }
                    }
                ]
            )
        ]

    def _create_task_prompt(self, task_type: str, options: Dict[str, Any], custom_prompt: Optional[str] = None) -> str:
        """åˆ›å»ºä»»åŠ¡ç‰¹å®šçš„æç¤ºè¯"""
        # å¦‚æœæœ‰è‡ªå®šä¹‰æç¤ºè¯ï¼Œä¼˜å…ˆä½¿ç”¨
        if custom_prompt:
            logger.info(f"Task: {task_type}, ä½¿ç”¨è‡ªå®šä¹‰æç¤ºè¯: {custom_prompt[:200]}...")
            return custom_prompt

        # å¦åˆ™ä½¿ç”¨é»˜è®¤çš„æ¨¡æ¿æç¤ºè¯
        prompt = TaskConfig.get_task_prompt(
            task_type,
            options.get(f'max_{task_type}') if task_type in ['categories', 'tags'] else None
        )
        # æ·»åŠ è°ƒè¯•æ—¥å¿—
        logger.info(f"Task: {task_type}, æç¤ºè¯: {prompt}")
        return prompt

    def _get_cached_image_data(self, analysis) -> str:
        """è·å–æˆ–ç¼“å­˜å›¾ç‰‡æ•°æ®"""
        cache_key = f'image_b64_{analysis.media.id}'

        # å°è¯•ä»ç¼“å­˜è·å–
        cached = cache.get(cache_key)
        if cached:
            return cached

        # è¯»å–å¹¶ç¼–ç å›¾ç‰‡
        analysis.media.file.seek(0)
        image_content = analysis.media.file.read()
        image_base64 = base64.b64encode(image_content).decode('utf-8')
        analysis.media.file.seek(0)

        # ç¼“å­˜ç»“æœ
        cache.set(cache_key, image_base64, timeout=self.image_cache_ttl)
        return image_base64

    def _extract_analysis_data(self, analysis) -> Dict[str, Any]:
        """æå–åˆ†ææ‰€éœ€çš„æ•°æ®"""
        # å¦‚æœ model ä¸º Noneï¼Œå°è¯•è·å–é»˜è®¤ç«¯ç‚¹å’Œæ¨¡å‹
        if not analysis.model:
            from ollama.models import OllamaEndpoint, OllamaAIModel
            try:
                # è·å–ç”¨æˆ·çš„é»˜è®¤ç«¯ç‚¹
                default_endpoint = OllamaEndpoint.objects.filter(
                    created_by=analysis.media.uploaded_by,
                    is_default=True,
                    is_active=True
                ).first()

                if not default_endpoint:
                    raise ValueError("æœªæ‰¾åˆ°æ´»è·ƒçš„é»˜è®¤ç«¯ç‚¹")

                # è·å–é»˜è®¤æ¨¡å‹ï¼ˆå¿…é¡»æ”¯æŒè§†è§‰ï¼‰
                default_model = OllamaAIModel.objects.filter(
                    endpoint=default_endpoint,
                    is_active=True,
                    is_vision_capable=True
                ).first()

                if not default_model:
                    raise ValueError("ç«¯ç‚¹ä¸­æ²¡æœ‰æ”¯æŒå›¾ç‰‡åˆ†æçš„æ¨¡å‹")

                endpoint_url = default_endpoint.url
                model_name = default_model.name
            except Exception as e:
                logger.error(f"æ— æ³•è·å–é»˜è®¤æ¨¡å‹: {str(e)}")
                raise ValueError(f"åˆ†æé…ç½®é”™è¯¯: {str(e)}")
        else:
            endpoint_url = analysis.model.endpoint.url
            model_name = analysis.model.name

        return {
            'options': dict(analysis.analysis_options) if analysis.analysis_options else {},
            'endpoint_url': endpoint_url,
            'model_name': model_name,
            'media_id': analysis.media.id,
        }

    def _validate_input(self, analysis):
        """éªŒè¯è¾“å…¥"""
        if not analysis.media or not analysis.media.file:
            raise Exception('åª’ä½“æ–‡ä»¶ä¸å­˜åœ¨')

        if not analysis.model or not analysis.model.is_vision_capable:
            raise Exception('æ¨¡å‹ä¸æ”¯æŒè§†è§‰åˆ†æ')

        if not analysis.model.endpoint.is_active:
            raise Exception('æ¨¡å‹ç«¯ç‚¹æœªæ¿€æ´»')

        # æ£€æŸ¥æ˜¯å¦ä¸ºå›¾ç‰‡æ–‡ä»¶
        image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp', '.tiff'}
        file_extension = analysis.media.file.name.lower().split('.')[-1]
        if f'.{file_extension}' not in image_extensions:
            raise Exception('åªæ”¯æŒå›¾ç‰‡æ–‡ä»¶åˆ†æ')

    def _process_single_result(self, response_text, task_type: str):
        """å¤„ç†å•ä¸ªä»»åŠ¡çš„åˆ†æç»“æœ"""
        # å¤„ç†åˆ—è¡¨æ ¼å¼çš„å“åº”ï¼ˆæŸäº›æ¨¡å‹çš„ç‰¹æ®Šå“åº”ï¼‰
        if isinstance(response_text, list):
            # å¯¹äºæ‰€æœ‰ä»»åŠ¡ç±»å‹ï¼Œå¦‚æœè¿”å›çš„æ˜¯åˆ—è¡¨ï¼Œå…ˆè½¬æ¢æˆå­—ç¬¦ä¸²
            response_text = ' '.join(str(item) for item in response_text)
        else:
            # ç¡®ä¿æ˜¯å­—ç¬¦ä¸²
            response_text = str(response_text).strip()

        # å¤„ç†æ™ºè°±AIæ€è€ƒæ¨¡å‹çš„å“åº”æ ¼å¼
        answer_markers = ['ç°åœ¨å›ç­”ï¼š', 'ç°åœ¨:', 'æœ€ç»ˆç­”æ¡ˆï¼š', 'æœ€ç»ˆ:', 'ç­”æ¡ˆæ˜¯ï¼š', 'ç­”æ¡ˆ:']
        for marker in answer_markers:
            if marker in response_text:
                parts = response_text.split(marker)
                if len(parts) > 1:
                    response_text = parts[-1].strip()
                    break

        # æ¸…ç†æ€è€ƒè¿‡ç¨‹
        if ('ç”¨æˆ·ç°åœ¨éœ€è¦' in response_text or 'ç°åœ¨éœ€è¦' in response_text) and len(response_text) > 200:
            lines = response_text.split('\n')
            final_lines = []
            for line in reversed(lines):
                line = line.strip()
                if not line:
                    continue
                if any(keyword in line for keyword in ['ç”¨æˆ·ç°åœ¨éœ€è¦', 'ç°åœ¨éœ€è¦', 'é¦–å…ˆçœ‹', 'ç„¶å', 'æ¥ä¸‹æ¥']):
                    continue
                if (len(line) > 5 and
                    not any(keyword in line for keyword in ['éœ€è¦', 'è¯·', 'è¦æ±‚', 'é•¿åº¦', 'é¿å…', 'åŒ…å«', 'å®¢è§‚'])):
                    final_lines.insert(0, line)
                elif final_lines:
                    break

            if final_lines:
                response_text = '\n'.join(final_lines[:3])

        # æ ¹æ®ä»»åŠ¡ç±»å‹å¤„ç†ä¸åŒçš„å“åº”æ ¼å¼
        if task_type == 'title':
            # æ£€æŸ¥æ˜¯å¦æ˜¯é€—å·åˆ†éš”çš„è¯è¯­ï¼ˆé”™è¯¯æ ¼å¼ï¼‰
            if ',' in response_text and len(response_text.split(',')) > 3:
                # å¦‚æœæ˜¯å¾ˆå¤šè¯ç”¨é€—å·åˆ†éš”ï¼Œå–å‰å‡ ä¸ªä½œä¸ºæ ‡é¢˜
                words = [w.strip() for w in response_text.split(',')[:5]]
                return ' '.join(words)

            # æå–æ ‡é¢˜
            lines = response_text.split('\n')
            title = ''
            for line in lines:
                line = line.strip()
                if line and not line.startswith(('æ ‡é¢˜ï¼š', 'æ ‡é¢˜:', 'Title:', 'ç”¨æˆ·ç°åœ¨éœ€è¦', 'ç°åœ¨')):
                    title = line
                    break

            for prefix in ['æ ‡é¢˜ï¼š', 'æ ‡é¢˜:', 'Title:', 'title:']:
                if title.startswith(prefix):
                    title = title[len(prefix):].strip()
            return title[:50]

        elif task_type == 'description':
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç®€çŸ­çš„è¯åˆ—è¡¨ï¼ˆé”™è¯¯æ ¼å¼ï¼‰
            words = response_text.split()
            if len(words) <= 15 and len(words) > 0 and len(response_text) < 100:
                # å¯èƒ½æ˜¯è¯åˆ—è¡¨ï¼Œè½¬æ¢ä¸ºæè¿°
                if 'ã€' in response_text or ',' in response_text:
                    # å¦‚æœæ˜¯ç”¨é¡¿å·æˆ–é€—å·åˆ†éš”çš„è¯
                    separators = ['ã€', ',', ' ']
                    items = []
                    for sep in separators:
                        if sep in response_text:
                            items = [item.strip() for item in response_text.split(sep) if item.strip()]
                            break
                    if len(items) > 3:
                        # ç»„åˆæˆæ›´è‡ªç„¶çš„æè¿°
                        desc = f"å›¾ç‰‡ä¸­åŒ…å«äº†{items[0]}"
                        if len(items) > 1:
                            desc += f"ã€{items[1]}"
                        if len(items) > 2:
                            desc += f"ç­‰å…ƒç´ "
                        # å°è¯•æ¨æ–­åœºæ™¯
                        if any(word in response_text for word in ['ç”·å­', 'ç”·æ€§', 'å¥³äºº', 'å¥³æ€§']):
                            desc += "ï¼Œç”»é¢ä¸­æœ‰äººç‰©"
                        if any(word in response_text for word in ['å®¤å¤–', 'æˆ·å¤–', 'è‡ªç„¶å…‰']):
                            desc += "ï¼Œåœºæ™¯ä½äºå®¤å¤–"
                        return desc + "ã€‚"
                    elif len(items) > 1:
                        return f"è¿™æ˜¯ä¸€å¼ å±•ç¤º{'ã€'.join(items[:-1])}å’Œ{items[-1]}çš„å›¾ç‰‡ã€‚"
                return f"è¿™æ˜¯ä¸€å¼ å±•ç¤º{response_text}çš„å›¾ç‰‡ã€‚"

            # æå–æè¿°
            lines = response_text.split('\n')
            description_lines = []
            for line in lines:
                line = line.strip()
                if (line and
                    not line.startswith(('æ ‡é¢˜ï¼š', 'Tags:', 'åˆ†ç±»ï¼š')) and
                    not any(word in line for word in ['ç”¨æˆ·ç°åœ¨éœ€è¦', 'éœ€è¦', 'è¯·', 'è¦æ±‚', 'é•¿åº¦', 'é¿å…'])):
                    description_lines.append(line)
            return ' '.join(description_lines)[:500]

        elif task_type in ['categories', 'tags']:
            # æå–åˆ—è¡¨
            result = []
            if ',' in response_text:
                result = [item.strip() for item in response_text.split(',')]
            else:
                lines = response_text.split('\n')
                result = [line.strip() for line in lines if line.strip()]

            # è¿‡æ»¤å’Œæ¸…ç†
            filtered_result = []
            for item in result:
                import re
                item = re.sub(r'^\d+[\.\)]\s*', '', item)
                for prefix in ['æ ‡ç­¾ï¼š', 'Tags:', 'åˆ†ç±»ï¼š', 'Categories:', '- ', 'â€¢ ']:
                    if item.startswith(prefix):
                        item = item[len(prefix):].strip()
                if item and len(item) <= 20:
                    filtered_result.append(item)

            return filtered_result

        return response_text

    def _process_results(self, results: Dict[str, Any], enabled_tasks: List[str], analysis, start_time: float) -> Dict[str, Any]:
        """å¤„ç†å¹¶è¡Œç»“æœ"""
        processed_results = {}
        failed_tasks = []

        for task_type in enabled_tasks:
            if task_type in results and results[task_type]:
                try:
                    # ç¡®ä¿ç»“æœä¸æ˜¯åµŒå¥—çš„
                    result = results[task_type]

                    # å¤„ç†å¯èƒ½çš„åµŒå¥—åˆ—è¡¨ï¼ˆLangChain æœ‰æ—¶ä¼šè¿”å›åµŒå¥—ç»“æ„ï¼‰
                    if isinstance(result, list) and len(result) == 1 and isinstance(result[0], list):
                        result = result[0]

                    # æ ¹æ®ä»»åŠ¡ç±»å‹å¤„ç†ç»“æœ
                    if task_type in ['categories', 'tags']:
                        # å¯¹äº tags å’Œ categoriesï¼Œç¡®ä¿æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨
                        if isinstance(result, list):
                            result = [str(item) for item in result if item]
                        else:
                            result = [str(result)]
                    else:
                        # å¯¹äº title å’Œ descriptionï¼Œç¡®ä¿æ˜¯å­—ç¬¦ä¸²
                        # æ³¨æ„ï¼š_process_single_result å·²ç»å¤„ç†äº†åˆ—è¡¨æƒ…å†µï¼Œè¿™é‡Œåªéœ€è¦ç¡®ä¿æ˜¯å­—ç¬¦ä¸²
                        if isinstance(result, list):
                            # ç†è®ºä¸Šä¸åº”è¯¥åˆ°è¿™é‡Œï¼Œä½†ä»¥é˜²ä¸‡ä¸€
                            result = ' '.join(str(r) for r in result)
                        else:
                            result = str(result)

                    logger.debug(f"Processed {task_type} result: {type(result)} - {result}")
                    processed_results[task_type] = result
                except Exception as e:
                    logger.error(f"Error processing {task_type}: {str(e)}")
                    failed_tasks.append(f"{task_type}: ç»“æœå¤„ç†å¤±è´¥ - {str(e)}")
            else:
                failed_tasks.append(f"{task_type}: æ— è¿”å›ç»“æœ")

        # æ±‡æ€»ç»“æœ
        final_result = self._combine_results(processed_results, analysis.analysis_options)
        processing_time = int((time.time() - start_time) * 1000)

        return {
            'success': len(processed_results) > 0,
            'result': final_result,
            'processing_time_ms': processing_time,
            'model_used': analysis.model.name if analysis.model else 'default',
            'endpoint_used': analysis.model.endpoint.name if analysis.model else 'default',
            'partial_results': processed_results,
            'failed_tasks': failed_tasks if failed_tasks else None
        }

    def _combine_results(self, results: Dict[str, Any], options: Dict[str, Any]) -> Dict[str, Any]:
        """æ±‡æ€»å¤šä¸ªåˆ†æä»»åŠ¡çš„ç»“æœ"""
        combined = {
            'title': '',
            'description': '',
            'categories': [],
            'tags': [],
            'analysis_options': options
        }

        # åˆå¹¶ç»“æœ
        if 'title' in results:
            combined['title'] = results['title']
        elif options.get('generate_title'):
            combined['title'] = 'æ ‡é¢˜åˆ†æå¤±è´¥'

        if 'description' in results:
            combined['description'] = results['description']
        elif options.get('generate_description'):
            combined['description'] = 'æè¿°åˆ†æå¤±è´¥'

        if 'categories' in results:
            combined['categories'] = results['categories']
        elif options.get('generate_categories'):
            combined['categories'] = []

        if 'tags' in results:
            combined['tags'] = results['tags']
        elif options.get('generate_tags'):
            combined['tags'] = []

        return combined

    # å‘åå…¼å®¹çš„åŒæ­¥æ–¹æ³•
    def analyze(self, analysis) -> Dict[str, Any]:
        """å‘åå…¼å®¹çš„åŒæ­¥åˆ†æ"""
        return self.analyze_parallel(analysis)


# ä¿æŒå‘åå…¼å®¹çš„åˆ«å
OllamaImageAnalyzer = LangChainImageAnalyzer


=== /root/dev/epipremnum/backend/workflow/prompt_templates.py ===
"""
å›¾ç‰‡åˆ†ææç¤ºè¯æ¨¡æ¿
æä¾›å„ç§åˆ†æä»»åŠ¡çš„æç¤ºè¯ç”Ÿæˆå™¨
ä½¿ç”¨LangChainçš„PromptTemplateå¢å¼ºåŠŸèƒ½
"""

from langchain_core.prompts import PromptTemplate, ChatPromptTemplate
from langchain_core.messages import HumanMessage
from typing import Dict, Any, Optional


class LangChainPromptTemplates:
    """ä½¿ç”¨LangChainçš„å›¾ç‰‡åˆ†ææç¤ºè¯æ¨¡æ¿ç±»"""

    @staticmethod
    def title_prompt_template() -> PromptTemplate:
        """ç”Ÿæˆæ ‡é¢˜åˆ†æçš„PromptTemplate"""
        template = """è¯·ä¸ºè¿™å¼ å›¾ç‰‡ç”Ÿæˆä¸€ä¸ªå‡†ç¡®çš„æ ‡é¢˜ã€‚

è¿™ä¸ªæ ‡é¢˜å°†ç”¨äºï¼š
1. ä½œä¸ºå›¾ç‰‡çš„æ–‡ä»¶åæˆ–ç´¢å¼•åç§°
2. å¸®åŠ©ç”¨æˆ·å¿«é€Ÿè¯†åˆ«å›¾ç‰‡å†…å®¹
3. ä¾¿äºæœç´¢å’Œæ£€ç´¢

è¦æ±‚ï¼š
- æ ‡é¢˜è¦å‡†ç¡®æè¿°å›¾ç‰‡çš„æ ¸å¿ƒå†…å®¹
- ä½¿ç”¨ç®€æ´ã€æ¸…æ™°çš„è¯­è¨€
- é•¿åº¦æ§åˆ¶åœ¨5-20ä¸ªå­—ä¹‹é—´
- é¿å…ä½¿ç”¨"å›¾ç‰‡"ã€"ç…§ç‰‡"ç­‰é€šç”¨è¯
- é‡ç‚¹æè¿°ä¸»è¦å¯¹è±¡ã€åœºæ™¯æˆ–äº‹ä»¶

è¯·ç›´æ¥è¿”å›æ ‡é¢˜ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šã€‚"""
        return PromptTemplate(
            input_variables=[],
            template=template
        )

    @staticmethod
    def description_prompt_template() -> PromptTemplate:
        """ç”Ÿæˆæè¿°åˆ†æçš„PromptTemplate"""
        template = """è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹ã€‚

è¿™ä¸ªæè¿°å°†ç”¨äºï¼š
1. AIåå‘ç”Ÿæˆæˆ–è¿˜åŸç›¸ä¼¼å›¾ç‰‡
2. ä¸ºå›¾ç‰‡æ‰“æ ‡ç­¾å’Œåˆ†ç±»çš„å‚è€ƒ
3. å›¾ç‰‡æœç´¢å’Œå†…å®¹ç†è§£

è¦æ±‚ï¼š
- è¯¦ç»†æè¿°æ‰€æœ‰å¯è§çš„å…ƒç´ ã€å¯¹è±¡ã€åœºæ™¯
- åŒ…å«ä½ç½®å…³ç³»ã€ç©ºé—´å¸ƒå±€ä¿¡æ¯
- æè¿°é¢œè‰²ã€å…‰å½±ã€æè´¨ç­‰è§†è§‰ç‰¹å¾
- è¯´æ˜äººç‰©çš„åŠ¨ä½œã€è¡¨æƒ…ã€æœè£…ç­‰ç»†èŠ‚
- æè¿°ç¯å¢ƒã€èƒŒæ™¯ã€æ°›å›´ç­‰ä¿¡æ¯
- é•¿åº¦æ§åˆ¶åœ¨50-500å­—ä¹‹é—´
- ä½¿ç”¨å®¢è§‚ã€å‡†ç¡®çš„è¯­è¨€ï¼Œé¿å…ä¸»è§‚è¯„ä»·
- åŒ…å«è¶³å¤Ÿçš„ç»†èŠ‚ä»¥ä¾¿äºAIç†è§£å’Œé‡ç°

è¯·ç›´æ¥è¿”å›æè¿°å†…å®¹ï¼Œä¸è¦åŒ…å«ä»»ä½•åˆ†æè¿‡ç¨‹ã€‚"""
        return PromptTemplate(
            input_variables=[],
            template=template
        )

    @staticmethod
    def categories_prompt_template(max_categories: int) -> PromptTemplate:
        """ç”Ÿæˆåˆ†ç±»åˆ†æçš„PromptTemplate"""
        template = """è¯·ä¸ºè¿™å¼ å›¾ç‰‡ç”Ÿæˆå‡†ç¡®çš„åˆ†ç±»ã€‚

åˆ†ç±»ç”¨äºï¼š
1. ç»„ç»‡å’Œç®¡ç†å›¾ç‰‡åº“
2. å¿«é€Ÿç­›é€‰å’ŒæŸ¥æ‰¾ç‰¹å®šç±»å‹çš„å†…å®¹
3. å»ºç«‹å†…å®¹åˆ†ç±»ä½“ç³»

è¦æ±‚ï¼š
- æ ¹æ®å›¾ç‰‡ä¸»è¦å†…å®¹ç¡®å®šåˆ†ç±»
- åˆ†ç±»è¦å…·æœ‰æ¦‚æ‹¬æ€§å’Œä»£è¡¨æ€§
- ç”Ÿæˆæœ€å¤š{max_categories}ä¸ªåˆ†ç±»
- ä½¿ç”¨é€šç”¨çš„ã€æ˜“äºç†è§£çš„åˆ†ç±»åç§°
- æ¯ä¸ªåˆ†ç±»2-6ä¸ªå­—
- ä¼˜å…ˆè€ƒè™‘ä¸»è¦åˆ†ç±»ï¼Œå†è€ƒè™‘æ¬¡è¦åˆ†ç±»
- é¿å…è¿‡äºå…·ä½“æˆ–è¿‡äºå®½æ³›çš„åˆ†ç±»

å¸¸è§çš„åˆ†ç±»ç¤ºä¾‹ï¼š
- é£æ™¯ç±»ï¼šè‡ªç„¶é£å…‰ã€åŸå¸‚æ™¯è§‚ã€å»ºç­‘ã€æµ·æ´‹ã€å±±è„‰ç­‰
- äººç‰©ç±»ï¼šäººç‰©è‚–åƒã€å›¢ä½“ç…§ã€æ´»åŠ¨ç…§ç‰‡ç­‰
- ç‰©å“ç±»ï¼šç¾é£Ÿã€åŠ¨ç‰©ã€æ¤ç‰©ã€äº¤é€šå·¥å…·ã€ç§‘æŠ€äº§å“ç­‰
- è‰ºæœ¯ç±»ï¼šç»˜ç”»ã€é›•å¡‘ã€è®¾è®¡ã€æ‘„å½±ä½œå“ç­‰
- åœºæ™¯ç±»ï¼šå®¤å†…ã€å®¤å¤–ã€å·¥ä½œã€ä¼‘é—²ã€è¿åŠ¨ç­‰

è¯·ç”¨é€—å·åˆ†éš”è¿”å›åˆ†ç±»åˆ—è¡¨ã€‚"""
        return PromptTemplate(
            input_variables=["max_categories"],
            template=template
        )

    @staticmethod
    def tags_prompt_template(max_tags: int) -> PromptTemplate:
        """ç”Ÿæˆæ ‡ç­¾åˆ†æçš„PromptTemplate"""
        template = """è¯·ä¸ºè¿™å¼ å›¾ç‰‡æå–ç²¾å‡†çš„å…³é”®è¯æ ‡ç­¾ã€‚

æ ‡ç­¾ç”¨äºï¼š
1. ç²¾ç¡®æ ‡è®°å›¾ç‰‡çš„å…·ä½“å†…å®¹
2. æ”¯æŒå¤šç»´åº¦æœç´¢å’Œç­›é€‰
3. ä¸ç›¸ä¼¼å†…å®¹å»ºç«‹å…³è”
4. AIå†…å®¹ç†è§£å’Œæ¨è

è¦æ±‚ï¼š
- æå–å›¾ç‰‡ä¸­çš„æ‰€æœ‰å…³é”®å…ƒç´ 
- ç”Ÿæˆæœ€å¤š{max_tags}ä¸ªæ ‡ç­¾
- æ ‡ç­¾è¦å…·ä½“ã€å‡†ç¡®ã€æœ‰ä»£è¡¨æ€§
- æ¯ä¸ªæ ‡ç­¾1-4ä¸ªå­—
- åŒ…æ‹¬ä½†ä¸é™äºï¼š
  * ä¸»è¦å¯¹è±¡ï¼ˆäººç‰©ã€åŠ¨ç‰©ã€ç‰©å“ç­‰ï¼‰
  * ç¯å¢ƒåœºæ™¯ï¼ˆå®¤å†…ã€å®¤å¤–ã€å…·ä½“åœ°ç‚¹ç­‰ï¼‰
  * åŠ¨ä½œçŠ¶æ€ï¼ˆåã€ç«‹ã€è¿åŠ¨ç­‰ï¼‰
  * é¢œè‰²ç‰¹å¾ï¼ˆçº¢è‰²ã€è“è‰²ã€å¤šå½©ç­‰ï¼‰
  * æƒ…æ„Ÿæ°›å›´ï¼ˆå¿«ä¹ã€å®‰é™ã€ç´§å¼ ç­‰ï¼‰
  * é£æ ¼ç‰¹ç‚¹ï¼ˆå¤å¤ã€ç°ä»£ã€è‰ºæœ¯ç­‰ï¼‰
  * æŠ€æœ¯ç‰¹å¾ï¼ˆç‰¹å†™ã€è¿œæ™¯ã€é»‘ç™½ç­‰ï¼‰
- é¿å…ä½¿ç”¨ä¸»è§‚è¯„ä»·æ ‡ç­¾
- ä¼˜å…ˆä½¿ç”¨èƒ½è¢«å…¶ä»–ç”¨æˆ·ç†è§£çš„é€šç”¨è¯æ±‡

è¯·ç”¨é€—å·åˆ†éš”è¿”å›æ ‡ç­¾åˆ—è¡¨ã€‚"""
        return PromptTemplate(
            input_variables=["max_tags"],
            template=template
        )

    @staticmethod
    def multimodal_prompt_template(text_prompt: str) -> ChatPromptTemplate:
        """ç”Ÿæˆå¤šæ¨¡æ€åˆ†æçš„ChatPromptTemplate"""
        return ChatPromptTemplate.from_messages([
            ("human", [
                {
                    "type": "text",
                    "text": text_prompt
                },
                {
                    "type": "image_url",
                    "image_url": "data:image/jpeg;base64,{image_base64}"
                }
            ])
        ])

    @staticmethod
    def few_shot_prompt_template(base_prompt: str, examples: list) -> ChatPromptTemplate:
        """ç”ŸæˆåŒ…å«ç¤ºä¾‹çš„Few-shot PromptTemplate"""
        messages = [("system", "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å›¾ç‰‡åˆ†æå¸ˆï¼Œè¯·æ ¹æ®ç¤ºä¾‹çš„æ ¼å¼å›ç­”ã€‚")]

        # æ·»åŠ ç¤ºä¾‹
        for example in examples:
            messages.append(("human", example["input"]))
            messages.append(("ai", example["output"]))

        # æ·»åŠ å®é™…çš„é—®é¢˜
        messages.append(("human", base_prompt))

        return ChatPromptTemplate.from_messages(messages)


class PromptTemplates:
    """å›¾ç‰‡åˆ†ææç¤ºè¯æ¨¡æ¿ç±»ï¼ˆå‘åå…¼å®¹ï¼‰"""

    @staticmethod
    def title_prompt():
        """ç”Ÿæˆæ ‡é¢˜åˆ†æçš„æç¤ºè¯"""
        return LangChainPromptTemplates.title_prompt_template().template

    @staticmethod
    def description_prompt():
        """ç”Ÿæˆæè¿°åˆ†æçš„æç¤ºè¯"""
        return LangChainPromptTemplates.description_prompt_template().template

    @staticmethod
    def categories_prompt(max_categories):
        """ç”Ÿæˆåˆ†ç±»åˆ†æçš„æç¤ºè¯"""
        return LangChainPromptTemplates.categories_prompt_template(max_categories).format(max_categories=max_categories)

    @staticmethod
    def tags_prompt(max_tags):
        """ç”Ÿæˆæ ‡ç­¾åˆ†æçš„æç¤ºè¯"""
        return LangChainPromptTemplates.tags_prompt_template(max_tags).format(max_tags=max_tags)

    @staticmethod
    def default_tags_prompt():
        """ç”Ÿæˆé»˜è®¤æ ‡ç­¾åˆ†ææç¤ºè¯ï¼ˆç”¨äºé»˜è®¤åˆ†æï¼‰"""
        return LangChainPromptTemplates.tags_prompt_template(5).format(max_tags=5)


class TaskConfig:
    """åˆ†æä»»åŠ¡é…ç½®ç±»"""

    # ä»»åŠ¡ç±»å‹æ˜ å°„
    TASK_TYPES = {
        'title': {
            'name': 'æ ‡é¢˜ç”Ÿæˆ',
            'prompt_method': PromptTemplates.title_prompt,
            'langchain_template_method': LangChainPromptTemplates.title_prompt_template,
            'default_max': None
        },
        'description': {
            'name': 'AIæè¿°ç”Ÿæˆ',
            'prompt_method': PromptTemplates.description_prompt,
            'langchain_template_method': LangChainPromptTemplates.description_prompt_template,
            'default_max': None
        },
        'categories': {
            'name': 'åˆ†ç±»ç”Ÿæˆ',
            'prompt_method': PromptTemplates.categories_prompt,
            'langchain_template_method': LangChainPromptTemplates.categories_prompt_template,
            'default_max': 5
        },
        'tags': {
            'name': 'æ ‡ç­¾ç”Ÿæˆ',
            'prompt_method': PromptTemplates.tags_prompt,
            'langchain_template_method': LangChainPromptTemplates.tags_prompt_template,
            'default_max': 10
        }
    }

    # é»˜è®¤ä»»åŠ¡é…ç½®ï¼ˆå½“ç”¨æˆ·æ²¡æœ‰æŒ‡å®šä»»ä½•é€‰é¡¹æ—¶ï¼‰
    DEFAULT_TASKS = ['title', 'description', 'tags']

    @classmethod
    def get_task_prompt(cls, task_type: str, max_value: Optional[int] = None) -> str:
        """è·å–æŒ‡å®šä»»åŠ¡çš„æç¤ºè¯"""
        if task_type not in cls.TASK_TYPES:
            raise ValueError(f"ä¸æ”¯æŒçš„ä»»åŠ¡ç±»å‹: {task_type}")

        task_config = cls.TASK_TYPES[task_type]
        prompt_method = task_config['prompt_method']

        if max_value is None:
            max_value = task_config['default_max']

        if max_value is not None:
            return prompt_method(max_value)
        else:
            return prompt_method()

    @classmethod
    def get_langchain_template(cls, task_type: str, max_value: Optional[int] = None) -> PromptTemplate:
        """è·å–æŒ‡å®šä»»åŠ¡çš„LangChain PromptTemplate"""
        if task_type not in cls.TASK_TYPES:
            raise ValueError(f"ä¸æ”¯æŒçš„ä»»åŠ¡ç±»å‹: {task_type}")

        task_config = cls.TASK_TYPES[task_type]
        template_method = task_config['langchain_template_method']

        if max_value is None:
            max_value = task_config['default_max']

        if max_value is not None:
            return template_method(max_value)
        else:
            return template_method()

    @classmethod
    def get_multimodal_template(cls, prompt: str) -> ChatPromptTemplate:
        """è·å–å¤šæ¨¡æ€ChatPromptTemplate"""
        return LangChainPromptTemplates.multimodal_prompt_template(prompt)

    @classmethod
    def get_enabled_tasks(cls, options: Dict[str, Any]) -> list:
        """æ ¹æ®ç”¨æˆ·é€‰é¡¹è·å–éœ€è¦æ‰§è¡Œçš„ä»»åŠ¡åˆ—è¡¨"""
        tasks = []
        for task_type in cls.TASK_TYPES:
            if options.get(f'generate_{task_type}', False):
                tasks.append(task_type)
        return tasks

    @classmethod
    def get_default_tasks(cls) -> list:
        """è·å–é»˜è®¤ä»»åŠ¡åˆ—è¡¨"""
        return cls.DEFAULT_TASKS.copy()


=== /root/dev/epipremnum/backend/workflow/state_manager.py ===
"""
åŸå­çŠ¶æ€ç®¡ç†å™¨
æä¾›æ•°æ®åº“äº‹åŠ¡ä¿æŠ¤å’ŒåŸå­æ€§çŠ¶æ€æ“ä½œ
"""

import logging
import time
import random
from typing import Dict, Any, Optional, List
from django.db import transaction, models, DatabaseError
from django.db.models import F, Q
from django.core.cache import cache
from django.utils import timezone

from utils.request_queue import throttle_db_write

logger = logging.getLogger(__name__)


class StateManager:
    """åŸå­çŠ¶æ€ç®¡ç†å™¨"""

    def __init__(self):
        self.cache_timeout = 30  # 30ç§’ç¼“å­˜è¶…æ—¶ï¼Œæé«˜å®æ—¶æ€§
        self.max_retries = 5  # å¢åŠ æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œåº”å¯¹é«˜å¹¶å‘
        self.base_delay = 0.05  # å‡å°‘åŸºç¡€å»¶è¿Ÿæ—¶é—´ï¼ŒåŠ å¿«é‡è¯•
        self.max_total_delay = 5.0  # æœ€å¤§æ€»å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰

    def _retry_with_backoff(self, func, *args, **kwargs):
        """
        å¸¦æŒ‡æ•°é€€é¿çš„é‡è¯•æœºåˆ¶
        ä¸»è¦ç”¨äºå¤„ç†æ•°æ®åº“é”å®šé—®é¢˜
        """
        total_delay = 0
        for attempt in range(self.max_retries + 1):
            try:
                return func(*args, **kwargs)
            except DatabaseError as e:
                if "database is locked" in str(e).lower() and attempt < self.max_retries:
                    # æŒ‡æ•°é€€é¿ + éšæœºæŠ–åŠ¨ï¼Œé¿å…æƒŠç¾¤æ•ˆåº”
                    delay = self.base_delay * (2 ** attempt) + random.uniform(0, 0.05)

                    # æ£€æŸ¥æ€»å»¶è¿Ÿæ—¶é—´æ˜¯å¦è¶…è¿‡é™åˆ¶
                    if total_delay + delay > self.max_total_delay:
                        logger.error(f"âŒ æ•°æ®åº“é”å®šé‡è¯•è¶…æ—¶ï¼Œæ€»å»¶è¿Ÿ {total_delay:.2f}s è¶…è¿‡é™åˆ¶ {self.max_total_delay}s")
                        raise

                    total_delay += delay
                    logger.warning(f"ğŸ”„ æ•°æ®åº“é”å®šï¼Œç¬¬ {attempt + 1} æ¬¡é‡è¯•ï¼Œç­‰å¾… {delay:.2f}s (ç´¯è®¡ {total_delay:.2f}s): {str(e)}")
                    time.sleep(delay)
                    continue
                else:
                    # é‡è¯•æ¬¡æ•°ç”¨å®Œæˆ–ä¸æ˜¯é”å®šé”™è¯¯ï¼Œç›´æ¥æŠ›å‡º
                    logger.error(f"âŒ æ•°æ®åº“æ“ä½œå¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°: {str(e)}")
                    raise
            except Exception as e:
                # éæ•°æ®åº“é”™è¯¯ï¼Œç›´æ¥æŠ›å‡º
                raise

    @throttle_db_write
    def create_analysis_safely(self, media, model, analysis_options, prompt=None):
        """åŸå­æ€§åˆ›å»ºåˆ†æä»»åŠ¡ï¼ˆå¸¦é‡è¯•æœºåˆ¶å’Œé™æµï¼Œä¼˜åŒ–é”ç«äº‰ï¼‰"""
        from ollama.models import OllamaImageAnalysis

        def _do_create():
            with transaction.atomic():
                # ä¼˜åŒ–ï¼šå…ˆæ£€æŸ¥æ˜¯å¦å­˜åœ¨è¿›è¡Œä¸­çš„ä»»åŠ¡ï¼Œé¿å…ä¸å¿…è¦çš„é”
                # ä½¿ç”¨æ›´å®½æ¾çš„æŸ¥è¯¢æ¡ä»¶ï¼Œå‡å°‘é”ç«äº‰
                existing_analysis = OllamaImageAnalysis.objects.filter(
                    media=media,
                    model=model,
                    analysis_options=analysis_options,
                    status__in=['pending', 'processing']  # åªæ£€æŸ¥è¿›è¡Œä¸­çš„ä»»åŠ¡
                ).first()

                if existing_analysis:
                    logger.info(f"å‘ç°å·²æœ‰è¿›è¡Œä¸­çš„åˆ†æä»»åŠ¡: {existing_analysis.id}")
                    return existing_analysis, False  # è¿”å›ç°æœ‰ä»»åŠ¡ï¼Œ Falseè¡¨ç¤ºæœªåˆ›å»ºæ–°ä»»åŠ¡

                # åŸå­æ€§åˆ›å»ºæ–°ä»»åŠ¡
                analysis = OllamaImageAnalysis.objects.create(
                    media=media,
                    model=model,
                    analysis_options=analysis_options,
                    prompt=prompt,
                    status='pending'  # ç¡®ä¿åˆå§‹çŠ¶æ€æ­£ç¡®
                )

                logger.info(f"âœ… åŸå­æ€§åˆ›å»ºåˆ†æä»»åŠ¡: {analysis.id}")
                return analysis, True  # è¿”å›æ–°åˆ›å»ºçš„ä»»åŠ¡ï¼Œ Trueè¡¨ç¤ºåˆ›å»ºäº†æ–°ä»»åŠ¡

        try:
            return self._retry_with_backoff(_do_create)
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºåˆ†æä»»åŠ¡å¤±è´¥: {str(e)}")
            raise

    @throttle_db_write
    def update_analysis_status(self, analysis_id: int, from_status: Optional[str], to_status: str, **kwargs) -> bool:
        """åŸå­æ€§æ›´æ–°åˆ†æçŠ¶æ€ï¼ˆå¸¦é‡è¯•æœºåˆ¶å’Œé™æµï¼‰"""
        from ollama.models import OllamaImageAnalysis

        def _do_update():
            with transaction.atomic():
                # ä½¿ç”¨ select_for_update é”å®šè®°å½•é¿å…æ­»é”
                analysis = OllamaImageAnalysis.objects.select_for_update(skip_locked=False).get(id=analysis_id)

                # å¢å¼ºçŠ¶æ€æ£€æŸ¥é€»è¾‘
                current_status = analysis.status
                
                # å¦‚æœæŒ‡å®šäº†æºçŠ¶æ€ï¼Œæ£€æŸ¥å½“å‰çŠ¶æ€æ˜¯å¦åŒ¹é…
                if from_status:
                    if isinstance(from_status, str):
                        if current_status != from_status:
                            logger.warning(f"çŠ¶æ€ä¸åŒ¹é…: analysis_id={analysis_id}, "
                                         f"current={current_status}, expected={from_status}")
                            return False
                    elif isinstance(from_status, list):
                        if current_status not in from_status:
                            logger.warning(f"çŠ¶æ€ä¸åœ¨é¢„æœŸèŒƒå›´å†…: analysis_id={analysis_id}, "
                                         f"current={current_status}, expected={from_status}")
                            return False

                # æ›´ä¸¥æ ¼çš„çŠ¶æ€è½¬æ¢éªŒè¯
                if not self._is_valid_status_transition(current_status, to_status):
                    # ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœç›®æ ‡çŠ¶æ€æ˜¯cancelledæˆ–failedï¼Œå…è®¸ä»ä»»ä½•çŠ¶æ€è½¬æ¢
                    if to_status not in ['cancelled', 'failed']:
                        logger.error(f"æ— æ•ˆçš„çŠ¶æ€è½¬æ¢: analysis_id={analysis_id}, "
                                   f"{current_status} -> {to_status}")
                        return False
                    else:
                        logger.warning(f"å¼ºåˆ¶çŠ¶æ€è½¬æ¢ï¼ˆå–æ¶ˆ/å¤±è´¥ï¼‰: analysis_id={analysis_id}, "
                                     f"{current_status} -> {to_status}")

                # æ›´æ–°çŠ¶æ€å’Œé™„åŠ å­—æ®µ
                old_status = analysis.status
                analysis.status = to_status

                # æ›´æ–°æ—¶é—´æˆ³
                current_time = timezone.now()
                if to_status == 'processing' and not analysis.started_at:
                    analysis.started_at = current_time
                elif to_status in ['completed', 'failed', 'cancelled'] and not analysis.completed_at:
                    analysis.completed_at = current_time

                # æ›´æ–°å…¶ä»–å­—æ®µ
                for key, value in kwargs.items():
                    if hasattr(analysis, key):
                        setattr(analysis, key, value)

                # è®¡ç®—å¤„ç†æ—¶é—´
                if to_status == 'completed':
                    processing_time_ms = kwargs.get('processing_time')
                    if processing_time_ms is not None:
                        analysis.processing_time = processing_time_ms
                        logger.debug(f"ä½¿ç”¨ä¼ å…¥çš„å¤„ç†æ—¶é—´: {processing_time_ms}ms, analysis_id={analysis_id}")
                    elif analysis.started_at:
                        calculated_time = int((current_time - analysis.started_at).total_seconds() * 1000)
                        analysis.processing_time = calculated_time
                        logger.debug(f"è®¡ç®—çš„å¤„ç†æ—¶é—´: {calculated_time}ms, analysis_id={analysis_id}")
                    else:
                        analysis.processing_time = 0
                        logger.warning(f"æ— æ³•è®¡ç®—å¤„ç†æ—¶é—´ï¼Œstarted_atä¸ºç©ºï¼Œè®¾ç½®ä¸º0, analysis_id={analysis_id}")

                # ç¡®ä¿å¤„ç†æ—¶é—´ä¸ä¸ºNone
                if to_status == 'completed' and not analysis.processing_time:
                    analysis.processing_time = int((current_time - analysis.started_at).total_seconds() * 1000) if analysis.started_at else 0
                    logger.warning(f"å¤„ç†æ—¶é—´ä¸ºç©ºï¼Œé‡æ–°è®¡ç®—: {analysis.processing_time}ms, analysis_id={analysis_id}")

                analysis.save()

                # æ¸…é™¤ç›¸å…³ç¼“å­˜
                self._clear_analysis_cache(analysis_id)

                logger.info(f"âœ… çŠ¶æ€æ›´æ–°æˆåŠŸ: analysis_id={analysis_id}, "
                           f"{old_status} -> {to_status}")
                return True

        try:
            return self._retry_with_backoff(_do_update)
        except Exception as e:
            logger.error(f"âŒ çŠ¶æ€æ›´æ–°å¤±è´¥: analysis_id={analysis_id}, error={str(e)}")
            return False

    @throttle_db_write
    def batch_update_status(self, analysis_ids: List[int], from_status: Optional[str], to_status: str, **kwargs) -> Dict[str, int]:
        """æ‰¹é‡åŸå­æ€§æ›´æ–°çŠ¶æ€ï¼ˆå¸¦é‡è¯•æœºåˆ¶å’Œé™æµï¼‰"""
        from ollama.models import OllamaImageAnalysis

        def _do_batch_update():
            with transaction.atomic():
                # ä¼˜åŒ–ï¼šå…ˆè·å–å½“å‰çŠ¶æ€ï¼Œç”¨äºæ—¥å¿—è®°å½•
                current_statuses = dict(
                    OllamaImageAnalysis.objects.filter(id__in=analysis_ids)
                    .values_list('id', 'status')
                )
                
                # æ„å»ºæŸ¥è¯¢æ¡ä»¶
                queryset = OllamaImageAnalysis.objects.filter(id__in=analysis_ids)

                if from_status:
                    if isinstance(from_status, str):
                        queryset = queryset.filter(status=from_status)
                    elif isinstance(from_status, list):
                        queryset = queryset.filter(status__in=from_status)

                # æ›´çµæ´»çš„çŠ¶æ€è½¬æ¢é€»è¾‘
                if to_status == 'cancelled':
                    # å…è®¸ä» pending æˆ– processing çŠ¶æ€å–æ¶ˆ
                    if not from_status:  # å¦‚æœæ²¡æœ‰æŒ‡å®šæºçŠ¶æ€ï¼Œåˆ™è¿‡æ»¤
                        queryset = queryset.filter(status__in=['pending', 'processing'])
                elif to_status == 'processing':
                    # åªèƒ½ä» pending çŠ¶æ€å¼€å§‹å¤„ç†
                    if not from_status:  # å¦‚æœæ²¡æœ‰æŒ‡å®šæºçŠ¶æ€ï¼Œåˆ™è¿‡æ»¤
                        queryset = queryset.filter(status='pending')
                elif to_status == 'failed':
                    # å¯ä»¥ä»ä»»ä½•çŠ¶æ€æ ‡è®°ä¸ºå¤±è´¥ï¼Œä¸é¢å¤–è¿‡æ»¤
                    pass
                elif to_status == 'completed':
                    # åªèƒ½ä» processing çŠ¶æ€å®Œæˆ
                    if not from_status:  # å¦‚æœæ²¡æœ‰æŒ‡å®šæºçŠ¶æ€ï¼Œåˆ™è¿‡æ»¤
                        queryset = queryset.filter(status='processing')

                # å‡†å¤‡æ›´æ–°æ•°æ®
                update_data = {'status': to_status}
                current_time = timezone.now()

                if to_status == 'processing':
                    update_data['started_at'] = current_time
                elif to_status in ['completed', 'failed', 'cancelled']:
                    update_data['completed_at'] = current_time

                # æ·»åŠ å…¶ä»–æ›´æ–°å­—æ®µ
                update_data.update(kwargs)

                # æ‰§è¡Œæ‰¹é‡æ›´æ–°
                updated_count = queryset.update(**update_data)

                # ä¼˜åŒ–ï¼šè®°å½•è¯¦ç»†çš„çŠ¶æ€è½¬æ¢ä¿¡æ¯
                if updated_count < len(analysis_ids):
                    # æ‰¾å‡ºæœªæ›´æ–°çš„è®°å½• - ä¿®å¤ï¼šåº”è¯¥æ£€æŸ¥å“ªäº›è®°å½•å®é™…è¢«æ›´æ–°äº†
                    actually_updated_ids = set(
                        OllamaImageAnalysis.objects.filter(id__in=analysis_ids, status=to_status)
                        .values_list('id', flat=True)
                    )
                    not_updated_ids = set(analysis_ids) - actually_updated_ids
                    
                    for analysis_id in not_updated_ids:
                        current_status = current_statuses.get(analysis_id, 'unknown')
                        logger.warning(f"æ‰¹é‡æ›´æ–°è·³è¿‡: analysis_id={analysis_id}, "
                                     f"current_status={current_status}, target_status={to_status}")

                # æ¸…é™¤ç¼“å­˜
                for analysis_id in analysis_ids:
                    self._clear_analysis_cache(analysis_id)

                logger.info(f"âœ… æ‰¹é‡çŠ¶æ€æ›´æ–°å®Œæˆ: æˆåŠŸ {updated_count}/{len(analysis_ids)} ä¸ª, "
                           f"çŠ¶æ€: {from_status or '*'} -> {to_status}")

                return {
                    'success_count': updated_count,
                    'error_count': len(analysis_ids) - updated_count
                }

        try:
            return self._retry_with_backoff(_do_batch_update)
        except Exception as e:
            logger.error(f"âŒ æ‰¹é‡çŠ¶æ€æ›´æ–°å¤±è´¥: error={str(e)}")
            return {'success_count': 0, 'error_count': len(analysis_ids)}

    def _is_valid_status_transition(self, from_status: str, to_status: str) -> bool:
        """éªŒè¯çŠ¶æ€è½¬æ¢æ˜¯å¦æœ‰æ•ˆ"""
        valid_transitions = {
            'pending': ['processing', 'cancelled', 'failed'],
            'processing': ['completed', 'failed', 'cancelled'],
            'completed': [],  # å·²å®Œæˆä¸èƒ½è½¬æ¢
            'failed': ['pending'],  # å¤±è´¥å¯ä»¥é‡è¯•
            'cancelled': []  # å·²å–æ¶ˆä¸èƒ½è½¬æ¢
        }

        # ä¼˜åŒ–ï¼šå…è®¸ç‰¹æ®Šæƒ…å†µä¸‹çš„çŠ¶æ€è½¬æ¢
        # å¦‚æœç›®æ ‡çŠ¶æ€æ˜¯cancelledæˆ–failedï¼Œå…è®¸ä»ä»»ä½•çŠ¶æ€è½¬æ¢ï¼ˆç”¨äºå¼ºåˆ¶å–æ¶ˆæˆ–æ ‡è®°å¤±è´¥ï¼‰
        if to_status in ['cancelled', 'failed']:
            return True
            
        return to_status in valid_transitions.get(from_status, [])

    def _clear_analysis_cache(self, analysis_id: int):
        """æ¸…é™¤åˆ†æä»»åŠ¡ç›¸å…³ç¼“å­˜"""
        cache_keys = [
            f'analysis_status_{analysis_id}',
            f'analysis_details_{analysis_id}',
            f'user_task_counts_*',  # ç”¨æˆ·ä»»åŠ¡ç»Ÿè®¡ç¼“å­˜
        ]

        for key in cache_keys:
            if key.endswith('*'):
                # æ¨¡ç³ŠåŒ¹é…åˆ é™¤ - Djangoç¼“å­˜å¯èƒ½ä¸æ”¯æŒkeysæ–¹æ³•ï¼Œä½¿ç”¨ç®€å•çš„åˆ é™¤
                try:
                    cache.delete(key.replace('*', ''))
                except:
                    pass  # å¿½ç•¥åˆ é™¤å¤±è´¥
            else:
                cache.delete(key)

    @transaction.atomic
    def increment_retry_count(self, analysis_id: int) -> bool:
        """åŸå­æ€§å¢åŠ é‡è¯•æ¬¡æ•°"""
        from ollama.models import OllamaImageAnalysis

        try:
            with transaction.atomic():
                analysis = OllamaImageAnalysis.objects.select_for_update().get(id=analysis_id)

                if analysis.retry_count >= 3:  # æœ€å¤§é‡è¯•æ¬¡æ•°é™åˆ¶
                    logger.warning(f"åˆ†æä»»åŠ¡å·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°: analysis_id={analysis_id}")
                    return False

                analysis.retry_count = F('retry_count') + 1
                analysis.save()

                # é‡æ–°è·å–å¯¹è±¡ä»¥è·å–æ›´æ–°åçš„å€¼
                analysis.refresh_from_db()
                logger.info(f"ğŸ”„ é‡è¯•æ¬¡æ•°æ›´æ–°: analysis_id={analysis_id}, retry_count={analysis.retry_count}")
                return True

        except Exception as e:
            logger.error(f"âŒ æ›´æ–°é‡è¯•æ¬¡æ•°å¤±è´¥: analysis_id={analysis_id}, error={str(e)}")
            return False

    @throttle_db_write
    def update_media_with_analysis_result(self, analysis, result: Dict[str, Any]) -> bool:
        """åŸå­æ€§æ›´æ–°åª’ä½“åˆ†æç»“æœï¼ˆä½¿ç”¨é‡è¯•æœºåˆ¶å’Œé™æµï¼‰"""
        from media.models import Media, Category, Tag

        def _do_update():
            with transaction.atomic():
                # é”å®šåª’ä½“è®°å½•
                media = Media.objects.select_for_update().get(id=analysis.media.id)

                # æ›´æ–°åª’ä½“å­—æ®µ
                if result.get('title'):
                    media.title = result['title'][:200]  # é™åˆ¶é•¿åº¦

                # åˆå¹¶æè¿°å’Œæç¤ºè¯ä¸ºAIæè¿°
                ai_description_parts = []
                if result.get('description'):
                    ai_description_parts.append(result['description'][:1000])
                if result.get('prompt'):
                    ai_description_parts.append(f"æç¤ºè¯: {result['prompt'][:500]}")

                if ai_description_parts:
                    media.description = '\n\n'.join(ai_description_parts)

                # å¤„ç†åˆ†ç±»
                if result.get('categories'):
                    category_objects = []

                    # ç¡®ä¿ categories æ˜¯åˆ—è¡¨æ ¼å¼
                    categories_list = result['categories']
                    if not isinstance(categories_list, list):
                        # å¦‚æœä¸æ˜¯åˆ—è¡¨ï¼Œå°è¯•è½¬æ¢
                        if isinstance(categories_list, str):
                            categories_list = [categories_list]
                        else:
                            categories_list = [str(categories_list)]

                    # è·å–æˆ–åˆ›å»ºåˆ†ç±»å¯¹è±¡
                    for cat_name in categories_list[:10]:  # é™åˆ¶æ•°é‡
                        # ç¡®ä¿åˆ†ç±»åæ˜¯å­—ç¬¦ä¸²ï¼Œå¤„ç†å¯èƒ½çš„åµŒå¥—
                        if isinstance(cat_name, list):
                            # å¦‚æœæ˜¯åµŒå¥—åˆ—è¡¨ï¼Œå±•å¹³å®ƒ
                            cat_name = str(cat_name[0]) if cat_name else ''
                        elif not isinstance(cat_name, str):
                            cat_name = str(cat_name)

                        # è·³è¿‡ç©ºåˆ†ç±»
                        if not cat_name.strip():
                            continue

                        category, created = Category.objects.get_or_create(
                            name=cat_name[:100],  # é™åˆ¶é•¿åº¦
                            user=media.user,
                            defaults={'description': f'è‡ªåŠ¨ç”Ÿæˆçš„åˆ†ç±»: {cat_name}'}
                        )
                        category_objects.append(category)
                    
                    # è®¾ç½®åˆ†ç±»å…³ç³»
                    media.categories.set(category_objects)

                # å¤„ç†æ ‡ç­¾
                if result.get('tags'):
                    logger.debug(f"Tags received: {type(result['tags'])} - {result['tags']}")
                    tag_objects = []

                    # ç¡®ä¿ tags æ˜¯åˆ—è¡¨æ ¼å¼
                    tags_list = result['tags']
                    if not isinstance(tags_list, list):
                        # å¦‚æœä¸æ˜¯åˆ—è¡¨ï¼Œå°è¯•è½¬æ¢
                        if isinstance(tags_list, str):
                            tags_list = [tags_list]
                        else:
                            tags_list = [str(tags_list)]

                    # å¤„ç†æ¯ä¸ªæ ‡ç­¾
                    for tag_name in tags_list[:20]:  # é™åˆ¶æ•°é‡
                        # ç¡®ä¿æ ‡ç­¾åæ˜¯å­—ç¬¦ä¸²ï¼Œå¤„ç†å¯èƒ½çš„åµŒå¥—
                        if isinstance(tag_name, list):
                            # å¦‚æœæ˜¯åµŒå¥—åˆ—è¡¨ï¼Œå±•å¹³å®ƒ
                            tag_name = str(tag_name[0]) if tag_name else ''
                        elif not isinstance(tag_name, str):
                            tag_name = str(tag_name)

                        # è·³è¿‡ç©ºæ ‡ç­¾
                        if not tag_name.strip():
                            continue

                        tag, created = Tag.objects.get_or_create(
                            name=tag_name[:50],  # é™åˆ¶é•¿åº¦
                            user=media.user,
                            defaults={}
                        )
                        tag_objects.append(tag)

                    # åªæœ‰åœ¨æœ‰æ ‡ç­¾å¯¹è±¡æ—¶æ‰è®¾ç½®
                    if tag_objects:
                        media.tags.set(tag_objects)

                # æ›´æ–°æ—¶é—´æˆ³
                media.save()

                logger.info(f"âœ… åª’ä½“åˆ†æç»“æœæ›´æ–°æˆåŠŸ: media_id={media.id}")
                return True

        try:
            return self._retry_with_backoff(_do_update)
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°åª’ä½“åˆ†æç»“æœå¤±è´¥: media_id={analysis.media.id}, error={str(e)}")
            return False

    def get_user_task_statistics(self, user_id: int) -> Dict[str, Any]:
        """è·å–ç”¨æˆ·ä»»åŠ¡ç»Ÿè®¡ï¼ˆå®æ—¶æ•°æ®ï¼‰"""
        try:
            from ollama.models import OllamaImageAnalysis

            # ä½¿ç”¨èšåˆæŸ¥è¯¢è·å–ç»Ÿè®¡ä¿¡æ¯
            stats = OllamaImageAnalysis.objects.filter(
                media__user_id=user_id
            ).values('status').annotate(
                count=models.Count('id')
            )

            # æ„å»ºç»Ÿè®¡å­—å…¸
            result = {
                'pending': 0,
                'processing': 0,
                'completed': 0,
                'failed': 0,
                'cancelled': 0,
                'total': 0
            }

            for stat in stats:
                status = stat['status']
                count = stat['count']
                if status in result:
                    result[status] = count
                result['total'] += count

            # æ·»åŠ å…¶ä»–ç»Ÿè®¡ä¿¡æ¯
            result['processing_time_avg'] = self._get_avg_processing_time(user_id)
            result['last_activity'] = self._get_last_activity_time(user_id)

            return result

        except Exception as e:
            logger.error(f"âŒ è·å–ç”¨æˆ·ç»Ÿè®¡å¤±è´¥: user_id={user_id}, error={str(e)}")
            return {}

    def _get_avg_processing_time(self, user_id: int) -> float:
        """è·å–å¹³å‡å¤„ç†æ—¶é—´"""
        try:
            from ollama.models import OllamaImageAnalysis

            avg_time = OllamaImageAnalysis.objects.filter(
                media__user_id=user_id,
                status='completed',
                processing_time__isnull=False
            ).aggregate(
                avg_time=models.Avg('processing_time')
            )['avg_time']

            return round(avg_time or 0, 2)
        except:
            return 0.0

    def _get_last_activity_time(self, user_id: int) -> Optional[timezone.datetime]:
        """è·å–æœ€åæ´»åŠ¨æ—¶é—´"""
        try:
            from ollama.models import OllamaImageAnalysis

            last_analysis = OllamaImageAnalysis.objects.filter(
                media__user_id=user_id
            ).order_by('-created_at').first()

            return last_analysis.created_at if last_analysis else None
        except:
            return None

    @transaction.atomic
    def cleanup_old_analyses(self, days_old: int = 30) -> Dict[str, int]:
        """æ¸…ç†æ—§çš„åˆ†æè®°å½•"""
        from ollama.models import OllamaImageAnalysis

        try:
            cutoff_date = timezone.now() - timezone.timedelta(days=days_old)

            with transaction.atomic():
                # è·å–è¦åˆ é™¤çš„è®°å½•æ•°é‡
                old_count = OllamaImageAnalysis.objects.filter(
                    created_at__lt=cutoff_date,
                    status__in=['completed', 'failed', 'cancelled']
                ).count()

                if old_count == 0:
                    logger.info(f"æ²¡æœ‰éœ€è¦æ¸…ç†çš„æ—§åˆ†æè®°å½•ï¼ˆ{days_old}å¤©å‰ï¼‰")
                    return {'deleted_count': 0}

                # åˆ é™¤æ—§è®°å½•
                deleted_count, _ = OllamaImageAnalysis.objects.filter(
                    created_at__lt=cutoff_date,
                    status__in=['completed', 'failed', 'cancelled']
                ).delete()

                logger.info(f"âœ… æ¸…ç†å®Œæˆ: åˆ é™¤äº† {deleted_count} ä¸ªæ—§åˆ†æè®°å½•")
                return {'deleted_count': deleted_count}

        except Exception as e:
            logger.error(f"âŒ æ¸…ç†æ—§åˆ†æè®°å½•å¤±è´¥: error={str(e)}")
            return {'deleted_count': 0, 'error': str(e)}


# å…¨å±€çŠ¶æ€ç®¡ç†å™¨å®ä¾‹
state_manager = StateManager()


=== /root/dev/epipremnum/backend/workflow/task_service.py ===
"""
Ollamaå›¾ç‰‡åˆ†æä»»åŠ¡æœåŠ¡
è´Ÿè´£ä»»åŠ¡çš„åˆ›å»ºã€æŸ¥è¯¢ã€é‡è¯•ç­‰ç®¡ç†æ“ä½œ
"""

import logging
from typing import Dict, Optional
from django.contrib.auth import get_user_model
from django_async_manager.models import Task

from ollama.models import OllamaImageAnalysis, OllamaAIModel
from .task_workers import analyze_image_task, cancel_analysis_task
from .state_manager import state_manager

logger = logging.getLogger(__name__)
User = get_user_model()


class TaskService:
    """Ollamaå›¾ç‰‡åˆ†æä»»åŠ¡æœåŠ¡"""

    def create_task(self, user, media_id: int, model_name: Optional[str] = None,
                   analysis_options: Optional[Dict] = None, prompt: Optional[str] = None) -> Dict:
        """åˆ›å»ºåˆ†æä»»åŠ¡"""
        try:
            from media.models import Media

            # éªŒè¯åª’ä½“æ–‡ä»¶
            media = Media.objects.get(id=media_id)
            if media.user != user:
                return {'success': False, 'error': 'æ²¡æœ‰æƒé™è®¿é—®æ­¤åª’ä½“æ–‡ä»¶'}

            # è·å–æ¨¡å‹
            model = self._get_model(user, model_name)
            if not model:
                return {'success': False, 'error': 'æ²¡æœ‰å¯ç”¨çš„åˆ†ææ¨¡å‹'}

            # ä½¿ç”¨çŠ¶æ€ç®¡ç†å™¨åˆ›å»ºåˆ†æè®°å½•
            analysis, created = state_manager.create_analysis_safely(
                media=media,
                model=model,
                analysis_options=analysis_options or {},
                prompt=prompt
            )

            # å¦‚æœè¿”å›äº†å·²å­˜åœ¨çš„ä»»åŠ¡ï¼Œè¿”å›å…¶ä¿¡æ¯
            if not created:
                return {
                    'success': False,
                    'error': f'è¯¥åª’ä½“æ–‡ä»¶å·²æœ‰ç›¸åŒçš„åˆ†æä»»åŠ¡æ­£åœ¨è¿›è¡Œä¸­ï¼ˆåˆ†æID: {analysis.id}ï¼Œä»»åŠ¡ID: {analysis.task_id or "æœªåˆ†é…"}ï¼‰',
                    'data': {
                        'analysis_id': analysis.id,
                        'task_id': analysis.task_id or "æœªåˆ†é…",
                        'media_id': media_id,
                        'model_name': analysis.model.name if analysis.model else None,
                        'status': analysis.status,
                        'is_duplicate': True
                    }
                }

            # å¯åŠ¨å¼‚æ­¥ä»»åŠ¡
            task = analyze_image_task.run_async(analysis_id=analysis.id)
            analysis.task_id = task.id
            analysis.save(update_fields=['task_id'])

            logger.info(f"âœ… åˆ†æä»»åŠ¡åˆ›å»º: analysis_id={analysis.id}, task_id={task.id}")

            return {
                'success': True,
                'analysis_id': analysis.id,
                'task_id': str(task.id),
                'media_id': media_id,
                'model_name': model.name,
                'status': 'pending'
            }

        except Media.DoesNotExist:
            return {'success': False, 'error': 'åª’ä½“æ–‡ä»¶ä¸å­˜åœ¨'}
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºä»»åŠ¡å¤±è´¥: {str(e)}")
            return {'success': False, 'error': f'åˆ›å»ºä»»åŠ¡å¤±è´¥: {str(e)}'}

    def get_task_status(self, analysis_id: int, user) -> Dict:
        """è·å–ä»»åŠ¡çŠ¶æ€"""
        try:
            analysis = OllamaImageAnalysis.objects.select_related('media', 'model').get(
                id=analysis_id, media__user=user
            )

            return {
                'success': True,
                'analysis_id': analysis.id,
                'media_id': analysis.media.id,
                'status': analysis.status,
                'progress': analysis.task_progress,
                'created_at': analysis.created_at.isoformat(),
                'started_at': analysis.started_at.isoformat() if analysis.started_at else None,
                'completed_at': analysis.completed_at.isoformat() if analysis.completed_at else None,
                'processing_time_s': round(analysis.processing_time / 1000, 2) if analysis.processing_time else None,
                'retry_count': analysis.retry_count,
                'model_name': analysis.model.name if analysis.model else None,
                'can_retry': analysis.can_retry(),
                'error_message': analysis.error_message
            }

        except OllamaImageAnalysis.DoesNotExist:
            return {'success': False, 'error': 'åˆ†æä»»åŠ¡ä¸å­˜åœ¨'}
        except Exception as e:
            logger.error(f"âŒ è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {str(e)}")
            return {'success': False, 'error': f'è·å–çŠ¶æ€å¤±è´¥: {str(e)}'}

    def retry_task(self, analysis_id: int, user) -> Dict:
        """é‡è¯•ä»»åŠ¡"""
        try:
            analysis = OllamaImageAnalysis.objects.select_related('media').get(
                id=analysis_id, media__user=user
            )

            if not analysis.can_retry():
                return {
                    'success': False,
                    'error': f'ä»»åŠ¡æ— æ³•é‡è¯•: status={analysis.status}, retries={analysis.retry_count}'
                }

            # å¢åŠ é‡è¯•æ¬¡æ•°
            analysis.increment_retry()
            
            # é‡æ–°å¯åŠ¨åˆ†æä»»åŠ¡
            task = analyze_image_task.run_async(analysis_id=analysis_id)
            analysis.task_id = task.id
            analysis.save(update_fields=['task_id'])
            
            logger.info(f"ğŸ”„ é‡è¯•ä»»åŠ¡å¯åŠ¨: analysis_id={analysis_id}, task_id={task.id}")

            return {
                'success': True,
                'analysis_id': analysis_id,
                'task_id': str(task.id),
                'retry_count': analysis.retry_count
            }

        except OllamaImageAnalysis.DoesNotExist:
            return {'success': False, 'error': 'åˆ†æä»»åŠ¡ä¸å­˜åœ¨'}
        except Exception as e:
            logger.error(f"âŒ é‡è¯•ä»»åŠ¡å¤±è´¥: {str(e)}")
            return {'success': False, 'error': f'é‡è¯•å¤±è´¥: {str(e)}'}

    def cancel_task(self, analysis_id: int, user) -> Dict:
        """å–æ¶ˆä»»åŠ¡"""
        try:
            analysis = OllamaImageAnalysis.objects.select_related('media').get(
                id=analysis_id, media__user=user
            )

            if analysis.status not in ['pending', 'processing']:
                return {'success': False, 'error': f'ä»»åŠ¡æ— æ³•å–æ¶ˆ: status={analysis.status}'}

            task = cancel_analysis_task.run_async(analysis_id=analysis_id)
            logger.info(f"ğŸš« å–æ¶ˆä»»åŠ¡å¯åŠ¨: analysis_id={analysis_id}, task_id={task.id}")

            return {
                'success': True,
                'analysis_id': analysis_id,
                'task_id': str(task.id)
            }

        except OllamaImageAnalysis.DoesNotExist:
            return {'success': False, 'error': 'åˆ†æä»»åŠ¡ä¸å­˜åœ¨'}
        except Exception as e:
            logger.error(f"âŒ å–æ¶ˆä»»åŠ¡å¤±è´¥: {str(e)}")
            return {'success': False, 'error': f'å–æ¶ˆå¤±è´¥: {str(e)}'}

    def list_tasks(self, user, status_filter: Optional[str] = None,
                   limit: int = 50, offset: int = 0) -> Dict:
        """è·å–ä»»åŠ¡åˆ—è¡¨"""
        try:
            queryset = OllamaImageAnalysis.objects.filter(
                media__user=user
            ).select_related('media', 'model').order_by('-created_at')

            if status_filter:
                queryset = queryset.filter(status=status_filter)

            total_count = queryset.count()
            tasks = queryset[offset:offset + limit]

            task_list = []
            for task in tasks:
                task_list.append({
                    'analysis_id': task.id,
                    'media_id': task.media.id,
                    'media_title': task.media.title or task.media.file.name,
                    'status': task.status,
                    'progress': task.task_progress,
                    'model_name': task.model.name if task.model else None,
                    'created_at': task.created_at.isoformat(),
                    'processing_time_s': round(task.processing_time / 1000, 2) if task.processing_time else None,
                    'retry_count': task.retry_count,
                    'can_retry': task.can_retry(),
                    'error_message': task.error_message
                })

            return {
                'success': True,
                'tasks': task_list,
                'total_count': total_count,
                'limit': limit,
                'offset': offset
            }

        except Exception as e:
            logger.error(f"âŒ è·å–ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {str(e)}")
            return {'success': False, 'error': f'è·å–åˆ—è¡¨å¤±è´¥: {str(e)}'}

    def _get_model(self, user, model_name: Optional[str]) -> Optional[OllamaAIModel]:
        """è·å–åˆ†ææ¨¡å‹"""
        queryset = OllamaAIModel.objects.filter(
            endpoint__created_by=user,
            is_active=True,
            is_vision_capable=True
        )

        if model_name:
            queryset = queryset.filter(name=model_name)

        return queryset.filter(is_default=True).first() or queryset.first()

    
    def get_user_statistics(self, user) -> Dict:
        """è·å–ç”¨æˆ·ä»»åŠ¡ç»Ÿè®¡"""
        try:
            # ä½¿ç”¨çŠ¶æ€ç®¡ç†å™¨è·å–ç»Ÿè®¡ä¿¡æ¯
            user_stats = state_manager.get_user_task_statistics(user.id)
            
            return {
                'success': True,
                'statistics': user_stats
            }
            
        except Exception as e:
            logger.error(f"âŒ è·å–ç”¨æˆ·ç»Ÿè®¡å¤±è´¥: {str(e)}")
            return {'success': False, 'error': f'è·å–ç»Ÿè®¡å¤±è´¥: {str(e)}'}

    def cleanup_old_tasks(self, user, days_old: int = 30) -> Dict:
        """æ¸…ç†ç”¨æˆ·çš„æ—§ä»»åŠ¡"""
        try:
            # ä½¿ç”¨çŠ¶æ€ç®¡ç†å™¨æ¸…ç†æ—§åˆ†æè®°å½•
            cleanup_result = state_manager.cleanup_old_analyses(days_old)
            
            return {
                'success': True,
                'deleted_count': cleanup_result.get('deleted_count', 0),
                'message': f"å·²æ¸…ç† {cleanup_result.get('deleted_count', 0)} ä¸ªæ—§ä»»åŠ¡"
            }
            
        except Exception as e:
            logger.error(f"âŒ æ¸…ç†æ—§ä»»åŠ¡å¤±è´¥: {str(e)}")
            return {'success': False, 'error': f'æ¸…ç†å¤±è´¥: {str(e)}'}

    def batch_analyze(self, user, media_ids: list, model_name: Optional[str] = None,
                     analysis_options: Optional[Dict] = None) -> Dict:
        """æ‰¹é‡åˆ†æä»»åŠ¡"""
        try:
            from .batch_handler import batch_handler
            
            # ä½¿ç”¨æ‰¹é‡å¤„ç†å™¨æ‰§è¡Œæ‰¹é‡åˆ†æ
            result = batch_handler.analyze_images_with_concurrency_task(
                user_id=user.id,
                media_ids=media_ids,
                model_name=model_name,
                analysis_options=analysis_options or {}
            )
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ æ‰¹é‡åˆ†æå¤±è´¥: {str(e)}")
            return {'success': False, 'error': f'æ‰¹é‡åˆ†æå¤±è´¥: {str(e)}'}

    def cancel_all_user_tasks(self, user) -> Dict:
        """å–æ¶ˆç”¨æˆ·æ‰€æœ‰ä»»åŠ¡"""
        try:
            from .task_workers import cancel_all_user_tasks_task
            
            # å¯åŠ¨å–æ¶ˆæ‰€æœ‰ç”¨æˆ·ä»»åŠ¡çš„å¼‚æ­¥ä»»åŠ¡
            task = cancel_all_user_tasks_task.run_async(user_id=user.id)
            
            logger.info(f"ğŸš« å–æ¶ˆç”¨æˆ·æ‰€æœ‰ä»»åŠ¡å¯åŠ¨: user_id={user.id}, task_id={task.id}")
            
            return {
                'success': True,
                'task_id': str(task.id),
                'message': 'å·²å¯åŠ¨å–æ¶ˆæ‰€æœ‰ä»»åŠ¡çš„å¼‚æ­¥æ“ä½œ'
            }
            
        except Exception as e:
            logger.error(f"âŒ å–æ¶ˆæ‰€æœ‰ä»»åŠ¡å¤±è´¥: {str(e)}")
            return {'success': False, 'error': f'å–æ¶ˆæ‰€æœ‰ä»»åŠ¡å¤±è´¥: {str(e)}'}

    def get_batch_status(self, user) -> Dict:
        """è·å–æ‰¹é‡å¤„ç†çŠ¶æ€"""
        try:
            from .batch_handler import batch_handler
            
            # ä½¿ç”¨æ‰¹é‡å¤„ç†å™¨è·å–çŠ¶æ€æ‘˜è¦
            status_summary = batch_handler.get_status_summary(user)
            
            return {
                'success': True,
                'status': status_summary
            }
            
        except Exception as e:
            logger.error(f"âŒ è·å–æ‰¹é‡çŠ¶æ€å¤±è´¥: {str(e)}")
            return {'success': False, 'error': f'è·å–æ‰¹é‡çŠ¶æ€å¤±è´¥: {str(e)}'}


# å…¨å±€ä»»åŠ¡æœåŠ¡å®ä¾‹
task_service = TaskService()


=== /root/dev/epipremnum/backend/workflow/task_workers.py ===
"""
Ollamaå›¾ç‰‡åˆ†æå¼‚æ­¥ä»»åŠ¡å·¥ä½œè€… - ç®€åŒ–ç‰ˆ
ä¸“æ³¨äºæ‰¹é‡åˆ†æçš„é«˜æ•ˆæ‰§è¡Œ
"""

import logging

logger = logging.getLogger(__name__)

# å»¶è¿Ÿåˆå§‹åŒ– background_task
_background_task = None

def get_background_task_decorator():
    """è·å– background_task è£…é¥°å™¨ï¼ˆå»¶è¿ŸåŠ è½½ï¼‰"""
    global _background_task
    if _background_task is None:
        from django_async_manager import get_background_task
        _background_task = get_background_task()
    return _background_task


def _analyze_batch_task(user_id, analysis_ids, model_name, max_concurrent=5):
    """
    æ‰¹é‡åˆ†æå›¾ç‰‡ä»»åŠ¡ - ç®€åŒ–ç‰ˆ
    ç›´æ¥ä½¿ç”¨å¹¶å‘ç®¡ç†å™¨å¤„ç†
    """
    logger.info(f"å¼€å§‹æ‰¹é‡åˆ†æ: {len(analysis_ids)} ä¸ªä»»åŠ¡ï¼Œå¹¶å‘æ•°: {max_concurrent}")

    try:
        from ollama.models import OllamaImageAnalysis
        from .concurrency_manager import concurrency_manager
        from .state_manager import state_manager

        # è·å–åˆ†æä»»åŠ¡
        analyses = OllamaImageAnalysis.objects.filter(
            id__in=analysis_ids
        ).select_related('media', 'model')

        # æ‰¹é‡æ›´æ–°çŠ¶æ€ä¸ºå¤„ç†ä¸­
        state_manager.batch_update_status(
            analysis_ids=analysis_ids,
            from_status='pending',
            to_status='processing'
        )

        # å‡†å¤‡åª’ä½“IDåˆ—è¡¨
        media_ids = [analysis.media.id for analysis in analyses]

        # ä½¿ç”¨å¹¶å‘ç®¡ç†å™¨å¤„ç†
        batch_result = concurrency_manager.process_batch_images(
            user_id=user_id,
            media_ids=media_ids,
            model_name=model_name,
            analysis_options={'max_concurrent': max_concurrent}
        )

        logger.info(f"æ‰¹é‡åˆ†æå®Œæˆ: æˆåŠŸ {batch_result['success_count']}, å¤±è´¥ {batch_result['error_count']}")

        return {
            'success': True,
            'completed_count': batch_result['success_count'],
            'failed_count': batch_result['error_count'],
            'total_count': len(analyses),
            'model_name': model_name,
            'max_concurrent': max_concurrent,
            'details': batch_result
        }

    except Exception as e:
        logger.error(f"æ‰¹é‡åˆ†æä»»åŠ¡å¤±è´¥: {str(e)}")

        # æ‰¹é‡æ ‡è®°å¤±è´¥
        try:
            from .state_manager import state_manager
            state_manager.batch_update_status(
                analysis_ids=analysis_ids,
                from_status=['pending', 'processing'],
                to_status='failed',
                error_message=f'æ‰¹é‡ä»»åŠ¡å¤±è´¥: {str(e)}'
            )
        except Exception as update_error:
            logger.error(f"æ‰¹é‡æ›´æ–°å¤±è´¥çŠ¶æ€æ—¶å‡ºé”™: {str(update_error)}")

        raise


def _analyze_image_task(analysis_id):
    """
    å•ä¸ªå›¾ç‰‡åˆ†æä»»åŠ¡
    """
    logger.info(f"ğŸš€ å¼€å§‹å›¾ç‰‡åˆ†æ: analysis_id={analysis_id}")

    try:
        from ollama.models import OllamaImageAnalysis
        from .ollama_client import OllamaImageAnalyzer

        # è·å–åˆ†æä»»åŠ¡
        analysis = OllamaImageAnalysis.objects.select_related('media', 'model').get(id=analysis_id)

        # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
        if analysis.status in ['failed', 'cancelled']:
            logger.info(f"â­ï¸ è·³è¿‡å·²{analysis.status}çš„ä»»åŠ¡: analysis_id={analysis_id}")
            return {'success': True, 'skipped': True, 'status': analysis.status}

        # ä½¿ç”¨çŠ¶æ€ç®¡ç†å™¨æ›´æ–°çŠ¶æ€
        from .state_manager import state_manager
        success = state_manager.update_analysis_status(
            analysis_id=analysis_id,
            from_status='pending',
            to_status='processing'
        )

        if not success:
            logger.error(f"æ— æ³•æ›´æ–°åˆ†æçŠ¶æ€ä¸ºå¤„ç†ä¸­: analysis_id={analysis_id}")
            return {'success': False, 'error': 'çŠ¶æ€æ›´æ–°å¤±è´¥'}

        # æ‰§è¡Œåˆ†æï¼ˆä½¿ç”¨å¹¶è¡Œç‰ˆæœ¬ï¼‰
        analyzer = OllamaImageAnalyzer()
        result = analyzer.analyze_parallel(analysis)

        if result['success']:
            # æ›´æ–°åª’ä½“ä¿¡æ¯
            state_manager.update_media_with_analysis_result(
                analysis, result['result']
            )

            # æ›´æ–°ä»»åŠ¡çŠ¶æ€
            state_manager.update_analysis_status(
                analysis_id=analysis_id,
                from_status='processing',
                to_status='completed',
                analysis_results=result['result'],
                processing_time=result.get('processing_time_ms')
            )

            logger.info(f"âœ… åˆ†æå®Œæˆ: analysis_id={analysis_id}")
            return {
                'success': True,
                'analysis_id': analysis_id,
                'media_id': analysis.media.id,
                'processing_time_s': round(result.get('processing_time_ms', 0) / 1000, 2)
            }
        else:
            # æ ‡è®°å¤±è´¥
            state_manager.update_analysis_status(
                analysis_id=analysis_id,
                from_status='processing',
                to_status='failed',
                error_message=result['error']
            )

            logger.error(f"âŒ åˆ†æå¤±è´¥: analysis_id={analysis_id}, error={result['error']}")
            return {'success': False, 'error': result['error']}

    except OllamaImageAnalysis.DoesNotExist:
        logger.error(f"âŒ åˆ†æä»»åŠ¡ä¸å­˜åœ¨: analysis_id={analysis_id}")
        return {'success': False, 'error': 'åˆ†æä»»åŠ¡ä¸å­˜åœ¨'}
    except Exception as e:
        logger.error(f"âŒ ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: analysis_id={analysis_id}, error={str(e)}")

        # æ ‡è®°å¤±è´¥
        try:
            from .state_manager import state_manager
            state_manager.update_analysis_status(
                analysis_id=analysis_id,
                from_status=None,
                to_status='failed',
                error_message=f"ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {str(e)}"
            )
        except Exception as update_error:
            logger.error(f"æ›´æ–°å¤±è´¥çŠ¶æ€æ—¶å‡ºé”™: {str(update_error)}")

        return {'success': False, 'error': str(e)}


def _cancel_analysis_task(analysis_id):
    """
    å–æ¶ˆåˆ†æä»»åŠ¡
    """
    logger.info(f"ğŸš« å–æ¶ˆåˆ†æä»»åŠ¡: analysis_id={analysis_id}")

    try:
        from ollama.models import OllamaImageAnalysis
        from django_async_manager.models import Task
        from django.utils import timezone

        analysis = OllamaImageAnalysis.objects.get(id=analysis_id)

        # å–æ¶ˆå…³è”çš„å¼‚æ­¥ä»»åŠ¡
        async_task_cancelled = False
        if analysis.task_id:
            try:
                task = Task.objects.get(id=analysis.task_id)
                if task.status in ['pending', 'running', 'retry']:
                    task.status = 'cancelled'
                    task.save()
                    async_task_cancelled = True
                    logger.info(f"âœ… å¼‚æ­¥ä»»åŠ¡å·²å–æ¶ˆ: task_id={analysis.task_id}")
            except Task.DoesNotExist:
                logger.warning(f"âš ï¸ å¼‚æ­¥ä»»åŠ¡ä¸å­˜åœ¨: task_id={analysis.task_id}")

        # æ›´æ–°åˆ†æä»»åŠ¡çŠ¶æ€
        db_updated = False
        if analysis.status in ['pending', 'processing']:
            analysis.status = 'cancelled'
            analysis.completed_at = timezone.now()
            analysis.save()
            db_updated = True
            logger.info(f"âœ… æ•°æ®åº“çŠ¶æ€å·²æ›´æ–°: analysis_id={analysis_id}")

        return {
            'success': async_task_cancelled or db_updated,
            'analysis_id': analysis_id,
            'async_task_cancelled': async_task_cancelled,
            'database_updated': db_updated,
            'final_status': analysis.status
        }

    except OllamaImageAnalysis.DoesNotExist:
        logger.error(f"âŒ å–æ¶ˆä»»åŠ¡ä¸å­˜åœ¨: analysis_id={analysis_id}")
        return {'success': False, 'error': 'åˆ†æä»»åŠ¡ä¸å­˜åœ¨'}
    except Exception as e:
        logger.error(f"âŒ å–æ¶ˆä»»åŠ¡å¤±è´¥: {str(e)}")
        return {'success': False, 'error': f"å–æ¶ˆå¤±è´¥: {str(e)}"}


def _cancel_all_user_tasks_task(user_id):
    """
    å–æ¶ˆç”¨æˆ·æ‰€æœ‰è¿›è¡Œä¸­å’Œå¾…å¤„ç†çš„ä»»åŠ¡
    """
    logger.info(f"ğŸš« å¼€å§‹å–æ¶ˆç”¨æˆ·æ‰€æœ‰ä»»åŠ¡: user_id={user_id}")

    try:
        from ollama.models import OllamaImageAnalysis
        from django_async_manager.models import Task
        from django.utils import timezone

        # å–æ¶ˆæ•°æ®åº“ä¸­çš„åˆ†æä»»åŠ¡
        cancelled_analyses = OllamaImageAnalysis.objects.filter(
            media__user_id=user_id,
            status__in=['pending', 'processing']
        ).update(
            status='cancelled',
            completed_at=timezone.now(),
            error_message='ç”¨æˆ·å–æ¶ˆæ‰€æœ‰ä»»åŠ¡'
        )

        # å–æ¶ˆå¼‚æ­¥ä»»åŠ¡
        cancelled_async_tasks = Task.objects.filter(
            arguments__user_id=str(user_id),
            status__in=['pending', 'running', 'retry']
        ).update(
            status='cancelled',
            last_errors=['ç”¨æˆ·å–æ¶ˆæ‰€æœ‰ä»»åŠ¡'],
            completed_at=timezone.now()
        )

        logger.info(f"å–æ¶ˆæ‰€æœ‰ä»»åŠ¡å®Œæˆ: åˆ†æä»»åŠ¡ {cancelled_analyses} ä¸ª, å¼‚æ­¥ä»»åŠ¡ {cancelled_async_tasks} ä¸ª")

        return {
            'success': True,
            'cancelled_analyses': cancelled_analyses,
            'cancelled_async_tasks': cancelled_async_tasks,
            'total_cancelled': cancelled_analyses + cancelled_async_tasks
        }

    except Exception as e:
        logger.error(f"å–æ¶ˆæ‰€æœ‰ä»»åŠ¡å¤±è´¥: {str(e)}")
        return {'success': False, 'error': f"å–æ¶ˆæ‰€æœ‰ä»»åŠ¡å¤±è´¥: {str(e)}"}


# åº”ç”¨è£…é¥°å™¨ - å»¶è¿ŸåŠ è½½æ¨¡å¼
analyze_batch_task = get_background_task_decorator()(max_retries=2, retry_delay=30)(_analyze_batch_task)
analyze_image_task = get_background_task_decorator()(max_retries=3, retry_delay=60)(_analyze_image_task)
cancel_analysis_task = get_background_task_decorator()(max_retries=1, retry_delay=15)(_cancel_analysis_task)
cancel_all_user_tasks_task = get_background_task_decorator()(max_retries=1, retry_delay=15)(_cancel_all_user_tasks_task)


=== /root/dev/epipremnum/backend/workflow/tests.py ===
from django.test import TestCase

# Create your tests here.



=== /root/dev/epipremnum/backend/workflow/views.py ===
from django.shortcuts import render

# Create your views here.



